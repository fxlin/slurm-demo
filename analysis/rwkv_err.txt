INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)24=96, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x58
#
# Epoch = 427 to 2833 (will continue afterwards), save every 5 epoch
#
# Each "epoch" = 420 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x58/rwkv-426.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x58', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 420, 'epoch_count': 2407, 'epoch_begin': 427, 'epoch_save': 5, 'micro_bsz': 24, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x058', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 1, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 1, 'lm_eval_n': 1, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-07-10-17-46-45', 'betas': (0.9, 0.99), 'real_bsz': 96, 'run_name': 'L12 D768 F8 x058', 'my_pile_prev_p': 421}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x58/rwkv-426.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:datasets:PyTorch version 2.3.1+cu121 available.

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:01<00:12,  1.42s/it]
 30%|███       | 3/10 [00:01<00:02,  2.38it/s]
100%|██████████| 10/10 [00:01<00:00,  6.40it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:datasets:PyTorch version 2.3.1+cu121 available.
INFO:datasets:PyTorch version 2.3.1+cu121 available.
INFO:datasets:PyTorch version 2.3.1+cu121 available.

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:01<00:14,  1.58s/it]
 20%|██        | 2/10 [00:02<00:07,  1.10it/s]
100%|██████████| 10/10 [00:02<00:00,  4.83it/s]

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:01<00:15,  1.75s/it]
 50%|█████     | 5/10 [00:02<00:01,  3.17it/s]
100%|██████████| 10/10 [00:02<00:00,  4.98it/s]
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:01<00:16,  1.78s/it]
100%|██████████| 10/10 [00:01<00:00,  6.74it/s]
100%|██████████| 10/10 [00:01<00:00,  5.07it/s]
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 65.6 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
166 M     Trainable params
0         Non-trainable params
166 M     Total params
665.063   Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240710_180407-uhyjzs6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L12 D768 F8 x058 2024-07-10-17-46-45
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/uhyjzs6i


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:09,  1.10s/it][A

 20%|██        | 2/10 [00:01<00:07,  1.05it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.15it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:02<00:18,  2.06s/it][A
100%|██████████| 10/10 [00:02<00:00,  4.74it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:13,  1.46s/it][A

 20%|██        | 2/10 [00:02<00:07,  1.07it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.90it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:07,  1.27it/s][A

 30%|███       | 3/10 [00:01<00:03,  2.19it/s][A

 50%|█████     | 5/10 [00:01<00:01,  3.01it/s][A

 80%|████████  | 8/10 [00:02<00:00,  5.35it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.84it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:07,  1.14it/s][A

 20%|██        | 2/10 [00:01<00:03,  2.15it/s][A

 30%|███       | 3/10 [00:01<00:04,  1.47it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.00it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:06,  1.36it/s][A

 20%|██        | 2/10 [00:01<00:07,  1.01it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.27it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:12,  1.33s/it][A

 20%|██        | 2/10 [00:02<00:08,  1.08s/it][A
100%|██████████| 10/10 [00:02<00:00,  4.42it/s]
wandb: Network error (ConnectTimeout), entering retry loop.


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:06,  1.41it/s][A

 20%|██        | 2/10 [00:01<00:04,  1.76it/s][A

 30%|███       | 3/10 [00:01<00:03,  2.08it/s][A

 40%|████      | 4/10 [00:01<00:02,  2.30it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.04it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:15,  1.68s/it][A

 60%|██████    | 6/10 [00:01<00:00,  4.42it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.45it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:14,  1.57s/it][A

 40%|████      | 4/10 [00:01<00:02,  2.70it/s][A

 80%|████████  | 8/10 [00:01<00:00,  5.92it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.01it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:17,  1.91s/it][A

 40%|████      | 4/10 [00:02<00:02,  2.32it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.61it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:02<00:20,  2.28s/it][A
100%|██████████| 10/10 [00:02<00:00,  4.34it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:05,  1.52it/s][A

 20%|██        | 2/10 [00:01<00:07,  1.03it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.22it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:00<00:06,  1.49it/s][A

 20%|██        | 2/10 [00:01<00:06,  1.27it/s][A

 30%|███       | 3/10 [00:01<00:04,  1.60it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.88it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:11,  1.31s/it][A

 30%|███       | 3/10 [00:01<00:03,  1.88it/s][A

 80%|████████  | 8/10 [00:02<00:00,  5.82it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.91it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:12,  1.37s/it][A

 20%|██        | 2/10 [00:01<00:06,  1.29it/s][A

 30%|███       | 3/10 [00:01<00:03,  2.08it/s][A
100%|██████████| 10/10 [00:01<00:00,  5.36it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:01<00:14,  1.63s/it][A

 20%|██        | 2/10 [00:01<00:06,  1.15it/s][A

 30%|███       | 3/10 [00:02<00:03,  1.93it/s][A
100%|██████████| 10/10 [00:02<00:00,  4.84it/s]


  0%|          | 0/10 [00:00<?, ?it/s][A

 10%|█         | 1/10 [00:02<00:19,  2.16s/it][A
100%|██████████| 10/10 [00:02<00:00,  4.62it/s]
slurmstepd: error: *** JOB 62418026 ON udc-an34-19 CANCELLED AT 2024-07-11T09:56:52 ***

========================================
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.11s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:29,  3.23s/it]
100%|██████████| 10/10 [00:03<00:00,  3.09it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.20s/it]
100%|██████████| 10/10 [00:03<00:00,  3.05it/s]

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52
#
# Epoch = 625 to 3031 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52/rwkv-624.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 625, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x052', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-07-16-12-30-28', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': 'L24 D1024 F8 x052', 'my_pile_prev_p': 614}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52/rwkv-624.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 327 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
461 M     Trainable params
0         Non-trainable params
461 M     Total params
1,846.886 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240716_123126-9z2gi600
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L24 D1024 F8 x052 2024-07-16-12-30-28
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/9z2gi600
slurmstepd: error: *** JOB 62554360 ON udc-an36-25 CANCELLED AT 2024-07-17T16:25:31 ***

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)24=96, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x595
#
# Epoch = 0 to 2406 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 420 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x595/rwkv-init.pth', 'wandb': '', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x595', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 420, 'epoch_count': 2407, 'epoch_begin': 0, 'epoch_save': 10, 'micro_bsz': 24, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x0595', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-19-22-35-46', 'betas': (0.9, 0.99), 'real_bsz': 96, 'run_name': '01b-pre-x595'}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x595/rwkv-init.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb  --proj_dir /sfs ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 44.0 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
144 M     Trainable params
0         Non-trainable params
144 M     Total params
578.617   Total estimated model params size (MB)
slurmstepd: error: *** JOB 64227062 ON udc-an37-31 CANCELLED AT 2024-09-22T22:35:21 DUE TO TIME LIMIT ***

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)8=32, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-pre-x59
#
# Epoch = 1977 to 4383 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 1260 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 2048 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-pre-x59/rwkv-1976.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-pre-x59', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 1260, 'epoch_count': 2407, 'epoch_begin': 1977, 'epoch_save': 10, 'micro_bsz': 8, 'n_layer': 24, 'n_embd': 2048, 'dim_att': 2048, 'dim_ffn': 7168, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-21-15-06-28', 'betas': (0.9, 0.99), 'real_bsz': 32, 'run_name': '1b5-pre-x59', 'my_pile_prev_p': 1966}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-pre-x59/rwkv-1976.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 134 M 
1 | blocks | ModuleList | 932 M 
2 | ln_out | LayerNorm  | 4.1 K 
3 | head   | Linear     | 134 M 
--------------------------------------
1.2 B     Trainable params
0         Non-trainable params
1.2 B     Total params
4,802.052 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20241121_150755-5k0pp83s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 1b5-pre-x59 2024-11-21-15-06-28
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/5k0pp83s

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:41:59,594 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:41:59,594 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:41:59,638 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 105/5153 [00:00<00:04, 1040.81it/s]
  4%|▍         | 211/5153 [00:00<00:04, 1048.73it/s]
  6%|▌         | 317/5153 [00:00<00:04, 1052.60it/s]
  8%|▊         | 423/5153 [00:00<00:04, 1055.24it/s]
 10%|█         | 529/5153 [00:00<00:04, 1054.00it/s]
 12%|█▏        | 635/5153 [00:00<00:04, 1055.47it/s]
 14%|█▍        | 742/5153 [00:00<00:04, 1057.00it/s]
 16%|█▋        | 848/5153 [00:00<00:04, 1057.42it/s]
 19%|█▊        | 955/5153 [00:00<00:03, 1059.05it/s]
 21%|██        | 1062/5153 [00:01<00:03, 1060.60it/s]
 23%|██▎       | 1169/5153 [00:01<00:03, 1060.73it/s]
 25%|██▍       | 1276/5153 [00:01<00:03, 1062.18it/s]
 27%|██▋       | 1383/5153 [00:01<00:03, 1064.26it/s]
 29%|██▉       | 1491/5153 [00:01<00:03, 1066.89it/s]
 31%|███       | 1598/5153 [00:01<00:03, 1066.79it/s]
 33%|███▎      | 1705/5153 [00:01<00:03, 1065.28it/s]
 35%|███▌      | 1812/5153 [00:01<00:03, 1063.85it/s]
 37%|███▋      | 1919/5153 [00:01<00:03, 1062.88it/s]
 39%|███▉      | 2026/5153 [00:01<00:02, 1061.14it/s]
 41%|████▏     | 2133/5153 [00:02<00:02, 1059.86it/s]
 43%|████▎     | 2239/5153 [00:02<00:02, 1058.81it/s]
 46%|████▌     | 2345/5153 [00:02<00:02, 1058.30it/s]
 48%|████▊     | 2452/5153 [00:02<00:02, 1060.13it/s]
 50%|████▉     | 2559/5153 [00:02<00:02, 1061.20it/s]
 52%|█████▏    | 2666/5153 [00:02<00:02, 1063.75it/s]
 54%|█████▍    | 2773/5153 [00:02<00:02, 1065.23it/s]
 56%|█████▌    | 2880/5153 [00:02<00:02, 1064.93it/s]
 58%|█████▊    | 2987/5153 [00:02<00:02, 1063.09it/s]
 60%|██████    | 3094/5153 [00:02<00:01, 1061.38it/s]
 62%|██████▏   | 3201/5153 [00:03<00:01, 1060.02it/s]
 64%|██████▍   | 3308/5153 [00:03<00:01, 1058.36it/s]
 66%|██████▋   | 3414/5153 [00:03<00:01, 1058.46it/s]
 68%|██████▊   | 3520/5153 [00:03<00:01, 1058.21it/s]
 70%|███████   | 3627/5153 [00:03<00:01, 1059.71it/s]
 72%|███████▏  | 3734/5153 [00:03<00:01, 1060.31it/s]
 75%|███████▍  | 3841/5153 [00:03<00:01, 1061.89it/s]
 77%|███████▋  | 3948/5153 [00:03<00:01, 1062.67it/s]
 79%|███████▊  | 4055/5153 [00:03<00:01, 1063.55it/s]
 81%|████████  | 4162/5153 [00:03<00:00, 1064.69it/s]
 83%|████████▎ | 4269/5153 [00:04<00:00, 1064.89it/s]
 85%|████████▍ | 4376/5153 [00:04<00:00, 1064.52it/s]
 87%|████████▋ | 4483/5153 [00:04<00:00, 1065.74it/s]
 89%|████████▉ | 4591/5153 [00:04<00:00, 1067.37it/s]
 91%|█████████ | 4698/5153 [00:04<00:00, 1067.54it/s]
 93%|█████████▎| 4806/5153 [00:04<00:00, 1069.52it/s]
 95%|█████████▌| 4913/5153 [00:04<00:00, 1067.94it/s]
 97%|█████████▋| 5020/5153 [00:04<00:00, 1066.72it/s]
 99%|█████████▉| 5127/5153 [00:04<00:00, 1066.54it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1062.09it/s]
2024-11-21:14:42:04,547 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:42:32,584 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:32,584 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:32,628 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1022.70it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1025.76it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1030.14it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1033.41it/s]
 10%|█         | 518/5153 [00:00<00:04, 1034.75it/s]
 12%|█▏        | 623/5153 [00:00<00:04, 1037.17it/s]
 14%|█▍        | 727/5153 [00:00<00:04, 1037.62it/s]
 16%|█▌        | 831/5153 [00:00<00:04, 1037.89it/s]
 18%|█▊        | 936/5153 [00:00<00:04, 1038.64it/s]
 20%|██        | 1041/5153 [00:01<00:03, 1040.26it/s]
 22%|██▏       | 1146/5153 [00:01<00:03, 1041.91it/s]
 24%|██▍       | 1251/5153 [00:01<00:03, 1044.09it/s]
 26%|██▋       | 1356/5153 [00:01<00:03, 1045.12it/s]
 28%|██▊       | 1461/5153 [00:01<00:03, 1045.78it/s]
 30%|███       | 1566/5153 [00:01<00:03, 1046.85it/s]
 32%|███▏      | 1671/5153 [00:01<00:03, 1047.08it/s]
 34%|███▍      | 1776/5153 [00:01<00:03, 1047.28it/s]
 37%|███▋      | 1881/5153 [00:01<00:03, 1046.27it/s]
 39%|███▊      | 1986/5153 [00:01<00:03, 1044.66it/s]
 41%|████      | 2091/5153 [00:02<00:02, 1044.59it/s]
 43%|████▎     | 2196/5153 [00:02<00:02, 1043.51it/s]
 45%|████▍     | 2301/5153 [00:02<00:02, 1042.99it/s]
 47%|████▋     | 2406/5153 [00:02<00:02, 1044.39it/s]
 49%|████▊     | 2511/5153 [00:02<00:02, 1043.83it/s]
 51%|█████     | 2616/5153 [00:02<00:02, 1044.13it/s]
 53%|█████▎    | 2721/5153 [00:02<00:02, 1045.60it/s]
 55%|█████▍    | 2826/5153 [00:02<00:02, 1046.36it/s]
 57%|█████▋    | 2931/5153 [00:02<00:02, 1046.81it/s]
 59%|█████▉    | 3037/5153 [00:02<00:02, 1047.54it/s]
 61%|██████    | 3142/5153 [00:03<00:01, 1047.09it/s]
 63%|██████▎   | 3247/5153 [00:03<00:01, 1046.72it/s]
 65%|██████▌   | 3352/5153 [00:03<00:01, 1045.52it/s]
 67%|██████▋   | 3457/5153 [00:03<00:01, 1045.24it/s]
 69%|██████▉   | 3562/5153 [00:03<00:01, 1046.27it/s]
 71%|███████   | 3667/5153 [00:03<00:01, 1044.67it/s]
 73%|███████▎  | 3772/5153 [00:03<00:01, 1045.22it/s]
 75%|███████▌  | 3877/5153 [00:03<00:01, 1045.48it/s]
 77%|███████▋  | 3982/5153 [00:03<00:01, 1045.94it/s]
 79%|███████▉  | 4088/5153 [00:03<00:01, 1047.75it/s]
 81%|████████▏ | 4194/5153 [00:04<00:00, 1048.81it/s]
 83%|████████▎ | 4299/5153 [00:04<00:00, 1048.36it/s]
 85%|████████▌ | 4404/5153 [00:04<00:00, 1047.51it/s]
 88%|████████▊ | 4509/5153 [00:04<00:00, 1045.70it/s]
 90%|████████▉ | 4614/5153 [00:04<00:00, 1044.41it/s]
 92%|█████████▏| 4719/5153 [00:04<00:00, 1044.10it/s]
 94%|█████████▎| 4824/5153 [00:04<00:00, 1043.31it/s]
 96%|█████████▌| 4929/5153 [00:04<00:00, 1043.00it/s]
 98%|█████████▊| 5034/5153 [00:04<00:00, 1041.96it/s]
100%|█████████▉| 5139/5153 [00:04<00:00, 1042.42it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1043.56it/s]
2024-11-21:14:42:37,607 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:43:04,165 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:04,165 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:04,210 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1036.66it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1038.90it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1043.91it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1046.52it/s]
 10%|█         | 526/5153 [00:00<00:04, 1048.83it/s]
 12%|█▏        | 633/5153 [00:00<00:04, 1053.94it/s]
 14%|█▍        | 740/5153 [00:00<00:04, 1056.85it/s]
 16%|█▋        | 847/5153 [00:00<00:04, 1059.66it/s]
 19%|█▊        | 954/5153 [00:00<00:03, 1062.09it/s]
 21%|██        | 1061/5153 [00:01<00:03, 1062.93it/s]
 23%|██▎       | 1168/5153 [00:01<00:03, 1063.83it/s]
 25%|██▍       | 1276/5153 [00:01<00:03, 1066.03it/s]
 27%|██▋       | 1383/5153 [00:01<00:03, 1065.28it/s]
 29%|██▉       | 1490/5153 [00:01<00:03, 1066.44it/s]
 31%|███       | 1597/5153 [00:01<00:03, 1067.36it/s]
 33%|███▎      | 1704/5153 [00:01<00:03, 1066.78it/s]
 35%|███▌      | 1811/5153 [00:01<00:03, 1067.22it/s]
 37%|███▋      | 1918/5153 [00:01<00:03, 1066.98it/s]
 39%|███▉      | 2025/5153 [00:01<00:02, 1067.55it/s]
 41%|████▏     | 2132/5153 [00:02<00:02, 1067.89it/s]
 43%|████▎     | 2239/5153 [00:02<00:02, 1067.57it/s]
 46%|████▌     | 2346/5153 [00:02<00:02, 1066.41it/s]
 48%|████▊     | 2453/5153 [00:02<00:02, 1066.75it/s]
 50%|████▉     | 2560/5153 [00:02<00:02, 1064.70it/s]
 52%|█████▏    | 2667/5153 [00:02<00:02, 1065.94it/s]
 54%|█████▍    | 2774/5153 [00:02<00:02, 1065.28it/s]
 56%|█████▌    | 2881/5153 [00:02<00:02, 1065.30it/s]
 58%|█████▊    | 2988/5153 [00:02<00:02, 1065.12it/s]
 60%|██████    | 3095/5153 [00:02<00:01, 1064.91it/s]
 62%|██████▏   | 3202/5153 [00:03<00:01, 1065.19it/s]
 64%|██████▍   | 3309/5153 [00:03<00:01, 1063.47it/s]
 66%|██████▋   | 3416/5153 [00:03<00:01, 1064.59it/s]
 68%|██████▊   | 3523/5153 [00:03<00:01, 1064.11it/s]
 70%|███████   | 3630/5153 [00:03<00:01, 1065.35it/s]
 73%|███████▎  | 3737/5153 [00:03<00:01, 1063.82it/s]
 75%|███████▍  | 3844/5153 [00:03<00:01, 1065.34it/s]
 77%|███████▋  | 3951/5153 [00:03<00:01, 1065.83it/s]
 79%|███████▉  | 4058/5153 [00:03<00:01, 1066.96it/s]
 81%|████████  | 4166/5153 [00:03<00:00, 1068.16it/s]
 83%|████████▎ | 4273/5153 [00:04<00:00, 1068.65it/s]
 85%|████████▍ | 4380/5153 [00:04<00:00, 1068.15it/s]
 87%|████████▋ | 4487/5153 [00:04<00:00, 1067.86it/s]
 89%|████████▉ | 4594/5153 [00:04<00:00, 1067.09it/s]
 91%|█████████ | 4701/5153 [00:04<00:00, 1066.38it/s]
 93%|█████████▎| 4808/5153 [00:04<00:00, 1067.00it/s]
 95%|█████████▌| 4915/5153 [00:04<00:00, 1065.06it/s]
 97%|█████████▋| 5022/5153 [00:04<00:00, 1065.02it/s]
100%|█████████▉| 5129/5153 [00:04<00:00, 1065.29it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1063.96it/s]
2024-11-21:14:43:09,096 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:43:35,256 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:35,257 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:35,301 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1026.61it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.42it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1035.59it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1037.20it/s]
 10%|█         | 521/5153 [00:00<00:04, 1039.53it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1044.02it/s]
 14%|█▍        | 733/5153 [00:00<00:04, 1046.49it/s]
 16%|█▋        | 838/5153 [00:00<00:04, 1047.25it/s]
 18%|█▊        | 943/5153 [00:00<00:04, 1046.20it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1045.93it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1047.41it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1049.60it/s]
 26%|██▋       | 1365/5153 [00:01<00:03, 1049.34it/s]
 29%|██▊       | 1471/5153 [00:01<00:03, 1049.78it/s]
 31%|███       | 1577/5153 [00:01<00:03, 1051.35it/s]
 33%|███▎      | 1683/5153 [00:01<00:03, 1052.38it/s]
 35%|███▍      | 1789/5153 [00:01<00:03, 1053.53it/s]
 37%|███▋      | 1895/5153 [00:01<00:03, 1054.05it/s]
 39%|███▉      | 2001/5153 [00:01<00:02, 1055.44it/s]
 41%|████      | 2107/5153 [00:02<00:02, 1055.84it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1055.54it/s]
 45%|████▌     | 2319/5153 [00:02<00:02, 1055.16it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1056.82it/s]
 49%|████▉     | 2532/5153 [00:02<00:02, 1057.43it/s]
 51%|█████     | 2638/5153 [00:02<00:02, 1056.96it/s]
 53%|█████▎    | 2744/5153 [00:02<00:02, 1057.61it/s]
 55%|█████▌    | 2850/5153 [00:02<00:02, 1057.91it/s]
 57%|█████▋    | 2956/5153 [00:02<00:02, 1058.52it/s]
 59%|█████▉    | 3063/5153 [00:02<00:01, 1059.00it/s]
 62%|██████▏   | 3170/5153 [00:03<00:01, 1060.47it/s]
 64%|██████▎   | 3277/5153 [00:03<00:01, 1060.03it/s]
 66%|██████▌   | 3384/5153 [00:03<00:01, 1060.51it/s]
 68%|██████▊   | 3491/5153 [00:03<00:01, 1060.82it/s]
 70%|██████▉   | 3598/5153 [00:03<00:01, 1060.55it/s]
 72%|███████▏  | 3705/5153 [00:03<00:01, 1059.29it/s]
 74%|███████▍  | 3811/5153 [00:03<00:01, 1058.09it/s]
 76%|███████▌  | 3917/5153 [00:03<00:01, 1058.27it/s]
 78%|███████▊  | 4024/5153 [00:03<00:01, 1058.94it/s]
 80%|████████  | 4131/5153 [00:03<00:00, 1060.69it/s]
 82%|████████▏ | 4238/5153 [00:04<00:00, 1061.61it/s]
 84%|████████▍ | 4345/5153 [00:04<00:00, 1060.62it/s]
 86%|████████▋ | 4452/5153 [00:04<00:00, 1061.10it/s]
 88%|████████▊ | 4559/5153 [00:04<00:00, 1060.07it/s]
 91%|█████████ | 4666/5153 [00:04<00:00, 1059.80it/s]
 93%|█████████▎| 4772/5153 [00:04<00:00, 1058.54it/s]
 95%|█████████▍| 4878/5153 [00:04<00:00, 1057.93it/s]
 97%|█████████▋| 4984/5153 [00:04<00:00, 1057.98it/s]
 99%|█████████▉| 5090/5153 [00:04<00:00, 1058.32it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.62it/s]
2024-11-21:14:43:40,229 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:44:07,052 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:07,052 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:07,098 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.79it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.87it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1033.09it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1033.88it/s]
 10%|█         | 519/5153 [00:00<00:04, 1035.36it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1039.18it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1042.06it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1044.94it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1045.58it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1047.35it/s]
 22%|██▏       | 1152/5153 [00:01<00:03, 1049.09it/s]
 24%|██▍       | 1258/5153 [00:01<00:03, 1050.07it/s]
 26%|██▋       | 1364/5153 [00:01<00:03, 1048.56it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1048.22it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1048.64it/s]
 33%|███▎      | 1679/5153 [00:01<00:03, 1048.62it/s]
 35%|███▍      | 1785/5153 [00:01<00:03, 1049.49it/s]
 37%|███▋      | 1890/5153 [00:01<00:03, 1048.03it/s]
 39%|███▊      | 1995/5153 [00:01<00:03, 1048.17it/s]
 41%|████      | 2101/5153 [00:02<00:02, 1050.09it/s]
 43%|████▎     | 2207/5153 [00:02<00:02, 1051.38it/s]
 45%|████▍     | 2313/5153 [00:02<00:02, 1052.47it/s]
 47%|████▋     | 2419/5153 [00:02<00:02, 1052.91it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1053.85it/s]
 51%|█████     | 2631/5153 [00:02<00:02, 1052.12it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1052.35it/s]
 55%|█████▌    | 2843/5153 [00:02<00:02, 1051.20it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1049.45it/s]
 59%|█████▉    | 3055/5153 [00:02<00:01, 1049.65it/s]
 61%|██████▏   | 3160/5153 [00:03<00:01, 1049.59it/s]
 63%|██████▎   | 3266/5153 [00:03<00:01, 1051.11it/s]
 65%|██████▌   | 3372/5153 [00:03<00:01, 1051.67it/s]
 67%|██████▋   | 3478/5153 [00:03<00:01, 1051.81it/s]
 70%|██████▉   | 3584/5153 [00:03<00:01, 1053.14it/s]
 72%|███████▏  | 3690/5153 [00:03<00:01, 1053.31it/s]
 74%|███████▎  | 3796/5153 [00:03<00:01, 1052.39it/s]
 76%|███████▌  | 3902/5153 [00:03<00:01, 1050.92it/s]
 78%|███████▊  | 4008/5153 [00:03<00:01, 1049.29it/s]
 80%|███████▉  | 4113/5153 [00:03<00:00, 1049.15it/s]
 82%|████████▏ | 4218/5153 [00:04<00:00, 1048.18it/s]
 84%|████████▍ | 4323/5153 [00:04<00:00, 1046.28it/s]
 86%|████████▌ | 4428/5153 [00:04<00:00, 1045.98it/s]
 88%|████████▊ | 4533/5153 [00:04<00:00, 1046.90it/s]
 90%|█████████ | 4639/5153 [00:04<00:00, 1047.92it/s]
 92%|█████████▏| 4744/5153 [00:04<00:00, 1048.35it/s]
 94%|█████████▍| 4850/5153 [00:04<00:00, 1050.41it/s]
 96%|█████████▌| 4956/5153 [00:04<00:00, 1050.18it/s]
 98%|█████████▊| 5062/5153 [00:04<00:00, 1048.73it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1048.19it/s]
2024-11-21:14:44:12,056 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:44:38,984 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:38,984 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:39,029 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1021.00it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1026.71it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1029.14it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1033.51it/s]
 10%|█         | 520/5153 [00:00<00:04, 1034.93it/s]
 12%|█▏        | 625/5153 [00:00<00:04, 1039.20it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1042.02it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1043.90it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1044.27it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1045.28it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1046.40it/s]
 24%|██▍       | 1255/5153 [00:01<00:03, 1047.17it/s]
 26%|██▋       | 1360/5153 [00:01<00:03, 1047.85it/s]
 28%|██▊       | 1465/5153 [00:01<00:03, 1047.14it/s]
 30%|███       | 1571/5153 [00:01<00:03, 1048.81it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1050.12it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1052.12it/s]
 37%|███▋      | 1889/5153 [00:01<00:03, 1052.45it/s]
 39%|███▊      | 1995/5153 [00:01<00:02, 1053.64it/s]
 41%|████      | 2101/5153 [00:02<00:02, 1054.31it/s]
 43%|████▎     | 2207/5153 [00:02<00:02, 1052.78it/s]
 45%|████▍     | 2313/5153 [00:02<00:02, 1050.58it/s]
 47%|████▋     | 2419/5153 [00:02<00:02, 1049.81it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1050.45it/s]
 51%|█████     | 2631/5153 [00:02<00:02, 1048.43it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1049.53it/s]
 55%|█████▌    | 2843/5153 [00:02<00:02, 1049.87it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1050.69it/s]
 59%|█████▉    | 3055/5153 [00:02<00:01, 1051.35it/s]
 61%|██████▏   | 3161/5153 [00:03<00:01, 1051.48it/s]
 63%|██████▎   | 3267/5153 [00:03<00:01, 1053.69it/s]
 65%|██████▌   | 3373/5153 [00:03<00:01, 1053.51it/s]
 68%|██████▊   | 3479/5153 [00:03<00:01, 1052.12it/s]
 70%|██████▉   | 3585/5153 [00:03<00:01, 1051.48it/s]
 72%|███████▏  | 3691/5153 [00:03<00:01, 1050.22it/s]
 74%|███████▎  | 3797/5153 [00:03<00:01, 1050.06it/s]
 76%|███████▌  | 3903/5153 [00:03<00:01, 1049.71it/s]
 78%|███████▊  | 4008/5153 [00:03<00:01, 1049.08it/s]
 80%|███████▉  | 4114/5153 [00:03<00:00, 1050.53it/s]
 82%|████████▏ | 4220/5153 [00:04<00:00, 1051.57it/s]
 84%|████████▍ | 4326/5153 [00:04<00:00, 1051.87it/s]
 86%|████████▌ | 4432/5153 [00:04<00:00, 1051.99it/s]
 88%|████████▊ | 4538/5153 [00:04<00:00, 1053.40it/s]
 90%|█████████ | 4644/5153 [00:04<00:00, 1052.43it/s]
 92%|█████████▏| 4750/5153 [00:04<00:00, 1049.69it/s]
 94%|█████████▍| 4855/5153 [00:04<00:00, 1049.04it/s]
 96%|█████████▋| 4960/5153 [00:04<00:00, 1048.22it/s]
 98%|█████████▊| 5066/5153 [00:04<00:00, 1049.46it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1048.50it/s]
2024-11-21:14:44:43,986 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:45:11,918 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:11,918 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:11,963 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1035.37it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1039.25it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1040.29it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1040.36it/s]
 10%|█         | 524/5153 [00:00<00:04, 1040.87it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1045.21it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1049.99it/s]
 16%|█▋        | 843/5153 [00:00<00:04, 1053.44it/s]
 18%|█▊        | 950/5153 [00:00<00:03, 1056.73it/s]
 21%|██        | 1057/5153 [00:01<00:03, 1058.11it/s]
 23%|██▎       | 1164/5153 [00:01<00:03, 1059.43it/s]
 25%|██▍       | 1270/5153 [00:01<00:03, 1058.63it/s]
 27%|██▋       | 1377/5153 [00:01<00:03, 1059.39it/s]
 29%|██▉       | 1483/5153 [00:01<00:03, 1058.76it/s]
 31%|███       | 1589/5153 [00:01<00:03, 1056.54it/s]
 33%|███▎      | 1695/5153 [00:01<00:03, 1054.94it/s]
 35%|███▍      | 1801/5153 [00:01<00:03, 1055.41it/s]
 37%|███▋      | 1907/5153 [00:01<00:03, 1056.20it/s]
 39%|███▉      | 2013/5153 [00:01<00:02, 1056.91it/s]
 41%|████      | 2120/5153 [00:02<00:02, 1057.80it/s]
 43%|████▎     | 2227/5153 [00:02<00:02, 1059.03it/s]
 45%|████▌     | 2334/5153 [00:02<00:02, 1059.71it/s]
 47%|████▋     | 2440/5153 [00:02<00:02, 1059.40it/s]
 49%|████▉     | 2546/5153 [00:02<00:02, 1057.95it/s]
 51%|█████▏    | 2652/5153 [00:02<00:02, 1056.61it/s]
 54%|█████▎    | 2758/5153 [00:02<00:02, 1055.26it/s]
 56%|█████▌    | 2864/5153 [00:02<00:02, 1056.26it/s]
 58%|█████▊    | 2970/5153 [00:02<00:02, 1055.97it/s]
 60%|█████▉    | 3076/5153 [00:02<00:01, 1056.68it/s]
 62%|██████▏   | 3183/5153 [00:03<00:01, 1057.76it/s]
 64%|██████▍   | 3290/5153 [00:03<00:01, 1058.71it/s]
 66%|██████▌   | 3397/5153 [00:03<00:01, 1059.81it/s]
 68%|██████▊   | 3504/5153 [00:03<00:01, 1060.90it/s]
 70%|███████   | 3611/5153 [00:03<00:01, 1062.16it/s]
 72%|███████▏  | 3718/5153 [00:03<00:01, 1061.34it/s]
 74%|███████▍  | 3825/5153 [00:03<00:01, 1061.20it/s]
 76%|███████▋  | 3932/5153 [00:03<00:01, 1058.87it/s]
 78%|███████▊  | 4038/5153 [00:03<00:01, 1057.73it/s]
 80%|████████  | 4144/5153 [00:03<00:00, 1057.92it/s]
 82%|████████▏ | 4250/5153 [00:04<00:00, 1056.99it/s]
 85%|████████▍ | 4356/5153 [00:04<00:00, 1055.68it/s]
 87%|████████▋ | 4462/5153 [00:04<00:00, 1055.84it/s]
 89%|████████▊ | 4568/5153 [00:04<00:00, 1056.24it/s]
 91%|█████████ | 4674/5153 [00:04<00:00, 1056.47it/s]
 93%|█████████▎| 4781/5153 [00:04<00:00, 1058.85it/s]
 95%|█████████▍| 4887/5153 [00:04<00:00, 1058.78it/s]
 97%|█████████▋| 4993/5153 [00:04<00:00, 1057.44it/s]
 99%|█████████▉| 5099/5153 [00:04<00:00, 1056.33it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1056.14it/s]
2024-11-21:14:45:16,884 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
2024-11-21:14:45:43,323 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:43,323 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:43,367 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1036.87it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1042.35it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1046.16it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1045.55it/s]
 10%|█         | 525/5153 [00:00<00:04, 1045.41it/s]
 12%|█▏        | 632/5153 [00:00<00:04, 1050.41it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1053.62it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1055.39it/s]
 18%|█▊        | 952/5153 [00:00<00:03, 1057.70it/s]
 21%|██        | 1059/5153 [00:01<00:03, 1058.92it/s]
 23%|██▎       | 1165/5153 [00:01<00:03, 1058.63it/s]
 25%|██▍       | 1272/5153 [00:01<00:03, 1059.76it/s]
 27%|██▋       | 1379/5153 [00:01<00:03, 1060.82it/s]
 29%|██▉       | 1486/5153 [00:01<00:03, 1059.66it/s]
 31%|███       | 1592/5153 [00:01<00:03, 1059.18it/s]
 33%|███▎      | 1698/5153 [00:01<00:03, 1058.63it/s]
 35%|███▌      | 1805/5153 [00:01<00:03, 1060.45it/s]
 37%|███▋      | 1912/5153 [00:01<00:03, 1060.21it/s]
 39%|███▉      | 2019/5153 [00:01<00:02, 1059.79it/s]
 41%|████      | 2125/5153 [00:02<00:02, 1059.07it/s]
 43%|████▎     | 2231/5153 [00:02<00:02, 1058.56it/s]
 45%|████▌     | 2337/5153 [00:02<00:02, 1058.48it/s]
 47%|████▋     | 2444/5153 [00:02<00:02, 1060.30it/s]
 50%|████▉     | 2551/5153 [00:02<00:02, 1061.19it/s]
 52%|█████▏    | 2658/5153 [00:02<00:02, 1060.52it/s]
 54%|█████▎    | 2765/5153 [00:02<00:02, 1060.73it/s]
 56%|█████▌    | 2872/5153 [00:02<00:02, 1059.32it/s]
 58%|█████▊    | 2978/5153 [00:02<00:02, 1058.45it/s]
 60%|█████▉    | 3084/5153 [00:02<00:01, 1058.58it/s]
 62%|██████▏   | 3191/5153 [00:03<00:01, 1059.46it/s]
 64%|██████▍   | 3298/5153 [00:03<00:01, 1060.76it/s]
 66%|██████▌   | 3405/5153 [00:03<00:01, 1059.76it/s]
 68%|██████▊   | 3511/5153 [00:03<00:01, 1058.92it/s]
 70%|███████   | 3617/5153 [00:03<00:01, 1058.44it/s]
 72%|███████▏  | 3723/5153 [00:03<00:01, 1057.65it/s]
 74%|███████▍  | 3830/5153 [00:03<00:01, 1058.81it/s]
 76%|███████▋  | 3936/5153 [00:03<00:01, 1058.55it/s]
 78%|███████▊  | 4042/5153 [00:03<00:01, 1058.18it/s]
 80%|████████  | 4148/5153 [00:03<00:00, 1058.54it/s]
 83%|████████▎ | 4255/5153 [00:04<00:00, 1059.16it/s]
 85%|████████▍ | 4361/5153 [00:04<00:00, 1058.50it/s]
 87%|████████▋ | 4468/5153 [00:04<00:00, 1059.40it/s]
 89%|████████▉ | 4574/5153 [00:04<00:00, 1057.72it/s]
 91%|█████████ | 4680/5153 [00:04<00:00, 1055.72it/s]
 93%|█████████▎| 4786/5153 [00:04<00:00, 1056.07it/s]
 95%|█████████▍| 4892/5153 [00:04<00:00, 1055.19it/s]
 97%|█████████▋| 4998/5153 [00:04<00:00, 1055.86it/s]
 99%|█████████▉| 5104/5153 [00:04<00:00, 1056.17it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1057.36it/s]
2024-11-21:14:45:48,283 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:46:14,639 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:14,639 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:14,684 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1038.16it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1042.43it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1048.09it/s]
  8%|▊         | 421/5153 [00:00<00:04, 1051.01it/s]
 10%|█         | 527/5153 [00:00<00:04, 1051.88it/s]
 12%|█▏        | 634/5153 [00:00<00:04, 1055.08it/s]
 14%|█▍        | 741/5153 [00:00<00:04, 1058.13it/s]
 16%|█▋        | 848/5153 [00:00<00:04, 1061.18it/s]
 19%|█▊        | 955/5153 [00:00<00:03, 1062.04it/s]
 21%|██        | 1062/5153 [00:01<00:03, 1064.33it/s]
 23%|██▎       | 1169/5153 [00:01<00:03, 1064.73it/s]
 25%|██▍       | 1276/5153 [00:01<00:03, 1066.03it/s]
 27%|██▋       | 1383/5153 [00:01<00:03, 1066.56it/s]
 29%|██▉       | 1491/5153 [00:01<00:03, 1067.59it/s]
 31%|███       | 1598/5153 [00:01<00:03, 1067.84it/s]
 33%|███▎      | 1705/5153 [00:01<00:03, 1066.87it/s]
 35%|███▌      | 1812/5153 [00:01<00:03, 1065.10it/s]
 37%|███▋      | 1920/5153 [00:01<00:03, 1067.08it/s]
 39%|███▉      | 2027/5153 [00:01<00:02, 1067.61it/s]
 41%|████▏     | 2135/5153 [00:02<00:02, 1068.90it/s]
 44%|████▎     | 2243/5153 [00:02<00:02, 1069.22it/s]
 46%|████▌     | 2350/5153 [00:02<00:02, 1068.15it/s]
 48%|████▊     | 2457/5153 [00:02<00:02, 1068.64it/s]
 50%|████▉     | 2564/5153 [00:02<00:02, 1067.75it/s]
 52%|█████▏    | 2671/5153 [00:02<00:02, 1067.97it/s]
 54%|█████▍    | 2778/5153 [00:02<00:02, 1066.69it/s]
 56%|█████▌    | 2885/5153 [00:02<00:02, 1065.11it/s]
 58%|█████▊    | 2992/5153 [00:02<00:02, 1064.62it/s]
 60%|██████    | 3099/5153 [00:02<00:01, 1065.06it/s]
 62%|██████▏   | 3206/5153 [00:03<00:01, 1065.19it/s]
 64%|██████▍   | 3313/5153 [00:03<00:01, 1065.60it/s]
 66%|██████▋   | 3420/5153 [00:03<00:01, 1066.09it/s]
 68%|██████▊   | 3527/5153 [00:03<00:01, 1066.10it/s]
 71%|███████   | 3634/5153 [00:03<00:01, 1066.97it/s]
 73%|███████▎  | 3741/5153 [00:03<00:01, 1067.01it/s]
 75%|███████▍  | 3848/5153 [00:03<00:01, 1066.38it/s]
 77%|███████▋  | 3955/5153 [00:03<00:01, 1064.35it/s]
 79%|███████▉  | 4062/5153 [00:03<00:01, 1064.06it/s]
 81%|████████  | 4169/5153 [00:03<00:00, 1062.99it/s]
 83%|████████▎ | 4276/5153 [00:04<00:00, 1064.47it/s]
 85%|████████▌ | 4383/5153 [00:04<00:00, 1064.52it/s]
 87%|████████▋ | 4490/5153 [00:04<00:00, 1065.13it/s]
 89%|████████▉ | 4597/5153 [00:04<00:00, 1064.91it/s]
 91%|█████████▏| 4704/5153 [00:04<00:00, 1064.87it/s]
 93%|█████████▎| 4811/5153 [00:04<00:00, 1065.75it/s]
 95%|█████████▌| 4918/5153 [00:04<00:00, 1064.52it/s]
 98%|█████████▊| 5025/5153 [00:04<00:00, 1062.54it/s]
100%|█████████▉| 5132/5153 [00:04<00:00, 1062.13it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1063.97it/s]
2024-11-21:14:46:19,569 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:46:46,162 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:46,162 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:46,208 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 102/5153 [00:00<00:04, 1019.96it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1027.01it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1029.26it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1031.98it/s]
 10%|█         | 519/5153 [00:00<00:04, 1035.68it/s]
 12%|█▏        | 625/5153 [00:00<00:04, 1040.79it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1044.29it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1043.60it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1043.41it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1044.00it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1044.55it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1044.73it/s]
 26%|██▋       | 1361/5153 [00:01<00:03, 1045.16it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1045.63it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1047.52it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1047.56it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1048.72it/s]
 37%|███▋      | 1888/5153 [00:01<00:03, 1048.24it/s]
 39%|███▊      | 1993/5153 [00:01<00:03, 1047.34it/s]
 41%|████      | 2098/5153 [00:02<00:02, 1047.55it/s]
 43%|████▎     | 2203/5153 [00:02<00:02, 1046.86it/s]
 45%|████▍     | 2308/5153 [00:02<00:02, 1047.33it/s]
 47%|████▋     | 2413/5153 [00:02<00:02, 1047.93it/s]
 49%|████▉     | 2518/5153 [00:02<00:02, 1047.83it/s]
 51%|█████     | 2623/5153 [00:02<00:02, 1045.88it/s]
 53%|█████▎    | 2728/5153 [00:02<00:02, 1046.14it/s]
 55%|█████▍    | 2833/5153 [00:02<00:02, 1047.01it/s]
 57%|█████▋    | 2939/5153 [00:02<00:02, 1049.02it/s]
 59%|█████▉    | 3044/5153 [00:02<00:02, 1049.05it/s]
 61%|██████    | 3149/5153 [00:03<00:01, 1049.08it/s]
 63%|██████▎   | 3254/5153 [00:03<00:01, 1047.96it/s]
 65%|██████▌   | 3359/5153 [00:03<00:01, 1046.45it/s]
 67%|██████▋   | 3464/5153 [00:03<00:01, 1046.84it/s]
 69%|██████▉   | 3569/5153 [00:03<00:01, 1046.18it/s]
 71%|███████▏  | 3674/5153 [00:03<00:01, 1046.52it/s]
 73%|███████▎  | 3779/5153 [00:03<00:01, 1046.36it/s]
 75%|███████▌  | 3884/5153 [00:03<00:01, 1045.40it/s]
 77%|███████▋  | 3989/5153 [00:03<00:01, 1045.93it/s]
 79%|███████▉  | 4095/5153 [00:03<00:01, 1047.71it/s]
 82%|████████▏ | 4201/5153 [00:04<00:00, 1050.26it/s]
 84%|████████▎ | 4307/5153 [00:04<00:00, 1050.73it/s]
 86%|████████▌ | 4413/5153 [00:04<00:00, 1051.03it/s]
 88%|████████▊ | 4519/5153 [00:04<00:00, 1051.25it/s]
 90%|████████▉ | 4625/5153 [00:04<00:00, 1048.40it/s]
 92%|█████████▏| 4730/5153 [00:04<00:00, 1046.98it/s]
 94%|█████████▍| 4835/5153 [00:04<00:00, 1046.82it/s]
 96%|█████████▌| 4940/5153 [00:04<00:00, 1045.97it/s]
 98%|█████████▊| 5045/5153 [00:04<00:00, 1046.00it/s]
100%|█████████▉| 5150/5153 [00:04<00:00, 1046.95it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1045.83it/s]
2024-11-21:14:46:51,177 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
2024-11-21:14:47:17,046 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:17,046 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:17,091 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.95it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1032.27it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1036.65it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1038.35it/s]
 10%|█         | 521/5153 [00:00<00:04, 1038.67it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1042.09it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1044.56it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1046.59it/s]
 18%|█▊        | 943/5153 [00:00<00:04, 1048.14it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1047.76it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1049.94it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1051.30it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1051.44it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1052.07it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1051.84it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1051.34it/s]
 35%|███▍      | 1790/5153 [00:01<00:03, 1051.07it/s]
 37%|███▋      | 1896/5153 [00:01<00:03, 1051.35it/s]
 39%|███▉      | 2002/5153 [00:01<00:02, 1051.12it/s]
 41%|████      | 2108/5153 [00:02<00:02, 1050.61it/s]
 43%|████▎     | 2214/5153 [00:02<00:02, 1050.31it/s]
 45%|████▌     | 2320/5153 [00:02<00:02, 1050.60it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1052.58it/s]
 49%|████▉     | 2532/5153 [00:02<00:02, 1053.79it/s]
 51%|█████     | 2638/5153 [00:02<00:02, 1053.78it/s]
 53%|█████▎    | 2744/5153 [00:02<00:02, 1054.21it/s]
 55%|█████▌    | 2850/5153 [00:02<00:02, 1053.21it/s]
 57%|█████▋    | 2956/5153 [00:02<00:02, 1053.77it/s]
 59%|█████▉    | 3062/5153 [00:02<00:01, 1053.40it/s]
 61%|██████▏   | 3168/5153 [00:03<00:01, 1054.44it/s]
 64%|██████▎   | 3274/5153 [00:03<00:01, 1054.54it/s]
 66%|██████▌   | 3380/5153 [00:03<00:01, 1053.17it/s]
 68%|██████▊   | 3486/5153 [00:03<00:01, 1054.10it/s]
 70%|██████▉   | 3592/5153 [00:03<00:01, 1054.61it/s]
 72%|███████▏  | 3698/5153 [00:03<00:01, 1054.24it/s]
 74%|███████▍  | 3804/5153 [00:03<00:01, 1055.01it/s]
 76%|███████▌  | 3910/5153 [00:03<00:01, 1054.71it/s]
 78%|███████▊  | 4016/5153 [00:03<00:01, 1054.53it/s]
 80%|███████▉  | 4122/5153 [00:03<00:00, 1054.66it/s]
 82%|████████▏ | 4228/5153 [00:04<00:00, 1055.61it/s]
 84%|████████▍ | 4334/5153 [00:04<00:00, 1054.40it/s]
 86%|████████▌ | 4440/5153 [00:04<00:00, 1054.18it/s]
 88%|████████▊ | 4546/5153 [00:04<00:00, 1053.52it/s]
 90%|█████████ | 4652/5153 [00:04<00:00, 1051.46it/s]
 92%|█████████▏| 4758/5153 [00:04<00:00, 1051.42it/s]
 94%|█████████▍| 4864/5153 [00:04<00:00, 1050.49it/s]
 96%|█████████▋| 4970/5153 [00:04<00:00, 1050.09it/s]
 99%|█████████▊| 5076/5153 [00:04<00:00, 1050.48it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.88it/s]
2024-11-21:14:47:22,036 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:47:49,544 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:49,545 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:49,592 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1037.12it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1039.43it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1041.82it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1042.61it/s]
 10%|█         | 524/5153 [00:00<00:04, 1044.36it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1048.14it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1050.31it/s]
 16%|█▋        | 842/5153 [00:00<00:04, 1052.47it/s]
 18%|█▊        | 948/5153 [00:00<00:03, 1053.74it/s]
 20%|██        | 1054/5153 [00:01<00:03, 1053.30it/s]
 23%|██▎       | 1160/5153 [00:01<00:03, 1052.24it/s]
 25%|██▍       | 1266/5153 [00:01<00:03, 1051.22it/s]
 27%|██▋       | 1372/5153 [00:01<00:03, 1048.94it/s]
 29%|██▊       | 1477/5153 [00:01<00:03, 1047.59it/s]
 31%|███       | 1583/5153 [00:01<00:03, 1048.40it/s]
 33%|███▎      | 1689/5153 [00:01<00:03, 1049.13it/s]
 35%|███▍      | 1794/5153 [00:01<00:03, 1048.67it/s]
 37%|███▋      | 1900/5153 [00:01<00:03, 1050.72it/s]
 39%|███▉      | 2006/5153 [00:01<00:02, 1052.87it/s]
 41%|████      | 2113/5153 [00:02<00:02, 1055.73it/s]
 43%|████▎     | 2219/5153 [00:02<00:02, 1054.74it/s]
 45%|████▌     | 2325/5153 [00:02<00:02, 1053.33it/s]
 47%|████▋     | 2431/5153 [00:02<00:02, 1052.61it/s]
 49%|████▉     | 2537/5153 [00:02<00:02, 1050.10it/s]
 51%|█████▏    | 2643/5153 [00:02<00:02, 1049.72it/s]
 53%|█████▎    | 2749/5153 [00:02<00:02, 1050.60it/s]
 55%|█████▌    | 2855/5153 [00:02<00:02, 1050.98it/s]
 57%|█████▋    | 2961/5153 [00:02<00:02, 1052.01it/s]
 60%|█████▉    | 3067/5153 [00:02<00:01, 1051.87it/s]
 62%|██████▏   | 3173/5153 [00:03<00:01, 1052.62it/s]
 64%|██████▎   | 3279/5153 [00:03<00:01, 1053.24it/s]
 66%|██████▌   | 3385/5153 [00:03<00:01, 1053.95it/s]
 68%|██████▊   | 3491/5153 [00:03<00:01, 1052.47it/s]
 70%|██████▉   | 3597/5153 [00:03<00:01, 1051.40it/s]
 72%|███████▏  | 3703/5153 [00:03<00:01, 1049.83it/s]
 74%|███████▍  | 3808/5153 [00:03<00:01, 1049.85it/s]
 76%|███████▌  | 3913/5153 [00:03<00:01, 1047.43it/s]
 78%|███████▊  | 4018/5153 [00:03<00:01, 1046.90it/s]
 80%|████████  | 4123/5153 [00:03<00:00, 1045.56it/s]
 82%|████████▏ | 4229/5153 [00:04<00:00, 1046.97it/s]
 84%|████████▍ | 4334/5153 [00:04<00:00, 1047.40it/s]
 86%|████████▌ | 4440/5153 [00:04<00:00, 1049.28it/s]
 88%|████████▊ | 4546/5153 [00:04<00:00, 1050.59it/s]
 90%|█████████ | 4652/5153 [00:04<00:00, 1050.26it/s]
 92%|█████████▏| 4758/5153 [00:04<00:00, 1048.69it/s]
 94%|█████████▍| 4863/5153 [00:04<00:00, 1045.70it/s]
 96%|█████████▋| 4968/5153 [00:04<00:00, 1044.98it/s]
 98%|█████████▊| 5073/5153 [00:04<00:00, 1044.35it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.20it/s]
2024-11-21:14:47:54,546 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:48:22,011 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:22,012 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:22,058 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1025.50it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1034.11it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1036.74it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1039.57it/s]
 10%|█         | 522/5153 [00:00<00:04, 1043.24it/s]
 12%|█▏        | 628/5153 [00:00<00:04, 1048.12it/s]
 14%|█▍        | 734/5153 [00:00<00:04, 1051.37it/s]
 16%|█▋        | 840/5153 [00:00<00:04, 1051.11it/s]
 18%|█▊        | 946/5153 [00:00<00:04, 1050.97it/s]
 20%|██        | 1052/5153 [00:01<00:03, 1049.97it/s]
 22%|██▏       | 1158/5153 [00:01<00:03, 1050.39it/s]
 25%|██▍       | 1264/5153 [00:01<00:03, 1049.73it/s]
 27%|██▋       | 1370/5153 [00:01<00:03, 1051.36it/s]
 29%|██▊       | 1476/5153 [00:01<00:03, 1053.47it/s]
 31%|███       | 1582/5153 [00:01<00:03, 1054.05it/s]
 33%|███▎      | 1688/5153 [00:01<00:03, 1055.11it/s]
 35%|███▍      | 1794/5153 [00:01<00:03, 1055.70it/s]
 37%|███▋      | 1900/5153 [00:01<00:03, 1056.22it/s]
 39%|███▉      | 2006/5153 [00:01<00:02, 1055.44it/s]
 41%|████      | 2112/5153 [00:02<00:02, 1054.80it/s]
 43%|████▎     | 2218/5153 [00:02<00:02, 1053.88it/s]
 45%|████▌     | 2324/5153 [00:02<00:02, 1051.77it/s]
 47%|████▋     | 2430/5153 [00:02<00:02, 1051.78it/s]
 49%|████▉     | 2536/5153 [00:02<00:02, 1052.92it/s]
 51%|█████▏    | 2642/5153 [00:02<00:02, 1053.38it/s]
 53%|█████▎    | 2748/5153 [00:02<00:02, 1055.29it/s]
 55%|█████▌    | 2854/5153 [00:02<00:02, 1055.98it/s]
 57%|█████▋    | 2960/5153 [00:02<00:02, 1056.53it/s]
 59%|█████▉    | 3066/5153 [00:02<00:01, 1057.45it/s]
 62%|██████▏   | 3173/5153 [00:03<00:01, 1058.31it/s]
 64%|██████▎   | 3279/5153 [00:03<00:01, 1057.13it/s]
 66%|██████▌   | 3385/5153 [00:03<00:01, 1055.56it/s]
 68%|██████▊   | 3491/5153 [00:03<00:01, 1054.35it/s]
 70%|██████▉   | 3597/5153 [00:03<00:01, 1052.18it/s]
 72%|███████▏  | 3703/5153 [00:03<00:01, 1052.14it/s]
 74%|███████▍  | 3809/5153 [00:03<00:01, 1052.84it/s]
 76%|███████▌  | 3915/5153 [00:03<00:01, 1054.38it/s]
 78%|███████▊  | 4021/5153 [00:03<00:01, 1054.85it/s]
 80%|████████  | 4127/5153 [00:03<00:00, 1055.97it/s]
 82%|████████▏ | 4233/5153 [00:04<00:00, 1056.72it/s]
 84%|████████▍ | 4339/5153 [00:04<00:00, 1054.91it/s]
 86%|████████▋ | 4445/5153 [00:04<00:00, 1055.10it/s]
 88%|████████▊ | 4551/5153 [00:04<00:00, 1054.18it/s]
 90%|█████████ | 4657/5153 [00:04<00:00, 1052.35it/s]
 92%|█████████▏| 4763/5153 [00:04<00:00, 1050.45it/s]
 94%|█████████▍| 4869/5153 [00:04<00:00, 1048.72it/s]
 97%|█████████▋| 4974/5153 [00:04<00:00, 1048.39it/s]
 99%|█████████▊| 5079/5153 [00:04<00:00, 1048.72it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1052.12it/s]
2024-11-21:14:48:26,999 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:48:55,071 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:55,071 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:55,116 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.67it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1033.36it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1035.87it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1036.99it/s]
 10%|█         | 519/5153 [00:00<00:04, 1036.74it/s]
 12%|█▏        | 625/5153 [00:00<00:04, 1042.05it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1044.78it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1045.21it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1046.10it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1046.66it/s]
 22%|██▏       | 1152/5153 [00:01<00:03, 1047.90it/s]
 24%|██▍       | 1258/5153 [00:01<00:03, 1049.89it/s]
 26%|██▋       | 1363/5153 [00:01<00:03, 1049.50it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1050.36it/s]
 31%|███       | 1575/5153 [00:01<00:03, 1049.85it/s]
 33%|███▎      | 1680/5153 [00:01<00:03, 1049.85it/s]
 35%|███▍      | 1786/5153 [00:01<00:03, 1050.17it/s]
 37%|███▋      | 1892/5153 [00:01<00:03, 1049.95it/s]
 39%|███▉      | 1998/5153 [00:01<00:03, 1050.21it/s]
 41%|████      | 2104/5153 [00:02<00:02, 1050.09it/s]
 43%|████▎     | 2210/5153 [00:02<00:02, 1050.63it/s]
 45%|████▍     | 2316/5153 [00:02<00:02, 1048.85it/s]
 47%|████▋     | 2422/5153 [00:02<00:02, 1049.24it/s]
 49%|████▉     | 2527/5153 [00:02<00:02, 1049.31it/s]
 51%|█████     | 2632/5153 [00:02<00:02, 1048.90it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1048.60it/s]
 55%|█████▌    | 2842/5153 [00:02<00:02, 1048.35it/s]
 57%|█████▋    | 2947/5153 [00:02<00:02, 1047.08it/s]
 59%|█████▉    | 3052/5153 [00:02<00:02, 1047.37it/s]
 61%|██████▏   | 3157/5153 [00:03<00:01, 1047.56it/s]
 63%|██████▎   | 3262/5153 [00:03<00:01, 1046.76it/s]
 65%|██████▌   | 3367/5153 [00:03<00:01, 1046.31it/s]
 67%|██████▋   | 3473/5153 [00:03<00:01, 1047.60it/s]
 69%|██████▉   | 3579/5153 [00:03<00:01, 1048.94it/s]
 71%|███████▏  | 3684/5153 [00:03<00:01, 1048.32it/s]
 74%|███████▎  | 3790/5153 [00:03<00:01, 1050.49it/s]
 76%|███████▌  | 3896/5153 [00:03<00:01, 1051.80it/s]
 78%|███████▊  | 4002/5153 [00:03<00:01, 1050.86it/s]
 80%|███████▉  | 4108/5153 [00:03<00:00, 1051.05it/s]
 82%|████████▏ | 4214/5153 [00:04<00:00, 1050.65it/s]
 84%|████████▍ | 4320/5153 [00:04<00:00, 1049.31it/s]
 86%|████████▌ | 4425/5153 [00:04<00:00, 1048.80it/s]
 88%|████████▊ | 4530/5153 [00:04<00:00, 1048.47it/s]
 90%|████████▉ | 4635/5153 [00:04<00:00, 1048.17it/s]
 92%|█████████▏| 4740/5153 [00:04<00:00, 1048.54it/s]
 94%|█████████▍| 4845/5153 [00:04<00:00, 1047.01it/s]
 96%|█████████▌| 4951/5153 [00:04<00:00, 1048.52it/s]
 98%|█████████▊| 5056/5153 [00:04<00:00, 1048.74it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.82it/s]
2024-11-21:14:49:00,077 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:49:27,911 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:27,912 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:27,956 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 102/5153 [00:00<00:04, 1019.75it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1026.96it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1031.27it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1035.10it/s]
 10%|█         | 519/5153 [00:00<00:04, 1034.64it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1039.28it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1042.30it/s]
 16%|█▌        | 834/5153 [00:00<00:04, 1041.17it/s]
 18%|█▊        | 939/5153 [00:00<00:04, 1040.41it/s]
 20%|██        | 1044/5153 [00:01<00:03, 1042.08it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1045.86it/s]
 24%|██▍       | 1255/5153 [00:01<00:03, 1045.62it/s]
 26%|██▋       | 1360/5153 [00:01<00:03, 1044.24it/s]
 28%|██▊       | 1465/5153 [00:01<00:03, 1044.50it/s]
 30%|███       | 1571/5153 [00:01<00:03, 1046.34it/s]
 33%|███▎      | 1676/5153 [00:01<00:03, 1047.11it/s]
 35%|███▍      | 1781/5153 [00:01<00:03, 1047.26it/s]
 37%|███▋      | 1886/5153 [00:01<00:03, 1047.22it/s]
 39%|███▊      | 1991/5153 [00:01<00:03, 1046.29it/s]
 41%|████      | 2096/5153 [00:02<00:02, 1044.31it/s]
 43%|████▎     | 2201/5153 [00:02<00:02, 1045.81it/s]
 45%|████▍     | 2307/5153 [00:02<00:02, 1047.64it/s]
 47%|████▋     | 2413/5153 [00:02<00:02, 1048.45it/s]
 49%|████▉     | 2518/5153 [00:02<00:02, 1046.08it/s]
 51%|█████     | 2623/5153 [00:02<00:02, 1046.55it/s]
 53%|█████▎    | 2729/5153 [00:02<00:02, 1048.26it/s]
 55%|█████▍    | 2834/5153 [00:02<00:02, 1048.65it/s]
 57%|█████▋    | 2940/5153 [00:02<00:02, 1050.29it/s]
 59%|█████▉    | 3046/5153 [00:02<00:02, 1051.36it/s]
 61%|██████    | 3152/5153 [00:03<00:01, 1052.34it/s]
 63%|██████▎   | 3258/5153 [00:03<00:01, 1050.62it/s]
 65%|██████▌   | 3364/5153 [00:03<00:01, 1048.87it/s]
 67%|██████▋   | 3469/5153 [00:03<00:01, 1047.75it/s]
 69%|██████▉   | 3574/5153 [00:03<00:01, 1047.11it/s]
 71%|███████▏  | 3680/5153 [00:03<00:01, 1048.55it/s]
 73%|███████▎  | 3785/5153 [00:03<00:01, 1048.41it/s]
 75%|███████▌  | 3890/5153 [00:03<00:01, 1048.44it/s]
 78%|███████▊  | 3995/5153 [00:03<00:01, 1048.80it/s]
 80%|███████▉  | 4101/5153 [00:03<00:01, 1050.94it/s]
 82%|████████▏ | 4207/5153 [00:04<00:00, 1052.57it/s]
 84%|████████▎ | 4313/5153 [00:04<00:00, 1052.79it/s]
 86%|████████▌ | 4419/5153 [00:04<00:00, 1053.38it/s]
 88%|████████▊ | 4525/5153 [00:04<00:00, 1053.62it/s]
 90%|████████▉ | 4631/5153 [00:04<00:00, 1053.18it/s]
 92%|█████████▏| 4737/5153 [00:04<00:00, 1051.85it/s]
 94%|█████████▍| 4843/5153 [00:04<00:00, 1051.44it/s]
 96%|█████████▌| 4949/5153 [00:04<00:00, 1051.10it/s]
 98%|█████████▊| 5055/5153 [00:04<00:00, 1050.90it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.15it/s]
2024-11-21:14:49:32,919 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:50:00,333 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:00,334 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:00,378 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1038.76it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1044.67it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1047.63it/s]
  8%|▊         | 421/5153 [00:00<00:04, 1048.96it/s]
 10%|█         | 526/5153 [00:00<00:04, 1049.08it/s]
 12%|█▏        | 633/5153 [00:00<00:04, 1053.86it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1054.87it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1055.33it/s]
 18%|█▊        | 952/5153 [00:00<00:03, 1057.83it/s]
 21%|██        | 1058/5153 [00:01<00:03, 1058.25it/s]
 23%|██▎       | 1165/5153 [00:01<00:03, 1061.20it/s]
 25%|██▍       | 1273/5153 [00:01<00:03, 1064.06it/s]
 27%|██▋       | 1381/5153 [00:01<00:03, 1066.53it/s]
 29%|██▉       | 1488/5153 [00:01<00:03, 1067.44it/s]
 31%|███       | 1596/5153 [00:01<00:03, 1069.24it/s]
 33%|███▎      | 1704/5153 [00:01<00:03, 1070.02it/s]
 35%|███▌      | 1812/5153 [00:01<00:03, 1069.39it/s]
 37%|███▋      | 1919/5153 [00:01<00:03, 1066.86it/s]
 39%|███▉      | 2026/5153 [00:01<00:02, 1065.41it/s]
 41%|████▏     | 2133/5153 [00:02<00:02, 1064.75it/s]
 43%|████▎     | 2240/5153 [00:02<00:02, 1065.51it/s]
 46%|████▌     | 2347/5153 [00:02<00:02, 1065.75it/s]
 48%|████▊     | 2454/5153 [00:02<00:02, 1066.58it/s]
 50%|████▉     | 2561/5153 [00:02<00:02, 1066.34it/s]
 52%|█████▏    | 2668/5153 [00:02<00:02, 1065.79it/s]
 54%|█████▍    | 2775/5153 [00:02<00:02, 1066.99it/s]
 56%|█████▌    | 2883/5153 [00:02<00:02, 1068.70it/s]
 58%|█████▊    | 2990/5153 [00:02<00:02, 1068.08it/s]
 60%|██████    | 3097/5153 [00:02<00:01, 1067.46it/s]
 62%|██████▏   | 3204/5153 [00:03<00:01, 1065.79it/s]
 64%|██████▍   | 3311/5153 [00:03<00:01, 1064.18it/s]
 66%|██████▋   | 3418/5153 [00:03<00:01, 1064.25it/s]
 68%|██████▊   | 3525/5153 [00:03<00:01, 1063.59it/s]
 70%|███████   | 3632/5153 [00:03<00:01, 1065.26it/s]
 73%|███████▎  | 3739/5153 [00:03<00:01, 1065.53it/s]
 75%|███████▍  | 3846/5153 [00:03<00:01, 1066.51it/s]
 77%|███████▋  | 3953/5153 [00:03<00:01, 1066.82it/s]
 79%|███████▉  | 4061/5153 [00:03<00:01, 1068.41it/s]
 81%|████████  | 4169/5153 [00:03<00:00, 1069.81it/s]
 83%|████████▎ | 4277/5153 [00:04<00:00, 1070.02it/s]
 85%|████████▌ | 4385/5153 [00:04<00:00, 1068.63it/s]
 87%|████████▋ | 4492/5153 [00:04<00:00, 1068.14it/s]
 89%|████████▉ | 4599/5153 [00:04<00:00, 1067.53it/s]
 91%|█████████▏| 4706/5153 [00:04<00:00, 1066.05it/s]
 93%|█████████▎| 4813/5153 [00:04<00:00, 1064.64it/s]
 95%|█████████▌| 4920/5153 [00:04<00:00, 1063.86it/s]
 98%|█████████▊| 5027/5153 [00:04<00:00, 1062.11it/s]
100%|█████████▉| 5134/5153 [00:04<00:00, 1063.91it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1063.95it/s]
2024-11-21:14:50:05,263 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:50:31,642 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:31,642 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:31,686 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.22it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1033.70it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1038.69it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1040.95it/s]
 10%|█         | 522/5153 [00:00<00:04, 1043.34it/s]
 12%|█▏        | 628/5153 [00:00<00:04, 1048.47it/s]
 14%|█▍        | 734/5153 [00:00<00:04, 1051.57it/s]
 16%|█▋        | 840/5153 [00:00<00:04, 1053.99it/s]
 18%|█▊        | 946/5153 [00:00<00:03, 1055.40it/s]
 20%|██        | 1052/5153 [00:01<00:03, 1055.14it/s]
 22%|██▏       | 1159/5153 [00:01<00:03, 1056.99it/s]
 25%|██▍       | 1266/5153 [00:01<00:03, 1059.02it/s]
 27%|██▋       | 1372/5153 [00:01<00:03, 1058.60it/s]
 29%|██▊       | 1478/5153 [00:01<00:03, 1058.93it/s]
 31%|███       | 1584/5153 [00:01<00:03, 1059.21it/s]
 33%|███▎      | 1690/5153 [00:01<00:03, 1058.68it/s]
 35%|███▍      | 1797/5153 [00:01<00:03, 1060.59it/s]
 37%|███▋      | 1904/5153 [00:01<00:03, 1062.22it/s]
 39%|███▉      | 2011/5153 [00:01<00:02, 1063.17it/s]
 41%|████      | 2118/5153 [00:02<00:02, 1064.47it/s]
 43%|████▎     | 2225/5153 [00:02<00:02, 1063.54it/s]
 45%|████▌     | 2332/5153 [00:02<00:02, 1063.51it/s]
 47%|████▋     | 2439/5153 [00:02<00:02, 1063.49it/s]
 49%|████▉     | 2546/5153 [00:02<00:02, 1062.21it/s]
 51%|█████▏    | 2653/5153 [00:02<00:02, 1061.26it/s]
 54%|█████▎    | 2760/5153 [00:02<00:02, 1061.80it/s]
 56%|█████▌    | 2867/5153 [00:02<00:02, 1061.35it/s]
 58%|█████▊    | 2974/5153 [00:02<00:02, 1061.12it/s]
 60%|█████▉    | 3081/5153 [00:02<00:01, 1061.81it/s]
 62%|██████▏   | 3188/5153 [00:03<00:01, 1061.25it/s]
 64%|██████▍   | 3295/5153 [00:03<00:01, 1062.01it/s]
 66%|██████▌   | 3402/5153 [00:03<00:01, 1062.22it/s]
 68%|██████▊   | 3509/5153 [00:03<00:01, 1062.64it/s]
 70%|███████   | 3616/5153 [00:03<00:01, 1060.74it/s]
 72%|███████▏  | 3723/5153 [00:03<00:01, 1058.89it/s]
 74%|███████▍  | 3830/5153 [00:03<00:01, 1059.75it/s]
 76%|███████▋  | 3937/5153 [00:03<00:01, 1060.27it/s]
 78%|███████▊  | 4044/5153 [00:03<00:01, 1061.38it/s]
 81%|████████  | 4151/5153 [00:03<00:00, 1062.24it/s]
 83%|████████▎ | 4258/5153 [00:04<00:00, 1062.65it/s]
 85%|████████▍ | 4365/5153 [00:04<00:00, 1061.02it/s]
 87%|████████▋ | 4472/5153 [00:04<00:00, 1060.21it/s]
 89%|████████▉ | 4579/5153 [00:04<00:00, 1059.67it/s]
 91%|█████████ | 4685/5153 [00:04<00:00, 1059.69it/s]
 93%|█████████▎| 4791/5153 [00:04<00:00, 1059.66it/s]
 95%|█████████▌| 4897/5153 [00:04<00:00, 1058.96it/s]
 97%|█████████▋| 5003/5153 [00:04<00:00, 1058.49it/s]
 99%|█████████▉| 5109/5153 [00:04<00:00, 1058.75it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1058.51it/s]
2024-11-21:14:50:36,597 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:51:03,039 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:03,039 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:03,084 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1024.79it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1030.08it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1032.49it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1035.27it/s]
 10%|█         | 520/5153 [00:00<00:04, 1037.73it/s]
 12%|█▏        | 625/5153 [00:00<00:04, 1041.23it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1042.97it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1043.63it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1044.22it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1045.23it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1045.86it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1047.67it/s]
 26%|██▋       | 1362/5153 [00:01<00:03, 1048.93it/s]
 28%|██▊       | 1468/5153 [00:01<00:03, 1050.43it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1051.07it/s]
 33%|███▎      | 1680/5153 [00:01<00:03, 1050.99it/s]
 35%|███▍      | 1786/5153 [00:01<00:03, 1052.18it/s]
 37%|███▋      | 1892/5153 [00:01<00:03, 1051.06it/s]
 39%|███▉      | 1998/5153 [00:01<00:03, 1051.63it/s]
 41%|████      | 2104/5153 [00:02<00:02, 1051.01it/s]
 43%|████▎     | 2210/5153 [00:02<00:02, 1051.70it/s]
 45%|████▍     | 2316/5153 [00:02<00:02, 1051.01it/s]
 47%|████▋     | 2422/5153 [00:02<00:02, 1051.92it/s]
 49%|████▉     | 2528/5153 [00:02<00:02, 1053.29it/s]
 51%|█████     | 2634/5153 [00:02<00:02, 1053.35it/s]
 53%|█████▎    | 2740/5153 [00:02<00:02, 1054.36it/s]
 55%|█████▌    | 2846/5153 [00:02<00:02, 1055.19it/s]
 57%|█████▋    | 2952/5153 [00:02<00:02, 1055.40it/s]
 59%|█████▉    | 3058/5153 [00:02<00:01, 1054.59it/s]
 61%|██████▏   | 3164/5153 [00:03<00:01, 1052.40it/s]
 63%|██████▎   | 3270/5153 [00:03<00:01, 1051.12it/s]
 66%|██████▌   | 3376/5153 [00:03<00:01, 1049.48it/s]
 68%|██████▊   | 3481/5153 [00:03<00:01, 1049.04it/s]
 70%|██████▉   | 3587/5153 [00:03<00:01, 1050.36it/s]
 72%|███████▏  | 3693/5153 [00:03<00:01, 1049.81it/s]
 74%|███████▎  | 3799/5153 [00:03<00:01, 1051.71it/s]
 76%|███████▌  | 3905/5153 [00:03<00:01, 1052.15it/s]
 78%|███████▊  | 4011/5153 [00:03<00:01, 1052.67it/s]
 80%|███████▉  | 4117/5153 [00:03<00:00, 1053.73it/s]
 82%|████████▏ | 4223/5153 [00:04<00:00, 1054.45it/s]
 84%|████████▍ | 4329/5153 [00:04<00:00, 1053.48it/s]
 86%|████████▌ | 4435/5153 [00:04<00:00, 1052.10it/s]
 88%|████████▊ | 4541/5153 [00:04<00:00, 1051.79it/s]
 90%|█████████ | 4647/5153 [00:04<00:00, 1049.56it/s]
 92%|█████████▏| 4752/5153 [00:04<00:00, 1049.67it/s]
 94%|█████████▍| 4857/5153 [00:04<00:00, 1049.24it/s]
 96%|█████████▋| 4962/5153 [00:04<00:00, 1049.19it/s]
 98%|█████████▊| 5067/5153 [00:04<00:00, 1049.24it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.31it/s]
2024-11-21:14:51:08,038 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:51:34,157 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:34,157 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:34,203 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1033.11it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1041.17it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1047.38it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1048.02it/s]
 10%|█         | 525/5153 [00:00<00:04, 1046.47it/s]
 12%|█▏        | 631/5153 [00:00<00:04, 1049.39it/s]
 14%|█▍        | 737/5153 [00:00<00:04, 1051.83it/s]
 16%|█▋        | 843/5153 [00:00<00:04, 1052.70it/s]
 18%|█▊        | 949/5153 [00:00<00:03, 1053.92it/s]
 20%|██        | 1055/5153 [00:01<00:03, 1055.09it/s]
 23%|██▎       | 1162/5153 [00:01<00:03, 1057.11it/s]
 25%|██▍       | 1268/5153 [00:01<00:03, 1057.61it/s]
 27%|██▋       | 1375/5153 [00:01<00:03, 1059.57it/s]
 29%|██▉       | 1482/5153 [00:01<00:03, 1059.77it/s]
 31%|███       | 1588/5153 [00:01<00:03, 1059.10it/s]
 33%|███▎      | 1694/5153 [00:01<00:03, 1057.31it/s]
 35%|███▍      | 1800/5153 [00:01<00:03, 1056.96it/s]
 37%|███▋      | 1906/5153 [00:01<00:03, 1056.98it/s]
 39%|███▉      | 2012/5153 [00:01<00:02, 1056.42it/s]
 41%|████      | 2119/5153 [00:02<00:02, 1058.33it/s]
 43%|████▎     | 2225/5153 [00:02<00:02, 1058.67it/s]
 45%|████▌     | 2332/5153 [00:02<00:02, 1059.21it/s]
 47%|████▋     | 2439/5153 [00:02<00:02, 1059.57it/s]
 49%|████▉     | 2546/5153 [00:02<00:02, 1060.96it/s]
 51%|█████▏    | 2653/5153 [00:02<00:02, 1062.19it/s]
 54%|█████▎    | 2760/5153 [00:02<00:02, 1061.90it/s]
 56%|█████▌    | 2867/5153 [00:02<00:02, 1060.01it/s]
 58%|█████▊    | 2974/5153 [00:02<00:02, 1057.83it/s]
 60%|█████▉    | 3080/5153 [00:02<00:01, 1057.81it/s]
 62%|██████▏   | 3186/5153 [00:03<00:01, 1056.56it/s]
 64%|██████▍   | 3292/5153 [00:03<00:01, 1056.44it/s]
 66%|██████▌   | 3398/5153 [00:03<00:01, 1056.51it/s]
 68%|██████▊   | 3505/5153 [00:03<00:01, 1057.80it/s]
 70%|███████   | 3612/5153 [00:03<00:01, 1058.51it/s]
 72%|███████▏  | 3719/5153 [00:03<00:01, 1060.38it/s]
 74%|███████▍  | 3826/5153 [00:03<00:01, 1061.47it/s]
 76%|███████▋  | 3933/5153 [00:03<00:01, 1061.43it/s]
 78%|███████▊  | 4040/5153 [00:03<00:01, 1061.44it/s]
 80%|████████  | 4147/5153 [00:03<00:00, 1061.22it/s]
 83%|████████▎ | 4254/5153 [00:04<00:00, 1060.85it/s]
 85%|████████▍ | 4361/5153 [00:04<00:00, 1058.64it/s]
 87%|████████▋ | 4467/5153 [00:04<00:00, 1058.51it/s]
 89%|████████▊ | 4573/5153 [00:04<00:00, 1057.25it/s]
 91%|█████████ | 4679/5153 [00:04<00:00, 1056.50it/s]
 93%|█████████▎| 4785/5153 [00:04<00:00, 1057.38it/s]
 95%|█████████▍| 4891/5153 [00:04<00:00, 1057.63it/s]
 97%|█████████▋| 4998/5153 [00:04<00:00, 1058.52it/s]
 99%|█████████▉| 5105/5153 [00:04<00:00, 1059.74it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1057.32it/s]
2024-11-21:14:51:39,119 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:52:06,495 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:06,495 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:06,538 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.47it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.10it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1032.32it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1034.99it/s]
 10%|█         | 520/5153 [00:00<00:04, 1037.46it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1042.76it/s]
 14%|█▍        | 732/5153 [00:00<00:04, 1045.92it/s]
 16%|█▋        | 838/5153 [00:00<00:04, 1047.39it/s]
 18%|█▊        | 943/5153 [00:00<00:04, 1046.69it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1046.13it/s]
 22%|██▏       | 1153/5153 [00:01<00:03, 1047.14it/s]
 24%|██▍       | 1259/5153 [00:01<00:03, 1048.34it/s]
 26%|██▋       | 1364/5153 [00:01<00:03, 1047.08it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1047.07it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1047.22it/s]
 33%|███▎      | 1679/5153 [00:01<00:03, 1046.98it/s]
 35%|███▍      | 1785/5153 [00:01<00:03, 1048.47it/s]
 37%|███▋      | 1891/5153 [00:01<00:03, 1049.52it/s]
 39%|███▉      | 1997/5153 [00:01<00:03, 1050.38it/s]
 41%|████      | 2103/5153 [00:02<00:02, 1050.01it/s]
 43%|████▎     | 2209/5153 [00:02<00:02, 1049.36it/s]
 45%|████▍     | 2315/5153 [00:02<00:02, 1049.73it/s]
 47%|████▋     | 2421/5153 [00:02<00:02, 1050.12it/s]
 49%|████▉     | 2527/5153 [00:02<00:02, 1048.39it/s]
 51%|█████     | 2632/5153 [00:02<00:02, 1047.71it/s]
 53%|█████▎    | 2738/5153 [00:02<00:02, 1049.60it/s]
 55%|█████▌    | 2844/5153 [00:02<00:02, 1051.15it/s]
 57%|█████▋    | 2950/5153 [00:02<00:02, 1051.57it/s]
 59%|█████▉    | 3057/5153 [00:02<00:01, 1054.15it/s]
 61%|██████▏   | 3163/5153 [00:03<00:01, 1054.36it/s]
 63%|██████▎   | 3269/5153 [00:03<00:01, 1055.96it/s]
 65%|██████▌   | 3375/5153 [00:03<00:01, 1055.16it/s]
 68%|██████▊   | 3481/5153 [00:03<00:01, 1054.63it/s]
 70%|██████▉   | 3587/5153 [00:03<00:01, 1053.26it/s]
 72%|███████▏  | 3693/5153 [00:03<00:01, 1050.95it/s]
 74%|███████▎  | 3799/5153 [00:03<00:01, 1051.08it/s]
 76%|███████▌  | 3905/5153 [00:03<00:01, 1049.63it/s]
 78%|███████▊  | 4011/5153 [00:03<00:01, 1050.69it/s]
 80%|███████▉  | 4117/5153 [00:03<00:00, 1052.47it/s]
 82%|████████▏ | 4223/5153 [00:04<00:00, 1053.40it/s]
 84%|████████▍ | 4329/5153 [00:04<00:00, 1055.28it/s]
 86%|████████▌ | 4435/5153 [00:04<00:00, 1055.64it/s]
 88%|████████▊ | 4541/5153 [00:04<00:00, 1055.70it/s]
 90%|█████████ | 4647/5153 [00:04<00:00, 1053.54it/s]
 92%|█████████▏| 4753/5153 [00:04<00:00, 1052.39it/s]
 94%|█████████▍| 4859/5153 [00:04<00:00, 1051.22it/s]
 96%|█████████▋| 4965/5153 [00:04<00:00, 1049.42it/s]
 98%|█████████▊| 5070/5153 [00:04<00:00, 1049.29it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.27it/s]
2024-11-21:14:52:11,491 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:52:38,632 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:38,633 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:38,678 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1035.79it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1037.99it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1042.04it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1044.35it/s]
 10%|█         | 523/5153 [00:00<00:04, 1043.45it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1046.27it/s]
 14%|█▍        | 735/5153 [00:00<00:04, 1048.47it/s]
 16%|█▋        | 841/5153 [00:00<00:04, 1050.83it/s]
 18%|█▊        | 947/5153 [00:00<00:03, 1051.58it/s]
 20%|██        | 1053/5153 [00:01<00:03, 1051.72it/s]
 22%|██▏       | 1159/5153 [00:01<00:03, 1053.39it/s]
 25%|██▍       | 1265/5153 [00:01<00:03, 1054.42it/s]
 27%|██▋       | 1371/5153 [00:01<00:03, 1054.16it/s]
 29%|██▊       | 1477/5153 [00:01<00:03, 1054.38it/s]
 31%|███       | 1583/5153 [00:01<00:03, 1053.75it/s]
 33%|███▎      | 1689/5153 [00:01<00:03, 1053.36it/s]
 35%|███▍      | 1795/5153 [00:01<00:03, 1053.95it/s]
 37%|███▋      | 1901/5153 [00:01<00:03, 1055.54it/s]
 39%|███▉      | 2007/5153 [00:01<00:02, 1056.36it/s]
 41%|████      | 2113/5153 [00:02<00:02, 1056.41it/s]
 43%|████▎     | 2219/5153 [00:02<00:02, 1055.73it/s]
 45%|████▌     | 2325/5153 [00:02<00:02, 1054.67it/s]
 47%|████▋     | 2431/5153 [00:02<00:02, 1055.10it/s]
 49%|████▉     | 2537/5153 [00:02<00:02, 1054.84it/s]
 51%|█████▏    | 2643/5153 [00:02<00:02, 1056.00it/s]
 53%|█████▎    | 2749/5153 [00:02<00:02, 1056.87it/s]
 55%|█████▌    | 2855/5153 [00:02<00:02, 1056.32it/s]
 57%|█████▋    | 2961/5153 [00:02<00:02, 1055.69it/s]
 60%|█████▉    | 3067/5153 [00:02<00:01, 1054.74it/s]
 62%|██████▏   | 3173/5153 [00:03<00:01, 1055.59it/s]
 64%|██████▎   | 3279/5153 [00:03<00:01, 1054.97it/s]
 66%|██████▌   | 3385/5153 [00:03<00:01, 1055.64it/s]
 68%|██████▊   | 3491/5153 [00:03<00:01, 1055.20it/s]
 70%|██████▉   | 3597/5153 [00:03<00:01, 1054.13it/s]
 72%|███████▏  | 3703/5153 [00:03<00:01, 1053.70it/s]
 74%|███████▍  | 3809/5153 [00:03<00:01, 1054.54it/s]
 76%|███████▌  | 3916/5153 [00:03<00:01, 1057.34it/s]
 78%|███████▊  | 4022/5153 [00:03<00:01, 1056.74it/s]
 80%|████████  | 4128/5153 [00:03<00:00, 1056.91it/s]
 82%|████████▏ | 4234/5153 [00:04<00:00, 1056.79it/s]
 84%|████████▍ | 4340/5153 [00:04<00:00, 1055.50it/s]
 86%|████████▋ | 4446/5153 [00:04<00:00, 1056.20it/s]
 88%|████████▊ | 4552/5153 [00:04<00:00, 1055.74it/s]
 90%|█████████ | 4658/5153 [00:04<00:00, 1056.02it/s]
 92%|█████████▏| 4764/5153 [00:04<00:00, 1056.50it/s]
 95%|█████████▍| 4870/5153 [00:04<00:00, 1055.31it/s]
 97%|█████████▋| 4976/5153 [00:04<00:00, 1055.35it/s]
 99%|█████████▊| 5082/5153 [00:04<00:00, 1056.29it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.05it/s]
2024-11-21:14:52:43,609 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:53:11,036 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:11,036 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:11,081 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1038.92it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1038.03it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1041.50it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1044.14it/s]
 10%|█         | 523/5153 [00:00<00:04, 1044.88it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1048.07it/s]
 14%|█▍        | 735/5153 [00:00<00:04, 1051.57it/s]
 16%|█▋        | 841/5153 [00:00<00:04, 1053.20it/s]
 18%|█▊        | 948/5153 [00:00<00:03, 1056.43it/s]
 20%|██        | 1054/5153 [00:01<00:03, 1056.90it/s]
 23%|██▎       | 1161/5153 [00:01<00:03, 1058.05it/s]
 25%|██▍       | 1267/5153 [00:01<00:03, 1058.59it/s]
 27%|██▋       | 1374/5153 [00:01<00:03, 1059.15it/s]
 29%|██▊       | 1480/5153 [00:01<00:03, 1057.97it/s]
 31%|███       | 1586/5153 [00:01<00:03, 1057.82it/s]
 33%|███▎      | 1693/5153 [00:01<00:03, 1058.24it/s]
 35%|███▍      | 1800/5153 [00:01<00:03, 1059.22it/s]
 37%|███▋      | 1907/5153 [00:01<00:03, 1060.57it/s]
 39%|███▉      | 2014/5153 [00:01<00:02, 1061.39it/s]
 41%|████      | 2121/5153 [00:02<00:02, 1063.00it/s]
 43%|████▎     | 2228/5153 [00:02<00:02, 1064.17it/s]
 45%|████▌     | 2335/5153 [00:02<00:02, 1064.18it/s]
 47%|████▋     | 2442/5153 [00:02<00:02, 1064.33it/s]
 49%|████▉     | 2549/5153 [00:02<00:02, 1064.23it/s]
 52%|█████▏    | 2656/5153 [00:02<00:02, 1063.54it/s]
 54%|█████▎    | 2763/5153 [00:02<00:02, 1065.15it/s]
 56%|█████▌    | 2870/5153 [00:02<00:02, 1062.43it/s]
 58%|█████▊    | 2977/5153 [00:02<00:02, 1062.57it/s]
 60%|█████▉    | 3084/5153 [00:02<00:01, 1063.16it/s]
 62%|██████▏   | 3191/5153 [00:03<00:01, 1063.00it/s]
 64%|██████▍   | 3298/5153 [00:03<00:01, 1064.52it/s]
 66%|██████▌   | 3406/5153 [00:03<00:01, 1066.27it/s]
 68%|██████▊   | 3514/5153 [00:03<00:01, 1067.87it/s]
 70%|███████   | 3621/5153 [00:03<00:01, 1065.75it/s]
 72%|███████▏  | 3728/5153 [00:03<00:01, 1061.81it/s]
 74%|███████▍  | 3835/5153 [00:03<00:01, 1061.29it/s]
 76%|███████▋  | 3942/5153 [00:03<00:01, 1061.39it/s]
 79%|███████▊  | 4049/5153 [00:03<00:01, 1060.46it/s]
 81%|████████  | 4156/5153 [00:03<00:00, 1061.35it/s]
 83%|████████▎ | 4263/5153 [00:04<00:00, 1061.34it/s]
 85%|████████▍ | 4370/5153 [00:04<00:00, 1060.65it/s]
 87%|████████▋ | 4477/5153 [00:04<00:00, 1061.05it/s]
 89%|████████▉ | 4584/5153 [00:04<00:00, 1062.10it/s]
 91%|█████████ | 4691/5153 [00:04<00:00, 1062.81it/s]
 93%|█████████▎| 4798/5153 [00:04<00:00, 1062.53it/s]
 95%|█████████▌| 4905/5153 [00:04<00:00, 1060.24it/s]
 97%|█████████▋| 5012/5153 [00:04<00:00, 1058.33it/s]
 99%|█████████▉| 5119/5153 [00:04<00:00, 1059.29it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1059.55it/s]
2024-11-21:14:53:15,986 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:53:43,307 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:43,307 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:43,353 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1030.77it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1032.25it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1034.95it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1038.23it/s]
 10%|█         | 522/5153 [00:00<00:04, 1039.76it/s]
 12%|█▏        | 628/5153 [00:00<00:04, 1045.55it/s]
 14%|█▍        | 734/5153 [00:00<00:04, 1049.35it/s]
 16%|█▋        | 840/5153 [00:00<00:04, 1049.81it/s]
 18%|█▊        | 946/5153 [00:00<00:04, 1050.49it/s]
 20%|██        | 1052/5153 [00:01<00:03, 1050.94it/s]
 22%|██▏       | 1158/5153 [00:01<00:03, 1052.85it/s]
 25%|██▍       | 1264/5153 [00:01<00:03, 1054.29it/s]
 27%|██▋       | 1370/5153 [00:01<00:03, 1053.09it/s]
 29%|██▊       | 1476/5153 [00:01<00:03, 1054.26it/s]
 31%|███       | 1582/5153 [00:01<00:03, 1054.57it/s]
 33%|███▎      | 1689/5153 [00:01<00:03, 1056.28it/s]
 35%|███▍      | 1796/5153 [00:01<00:03, 1058.24it/s]
 37%|███▋      | 1902/5153 [00:01<00:03, 1058.19it/s]
 39%|███▉      | 2008/5153 [00:01<00:02, 1057.34it/s]
 41%|████      | 2114/5153 [00:02<00:02, 1056.31it/s]
 43%|████▎     | 2220/5153 [00:02<00:02, 1056.59it/s]
 45%|████▌     | 2326/5153 [00:02<00:02, 1056.32it/s]
 47%|████▋     | 2433/5153 [00:02<00:02, 1058.24it/s]
 49%|████▉     | 2539/5153 [00:02<00:02, 1056.12it/s]
 51%|█████▏    | 2645/5153 [00:02<00:02, 1056.07it/s]
 53%|█████▎    | 2752/5153 [00:02<00:02, 1057.37it/s]
 55%|█████▌    | 2859/5153 [00:02<00:02, 1059.25it/s]
 58%|█████▊    | 2965/5153 [00:02<00:02, 1059.27it/s]
 60%|█████▉    | 3072/5153 [00:02<00:01, 1060.05it/s]
 62%|██████▏   | 3179/5153 [00:03<00:01, 1059.48it/s]
 64%|██████▎   | 3285/5153 [00:03<00:01, 1059.61it/s]
 66%|██████▌   | 3392/5153 [00:03<00:01, 1060.64it/s]
 68%|██████▊   | 3499/5153 [00:03<00:01, 1059.78it/s]
 70%|██████▉   | 3606/5153 [00:03<00:01, 1060.12it/s]
 72%|███████▏  | 3713/5153 [00:03<00:01, 1057.04it/s]
 74%|███████▍  | 3820/5153 [00:03<00:01, 1057.97it/s]
 76%|███████▌  | 3926/5153 [00:03<00:01, 1056.70it/s]
 78%|███████▊  | 4032/5153 [00:03<00:01, 1056.11it/s]
 80%|████████  | 4139/5153 [00:03<00:00, 1057.50it/s]
 82%|████████▏ | 4245/5153 [00:04<00:00, 1057.70it/s]
 84%|████████▍ | 4351/5153 [00:04<00:00, 1058.33it/s]
 86%|████████▋ | 4457/5153 [00:04<00:00, 1058.04it/s]
 89%|████████▊ | 4563/5153 [00:04<00:00, 1058.19it/s]
 91%|█████████ | 4669/5153 [00:04<00:00, 1058.55it/s]
 93%|█████████▎| 4775/5153 [00:04<00:00, 1058.53it/s]
 95%|█████████▍| 4881/5153 [00:04<00:00, 1057.46it/s]
 97%|█████████▋| 4987/5153 [00:04<00:00, 1056.19it/s]
 99%|█████████▉| 5093/5153 [00:04<00:00, 1056.38it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1055.12it/s]
2024-11-21:14:53:48,280 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:54:15,227 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:15,227 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:15,271 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.80it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1032.45it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1035.47it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1040.14it/s]
 10%|█         | 521/5153 [00:00<00:04, 1042.86it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1048.20it/s]
 14%|█▍        | 733/5153 [00:00<00:04, 1051.72it/s]
 16%|█▋        | 839/5153 [00:00<00:04, 1053.12it/s]
 18%|█▊        | 945/5153 [00:00<00:03, 1054.24it/s]
 20%|██        | 1051/5153 [00:01<00:03, 1053.97it/s]
 22%|██▏       | 1157/5153 [00:01<00:03, 1054.96it/s]
 25%|██▍       | 1263/5153 [00:01<00:03, 1056.43it/s]
 27%|██▋       | 1370/5153 [00:01<00:03, 1058.16it/s]
 29%|██▊       | 1477/5153 [00:01<00:03, 1058.60it/s]
 31%|███       | 1584/5153 [00:01<00:03, 1059.60it/s]
 33%|███▎      | 1691/5153 [00:01<00:03, 1059.73it/s]
 35%|███▍      | 1797/5153 [00:01<00:03, 1059.32it/s]
 37%|███▋      | 1903/5153 [00:01<00:03, 1059.37it/s]
 39%|███▉      | 2009/5153 [00:01<00:02, 1059.42it/s]
 41%|████      | 2116/5153 [00:02<00:02, 1060.38it/s]
 43%|████▎     | 2223/5153 [00:02<00:02, 1060.24it/s]
 45%|████▌     | 2330/5153 [00:02<00:02, 1058.95it/s]
 47%|████▋     | 2436/5153 [00:02<00:02, 1058.66it/s]
 49%|████▉     | 2542/5153 [00:02<00:02, 1058.91it/s]
 51%|█████▏    | 2648/5153 [00:02<00:02, 1058.81it/s]
 53%|█████▎    | 2755/5153 [00:02<00:02, 1059.67it/s]
 56%|█████▌    | 2862/5153 [00:02<00:02, 1060.33it/s]
 58%|█████▊    | 2969/5153 [00:02<00:02, 1059.35it/s]
 60%|█████▉    | 3075/5153 [00:02<00:01, 1058.40it/s]
 62%|██████▏   | 3181/5153 [00:03<00:01, 1058.16it/s]
 64%|██████▍   | 3287/5153 [00:03<00:01, 1057.38it/s]
 66%|██████▌   | 3393/5153 [00:03<00:01, 1057.51it/s]
 68%|██████▊   | 3499/5153 [00:03<00:01, 1056.56it/s]
 70%|██████▉   | 3605/5153 [00:03<00:01, 1057.06it/s]
 72%|███████▏  | 3711/5153 [00:03<00:01, 1057.19it/s]
 74%|███████▍  | 3817/5153 [00:03<00:01, 1057.51it/s]
 76%|███████▌  | 3923/5153 [00:03<00:01, 1057.87it/s]
 78%|███████▊  | 4030/5153 [00:03<00:01, 1059.02it/s]
 80%|████████  | 4137/5153 [00:03<00:00, 1061.86it/s]
 82%|████████▏ | 4244/5153 [00:04<00:00, 1061.33it/s]
 84%|████████▍ | 4351/5153 [00:04<00:00, 1059.10it/s]
 86%|████████▋ | 4457/5153 [00:04<00:00, 1058.69it/s]
 89%|████████▊ | 4563/5153 [00:04<00:00, 1058.57it/s]
 91%|█████████ | 4669/5153 [00:04<00:00, 1057.04it/s]
 93%|█████████▎| 4775/5153 [00:04<00:00, 1056.51it/s]
 95%|█████████▍| 4881/5153 [00:04<00:00, 1056.04it/s]
 97%|█████████▋| 4987/5153 [00:04<00:00, 1055.58it/s]
 99%|█████████▉| 5093/5153 [00:04<00:00, 1056.63it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1056.33it/s]
2024-11-21:14:54:20,193 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:54:47,128 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:47,128 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:47,173 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.89it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1034.55it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1035.90it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1038.05it/s]
 10%|█         | 520/5153 [00:00<00:04, 1038.46it/s]
 12%|█▏        | 625/5153 [00:00<00:04, 1041.52it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1044.72it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1046.89it/s]
 18%|█▊        | 943/5153 [00:00<00:04, 1049.37it/s]
 20%|██        | 1049/5153 [00:01<00:03, 1051.48it/s]
 22%|██▏       | 1155/5153 [00:01<00:03, 1053.71it/s]
 24%|██▍       | 1261/5153 [00:01<00:03, 1052.63it/s]
 27%|██▋       | 1367/5153 [00:01<00:03, 1052.66it/s]
 29%|██▊       | 1473/5153 [00:01<00:03, 1052.21it/s]
 31%|███       | 1579/5153 [00:01<00:03, 1051.72it/s]
 33%|███▎      | 1685/5153 [00:01<00:03, 1050.27it/s]
 35%|███▍      | 1791/5153 [00:01<00:03, 1049.41it/s]
 37%|███▋      | 1896/5153 [00:01<00:03, 1049.54it/s]
 39%|███▉      | 2002/5153 [00:01<00:02, 1052.21it/s]
 41%|████      | 2108/5153 [00:02<00:02, 1053.60it/s]
 43%|████▎     | 2214/5153 [00:02<00:02, 1053.20it/s]
 45%|████▌     | 2320/5153 [00:02<00:02, 1052.59it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1053.73it/s]
 49%|████▉     | 2532/5153 [00:02<00:02, 1051.71it/s]
 51%|█████     | 2638/5153 [00:02<00:02, 1051.68it/s]
 53%|█████▎    | 2744/5153 [00:02<00:02, 1052.25it/s]
 55%|█████▌    | 2850/5153 [00:02<00:02, 1051.14it/s]
 57%|█████▋    | 2956/5153 [00:02<00:02, 1051.29it/s]
 59%|█████▉    | 3062/5153 [00:02<00:01, 1050.44it/s]
 61%|██████▏   | 3168/5153 [00:03<00:01, 1051.47it/s]
 64%|██████▎   | 3274/5153 [00:03<00:01, 1052.45it/s]
 66%|██████▌   | 3380/5153 [00:03<00:01, 1053.16it/s]
 68%|██████▊   | 3486/5153 [00:03<00:01, 1054.87it/s]
 70%|██████▉   | 3592/5153 [00:03<00:01, 1055.46it/s]
 72%|███████▏  | 3698/5153 [00:03<00:01, 1052.74it/s]
 74%|███████▍  | 3804/5153 [00:03<00:01, 1053.38it/s]
 76%|███████▌  | 3910/5153 [00:03<00:01, 1052.52it/s]
 78%|███████▊  | 4016/5153 [00:03<00:01, 1051.25it/s]
 80%|███████▉  | 4122/5153 [00:03<00:00, 1050.80it/s]
 82%|████████▏ | 4228/5153 [00:04<00:00, 1051.30it/s]
 84%|████████▍ | 4334/5153 [00:04<00:00, 1050.59it/s]
 86%|████████▌ | 4440/5153 [00:04<00:00, 1051.29it/s]
 88%|████████▊ | 4546/5153 [00:04<00:00, 1053.42it/s]
 90%|█████████ | 4652/5153 [00:04<00:00, 1051.51it/s]
 92%|█████████▏| 4758/5153 [00:04<00:00, 1050.89it/s]
 94%|█████████▍| 4864/5153 [00:04<00:00, 1048.50it/s]
 96%|█████████▋| 4969/5153 [00:04<00:00, 1048.62it/s]
 98%|█████████▊| 5074/5153 [00:04<00:00, 1047.86it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.01it/s]
2024-11-21:14:54:52,122 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:55:18,420 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:18,420 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:18,464 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1021.10it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1024.94it/s]
  6%|▌         | 309/5153 [00:00<00:04, 1025.93it/s]
  8%|▊         | 412/5153 [00:00<00:04, 1027.51it/s]
 10%|▉         | 515/5153 [00:00<00:04, 1027.74it/s]
 12%|█▏        | 619/5153 [00:00<00:04, 1030.79it/s]
 14%|█▍        | 723/5153 [00:00<00:04, 1033.20it/s]
 16%|█▌        | 828/5153 [00:00<00:04, 1036.15it/s]
 18%|█▊        | 932/5153 [00:00<00:04, 1036.47it/s]
 20%|██        | 1036/5153 [00:01<00:03, 1036.86it/s]
 22%|██▏       | 1141/5153 [00:01<00:03, 1037.86it/s]
 24%|██▍       | 1246/5153 [00:01<00:03, 1039.84it/s]
 26%|██▌       | 1351/5153 [00:01<00:03, 1040.88it/s]
 28%|██▊       | 1456/5153 [00:01<00:03, 1041.26it/s]
 30%|███       | 1561/5153 [00:01<00:03, 1040.65it/s]
 32%|███▏      | 1666/5153 [00:01<00:03, 1040.62it/s]
 34%|███▍      | 1771/5153 [00:01<00:03, 1040.07it/s]
 36%|███▋      | 1876/5153 [00:01<00:03, 1041.31it/s]
 38%|███▊      | 1981/5153 [00:01<00:03, 1042.19it/s]
 40%|████      | 2086/5153 [00:02<00:02, 1044.08it/s]
 43%|████▎     | 2191/5153 [00:02<00:02, 1044.30it/s]
 45%|████▍     | 2296/5153 [00:02<00:02, 1043.70it/s]
 47%|████▋     | 2401/5153 [00:02<00:02, 1043.97it/s]
 49%|████▊     | 2506/5153 [00:02<00:02, 1042.82it/s]
 51%|█████     | 2611/5153 [00:02<00:02, 1043.20it/s]
 53%|█████▎    | 2716/5153 [00:02<00:02, 1043.95it/s]
 55%|█████▍    | 2821/5153 [00:02<00:02, 1042.71it/s]
 57%|█████▋    | 2926/5153 [00:02<00:02, 1041.71it/s]
 59%|█████▉    | 3031/5153 [00:02<00:02, 1041.78it/s]
 61%|██████    | 3136/5153 [00:03<00:01, 1042.62it/s]
 63%|██████▎   | 3242/5153 [00:03<00:01, 1045.12it/s]
 65%|██████▍   | 3347/5153 [00:03<00:01, 1046.23it/s]
 67%|██████▋   | 3452/5153 [00:03<00:01, 1044.71it/s]
 69%|██████▉   | 3557/5153 [00:03<00:01, 1042.88it/s]
 71%|███████   | 3662/5153 [00:03<00:01, 1041.72it/s]
 73%|███████▎  | 3767/5153 [00:03<00:01, 1042.65it/s]
 75%|███████▌  | 3872/5153 [00:03<00:01, 1042.61it/s]
 77%|███████▋  | 3977/5153 [00:03<00:01, 1041.88it/s]
 79%|███████▉  | 4082/5153 [00:03<00:01, 1041.24it/s]
 81%|████████▏ | 4187/5153 [00:04<00:00, 1041.30it/s]
 83%|████████▎ | 4292/5153 [00:04<00:00, 1039.81it/s]
 85%|████████▌ | 4397/5153 [00:04<00:00, 1040.56it/s]
 87%|████████▋ | 4502/5153 [00:04<00:00, 1041.37it/s]
 89%|████████▉ | 4607/5153 [00:04<00:00, 1041.76it/s]
 91%|█████████▏| 4712/5153 [00:04<00:00, 1041.82it/s]
 93%|█████████▎| 4817/5153 [00:04<00:00, 1040.55it/s]
 96%|█████████▌| 4922/5153 [00:04<00:00, 1039.82it/s]
 98%|█████████▊| 5026/5153 [00:04<00:00, 1039.50it/s]
100%|█████████▉| 5131/5153 [00:04<00:00, 1040.10it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1040.15it/s]
2024-11-21:14:55:23,460 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:55:50,692 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:50,692 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:50,737 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1035.10it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1041.44it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1044.61it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1047.10it/s]
 10%|█         | 526/5153 [00:00<00:04, 1049.30it/s]
 12%|█▏        | 633/5153 [00:00<00:04, 1053.69it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1054.53it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1053.79it/s]
 18%|█▊        | 952/5153 [00:00<00:03, 1055.76it/s]
 21%|██        | 1058/5153 [00:01<00:03, 1056.37it/s]
 23%|██▎       | 1165/5153 [00:01<00:03, 1057.36it/s]
 25%|██▍       | 1272/5153 [00:01<00:03, 1058.84it/s]
 27%|██▋       | 1379/5153 [00:01<00:03, 1061.06it/s]
 29%|██▉       | 1486/5153 [00:01<00:03, 1060.54it/s]
 31%|███       | 1593/5153 [00:01<00:03, 1061.14it/s]
 33%|███▎      | 1700/5153 [00:01<00:03, 1061.42it/s]
 35%|███▌      | 1807/5153 [00:01<00:03, 1061.82it/s]
 37%|███▋      | 1914/5153 [00:01<00:03, 1060.31it/s]
 39%|███▉      | 2021/5153 [00:01<00:02, 1061.43it/s]
 41%|████▏     | 2128/5153 [00:02<00:02, 1061.20it/s]
 43%|████▎     | 2235/5153 [00:02<00:02, 1061.29it/s]
 45%|████▌     | 2342/5153 [00:02<00:02, 1061.66it/s]
 48%|████▊     | 2449/5153 [00:02<00:02, 1062.60it/s]
 50%|████▉     | 2556/5153 [00:02<00:02, 1063.33it/s]
 52%|█████▏    | 2663/5153 [00:02<00:02, 1062.39it/s]
 54%|█████▍    | 2770/5153 [00:02<00:02, 1064.51it/s]
 56%|█████▌    | 2877/5153 [00:02<00:02, 1064.04it/s]
 58%|█████▊    | 2984/5153 [00:02<00:02, 1063.05it/s]
 60%|█████▉    | 3091/5153 [00:02<00:01, 1061.93it/s]
 62%|██████▏   | 3198/5153 [00:03<00:01, 1060.63it/s]
 64%|██████▍   | 3305/5153 [00:03<00:01, 1058.96it/s]
 66%|██████▌   | 3411/5153 [00:03<00:01, 1058.22it/s]
 68%|██████▊   | 3517/5153 [00:03<00:01, 1057.92it/s]
 70%|███████   | 3623/5153 [00:03<00:01, 1057.98it/s]
 72%|███████▏  | 3730/5153 [00:03<00:01, 1058.85it/s]
 74%|███████▍  | 3836/5153 [00:03<00:01, 1059.13it/s]
 77%|███████▋  | 3943/5153 [00:03<00:01, 1060.36it/s]
 79%|███████▊  | 4050/5153 [00:03<00:01, 1060.77it/s]
 81%|████████  | 4157/5153 [00:03<00:00, 1062.41it/s]
 83%|████████▎ | 4264/5153 [00:04<00:00, 1062.80it/s]
 85%|████████▍ | 4371/5153 [00:04<00:00, 1062.30it/s]
 87%|████████▋ | 4478/5153 [00:04<00:00, 1061.50it/s]
 89%|████████▉ | 4585/5153 [00:04<00:00, 1061.05it/s]
 91%|█████████ | 4692/5153 [00:04<00:00, 1060.25it/s]
 93%|█████████▎| 4799/5153 [00:04<00:00, 1059.59it/s]
 95%|█████████▌| 4905/5153 [00:04<00:00, 1058.92it/s]
 97%|█████████▋| 5011/5153 [00:04<00:00, 1058.12it/s]
 99%|█████████▉| 5118/5153 [00:04<00:00, 1059.57it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1059.04it/s]
2024-11-21:14:55:55,644 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:56:21,756 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:21,756 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:21,800 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.91it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1033.12it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1034.65it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1034.30it/s]
 10%|█         | 519/5153 [00:00<00:04, 1034.24it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1039.22it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1043.70it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1046.19it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1047.50it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1050.27it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1052.12it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1054.17it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1053.60it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1052.01it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1049.55it/s]
 33%|███▎      | 1683/5153 [00:01<00:03, 1048.24it/s]
 35%|███▍      | 1788/5153 [00:01<00:03, 1048.50it/s]
 37%|███▋      | 1894/5153 [00:01<00:03, 1049.49it/s]
 39%|███▉      | 2000/5153 [00:01<00:03, 1050.99it/s]
 41%|████      | 2106/5153 [00:02<00:02, 1053.00it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1055.16it/s]
 45%|████▌     | 2319/5153 [00:02<00:02, 1055.98it/s]
 47%|████▋     | 2425/5153 [00:02<00:02, 1057.09it/s]
 49%|████▉     | 2531/5153 [00:02<00:02, 1057.61it/s]
 51%|█████     | 2637/5153 [00:02<00:02, 1055.11it/s]
 53%|█████▎    | 2743/5153 [00:02<00:02, 1053.82it/s]
 55%|█████▌    | 2849/5153 [00:02<00:02, 1052.05it/s]
 57%|█████▋    | 2955/5153 [00:02<00:02, 1051.00it/s]
 59%|█████▉    | 3061/5153 [00:02<00:01, 1051.50it/s]
 61%|██████▏   | 3167/5153 [00:03<00:01, 1052.09it/s]
 64%|██████▎   | 3273/5153 [00:03<00:01, 1052.51it/s]
 66%|██████▌   | 3379/5153 [00:03<00:01, 1053.31it/s]
 68%|██████▊   | 3485/5153 [00:03<00:01, 1055.11it/s]
 70%|██████▉   | 3591/5153 [00:03<00:01, 1056.30it/s]
 72%|███████▏  | 3697/5153 [00:03<00:01, 1055.28it/s]
 74%|███████▍  | 3804/5153 [00:03<00:01, 1056.97it/s]
 76%|███████▌  | 3910/5153 [00:03<00:01, 1054.19it/s]
 78%|███████▊  | 4016/5153 [00:03<00:01, 1051.43it/s]
 80%|███████▉  | 4122/5153 [00:03<00:00, 1050.92it/s]
 82%|████████▏ | 4228/5153 [00:04<00:00, 1052.72it/s]
 84%|████████▍ | 4334/5153 [00:04<00:00, 1050.07it/s]
 86%|████████▌ | 4440/5153 [00:04<00:00, 1050.33it/s]
 88%|████████▊ | 4546/5153 [00:04<00:00, 1051.05it/s]
 90%|█████████ | 4652/5153 [00:04<00:00, 1051.06it/s]
 92%|█████████▏| 4758/5153 [00:04<00:00, 1051.25it/s]
 94%|█████████▍| 4864/5153 [00:04<00:00, 1050.36it/s]
 96%|█████████▋| 4970/5153 [00:04<00:00, 1051.38it/s]
 99%|█████████▊| 5076/5153 [00:04<00:00, 1051.08it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.50it/s]
2024-11-21:14:56:26,748 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:56:54,231 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:54,231 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:54,275 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.71it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1036.63it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1039.18it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1042.05it/s]
 10%|█         | 523/5153 [00:00<00:04, 1043.48it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1046.22it/s]
 14%|█▍        | 735/5153 [00:00<00:04, 1048.23it/s]
 16%|█▋        | 840/5153 [00:00<00:04, 1047.20it/s]
 18%|█▊        | 945/5153 [00:00<00:04, 1047.27it/s]
 20%|██        | 1050/5153 [00:01<00:03, 1046.27it/s]
 22%|██▏       | 1155/5153 [00:01<00:03, 1046.99it/s]
 24%|██▍       | 1261/5153 [00:01<00:03, 1047.81it/s]
 27%|██▋       | 1367/5153 [00:01<00:03, 1050.33it/s]
 29%|██▊       | 1473/5153 [00:01<00:03, 1051.46it/s]
 31%|███       | 1579/5153 [00:01<00:03, 1052.18it/s]
 33%|███▎      | 1685/5153 [00:01<00:03, 1052.16it/s]
 35%|███▍      | 1791/5153 [00:01<00:03, 1050.49it/s]
 37%|███▋      | 1897/5153 [00:01<00:03, 1049.80it/s]
 39%|███▉      | 2002/5153 [00:01<00:03, 1049.26it/s]
 41%|████      | 2107/5153 [00:02<00:02, 1048.69it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1049.11it/s]
 45%|████▍     | 2318/5153 [00:02<00:02, 1048.86it/s]
 47%|████▋     | 2423/5153 [00:02<00:02, 1048.16it/s]
 49%|████▉     | 2529/5153 [00:02<00:02, 1049.17it/s]
 51%|█████     | 2635/5153 [00:02<00:02, 1049.58it/s]
 53%|█████▎    | 2741/5153 [00:02<00:02, 1051.81it/s]
 55%|█████▌    | 2847/5153 [00:02<00:02, 1051.48it/s]
 57%|█████▋    | 2953/5153 [00:02<00:02, 1051.14it/s]
 59%|█████▉    | 3059/5153 [00:02<00:01, 1049.69it/s]
 61%|██████▏   | 3164/5153 [00:03<00:01, 1048.50it/s]
 63%|██████▎   | 3269/5153 [00:03<00:01, 1047.66it/s]
 65%|██████▌   | 3374/5153 [00:03<00:01, 1046.25it/s]
 68%|██████▊   | 3479/5153 [00:03<00:01, 1045.98it/s]
 70%|██████▉   | 3584/5153 [00:03<00:01, 1046.43it/s]
 72%|███████▏  | 3689/5153 [00:03<00:01, 1046.56it/s]
 74%|███████▎  | 3795/5153 [00:03<00:01, 1048.50it/s]
 76%|███████▌  | 3901/5153 [00:03<00:01, 1048.83it/s]
 78%|███████▊  | 4006/5153 [00:03<00:01, 1048.75it/s]
 80%|███████▉  | 4112/5153 [00:03<00:00, 1049.51it/s]
 82%|████████▏ | 4217/5153 [00:04<00:00, 1048.28it/s]
 84%|████████▍ | 4322/5153 [00:04<00:00, 1047.46it/s]
 86%|████████▌ | 4427/5153 [00:04<00:00, 1047.81it/s]
 88%|████████▊ | 4532/5153 [00:04<00:00, 1047.71it/s]
 90%|████████▉ | 4637/5153 [00:04<00:00, 1047.60it/s]
 92%|█████████▏| 4742/5153 [00:04<00:00, 1046.69it/s]
 94%|█████████▍| 4847/5153 [00:04<00:00, 1047.22it/s]
 96%|█████████▌| 4953/5153 [00:04<00:00, 1048.16it/s]
 98%|█████████▊| 5058/5153 [00:04<00:00, 1047.92it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1048.07it/s]
2024-11-21:14:56:59,234 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:57:25,187 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:25,188 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:25,233 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1030.86it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1036.10it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1038.15it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1040.58it/s]
 10%|█         | 523/5153 [00:00<00:04, 1041.71it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1046.36it/s]
 14%|█▍        | 735/5153 [00:00<00:04, 1048.85it/s]
 16%|█▋        | 840/5153 [00:00<00:04, 1048.26it/s]
 18%|█▊        | 946/5153 [00:00<00:04, 1049.29it/s]
 20%|██        | 1051/5153 [00:01<00:03, 1049.45it/s]
 22%|██▏       | 1157/5153 [00:01<00:03, 1051.57it/s]
 25%|██▍       | 1264/5153 [00:01<00:03, 1054.30it/s]
 27%|██▋       | 1370/5153 [00:01<00:03, 1054.29it/s]
 29%|██▊       | 1476/5153 [00:01<00:03, 1054.58it/s]
 31%|███       | 1582/5153 [00:01<00:03, 1054.77it/s]
 33%|███▎      | 1688/5153 [00:01<00:03, 1055.08it/s]
 35%|███▍      | 1794/5153 [00:01<00:03, 1056.21it/s]
 37%|███▋      | 1900/5153 [00:01<00:03, 1057.30it/s]
 39%|███▉      | 2006/5153 [00:01<00:02, 1057.48it/s]
 41%|████      | 2113/5153 [00:02<00:02, 1058.48it/s]
 43%|████▎     | 2219/5153 [00:02<00:02, 1058.83it/s]
 45%|████▌     | 2326/5153 [00:02<00:02, 1059.25it/s]
 47%|████▋     | 2433/5153 [00:02<00:02, 1060.46it/s]
 49%|████▉     | 2540/5153 [00:02<00:02, 1060.66it/s]
 51%|█████▏    | 2647/5153 [00:02<00:02, 1060.13it/s]
 53%|█████▎    | 2754/5153 [00:02<00:02, 1059.03it/s]
 56%|█████▌    | 2860/5153 [00:02<00:02, 1057.18it/s]
 58%|█████▊    | 2966/5153 [00:02<00:02, 1056.67it/s]
 60%|█████▉    | 3072/5153 [00:02<00:01, 1056.19it/s]
 62%|██████▏   | 3178/5153 [00:03<00:01, 1055.58it/s]
 64%|██████▎   | 3284/5153 [00:03<00:01, 1053.98it/s]
 66%|██████▌   | 3390/5153 [00:03<00:01, 1053.62it/s]
 68%|██████▊   | 3496/5153 [00:03<00:01, 1053.38it/s]
 70%|██████▉   | 3602/5153 [00:03<00:01, 1055.06it/s]
 72%|███████▏  | 3708/5153 [00:03<00:01, 1055.82it/s]
 74%|███████▍  | 3815/5153 [00:03<00:01, 1058.92it/s]
 76%|███████▌  | 3921/5153 [00:03<00:01, 1057.52it/s]
 78%|███████▊  | 4027/5153 [00:03<00:01, 1055.78it/s]
 80%|████████  | 4133/5153 [00:03<00:00, 1055.05it/s]
 82%|████████▏ | 4239/5153 [00:04<00:00, 1054.75it/s]
 84%|████████▍ | 4345/5153 [00:04<00:00, 1055.36it/s]
 86%|████████▋ | 4451/5153 [00:04<00:00, 1056.47it/s]
 88%|████████▊ | 4557/5153 [00:04<00:00, 1054.95it/s]
 90%|█████████ | 4663/5153 [00:04<00:00, 1054.85it/s]
 93%|█████████▎| 4769/5153 [00:04<00:00, 1053.93it/s]
 95%|█████████▍| 4875/5153 [00:04<00:00, 1053.95it/s]
 97%|█████████▋| 4981/5153 [00:04<00:00, 1054.64it/s]
 99%|█████████▊| 5087/5153 [00:04<00:00, 1054.60it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.09it/s]
2024-11-21:14:57:30,163 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
2024-11-21:14:57:56,604 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:56,604 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:56,649 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 102/5153 [00:00<00:04, 1018.51it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1029.58it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1031.70it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1034.13it/s]
 10%|█         | 518/5153 [00:00<00:04, 1036.11it/s]
 12%|█▏        | 623/5153 [00:00<00:04, 1039.30it/s]
 14%|█▍        | 728/5153 [00:00<00:04, 1041.70it/s]
 16%|█▌        | 833/5153 [00:00<00:04, 1042.53it/s]
 18%|█▊        | 938/5153 [00:00<00:04, 1042.89it/s]
 20%|██        | 1043/5153 [00:01<00:03, 1044.28it/s]
 22%|██▏       | 1148/5153 [00:01<00:03, 1044.38it/s]
 24%|██▍       | 1253/5153 [00:01<00:03, 1044.55it/s]
 26%|██▋       | 1358/5153 [00:01<00:03, 1044.48it/s]
 28%|██▊       | 1463/5153 [00:01<00:03, 1043.86it/s]
 30%|███       | 1568/5153 [00:01<00:03, 1044.53it/s]
 32%|███▏      | 1673/5153 [00:01<00:03, 1043.85it/s]
 35%|███▍      | 1778/5153 [00:01<00:03, 1043.90it/s]
 37%|███▋      | 1883/5153 [00:01<00:03, 1044.47it/s]
 39%|███▊      | 1988/5153 [00:01<00:03, 1045.78it/s]
 41%|████      | 2094/5153 [00:02<00:02, 1048.69it/s]
 43%|████▎     | 2200/5153 [00:02<00:02, 1049.36it/s]
 45%|████▍     | 2306/5153 [00:02<00:02, 1050.56it/s]
 47%|████▋     | 2412/5153 [00:02<00:02, 1050.40it/s]
 49%|████▉     | 2518/5153 [00:02<00:02, 1048.31it/s]
 51%|█████     | 2623/5153 [00:02<00:02, 1047.10it/s]
 53%|█████▎    | 2728/5153 [00:02<00:02, 1047.08it/s]
 55%|█████▍    | 2833/5153 [00:02<00:02, 1047.80it/s]
 57%|█████▋    | 2938/5153 [00:02<00:02, 1047.63it/s]
 59%|█████▉    | 3043/5153 [00:02<00:02, 1046.05it/s]
 61%|██████    | 3148/5153 [00:03<00:01, 1045.79it/s]
 63%|██████▎   | 3253/5153 [00:03<00:01, 1046.14it/s]
 65%|██████▌   | 3358/5153 [00:03<00:01, 1046.87it/s]
 67%|██████▋   | 3464/5153 [00:03<00:01, 1048.94it/s]
 69%|██████▉   | 3570/5153 [00:03<00:01, 1050.02it/s]
 71%|███████▏  | 3676/5153 [00:03<00:01, 1051.49it/s]
 73%|███████▎  | 3782/5153 [00:03<00:01, 1050.76it/s]
 75%|███████▌  | 3888/5153 [00:03<00:01, 1050.32it/s]
 78%|███████▊  | 3994/5153 [00:03<00:01, 1049.32it/s]
 80%|███████▉  | 4099/5153 [00:03<00:01, 1046.20it/s]
 82%|████████▏ | 4204/5153 [00:04<00:00, 1037.65it/s]
 84%|████████▎ | 4308/5153 [00:04<00:00, 1030.78it/s]
 86%|████████▌ | 4412/5153 [00:04<00:00, 1026.12it/s]
 88%|████████▊ | 4515/5153 [00:04<00:00, 1023.60it/s]
 90%|████████▉ | 4618/5153 [00:04<00:00, 1020.72it/s]
 92%|█████████▏| 4721/5153 [00:04<00:00, 1018.98it/s]
 94%|█████████▎| 4823/5153 [00:04<00:00, 1018.62it/s]
 96%|█████████▌| 4925/5153 [00:04<00:00, 1015.66it/s]
 98%|█████████▊| 5027/5153 [00:04<00:00, 1013.65it/s]
100%|█████████▉| 5129/5153 [00:04<00:00, 1012.67it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1038.70it/s]
2024-11-21:14:58:01,652 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:58:51,614 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:58:51,614 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:58:51,659 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1023.43it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1023.81it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1026.66it/s]
  8%|▊         | 413/5153 [00:00<00:04, 1026.22it/s]
 10%|█         | 516/5153 [00:00<00:04, 1024.78it/s]
 12%|█▏        | 622/5153 [00:00<00:04, 1034.12it/s]
 14%|█▍        | 727/5153 [00:00<00:04, 1038.21it/s]
 16%|█▌        | 832/5153 [00:00<00:04, 1040.40it/s]
 18%|█▊        | 937/5153 [00:00<00:04, 1042.44it/s]
 20%|██        | 1043/5153 [00:01<00:03, 1045.50it/s]
 22%|██▏       | 1148/5153 [00:01<00:03, 1046.36it/s]
 24%|██▍       | 1254/5153 [00:01<00:03, 1047.91it/s]
 26%|██▋       | 1360/5153 [00:01<00:03, 1049.37it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1050.19it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1050.58it/s]
 33%|███▎      | 1678/5153 [00:01<00:03, 1049.40it/s]
 35%|███▍      | 1784/5153 [00:01<00:03, 1049.65it/s]
 37%|███▋      | 1889/5153 [00:01<00:03, 1047.22it/s]
 39%|███▊      | 1994/5153 [00:01<00:03, 1045.77it/s]
 41%|████      | 2099/5153 [00:02<00:02, 1045.38it/s]
 43%|████▎     | 2204/5153 [00:02<00:02, 1045.03it/s]
 45%|████▍     | 2309/5153 [00:02<00:02, 1046.28it/s]
 47%|████▋     | 2415/5153 [00:02<00:02, 1047.54it/s]
 49%|████▉     | 2521/5153 [00:02<00:02, 1049.79it/s]
 51%|█████     | 2626/5153 [00:02<00:02, 1049.48it/s]
 53%|█████▎    | 2732/5153 [00:02<00:02, 1050.66it/s]
 55%|█████▌    | 2838/5153 [00:02<00:02, 1052.71it/s]
 57%|█████▋    | 2944/5153 [00:02<00:02, 1053.29it/s]
 59%|█████▉    | 3050/5153 [00:02<00:01, 1054.11it/s]
 61%|██████    | 3156/5153 [00:03<00:01, 1052.51it/s]
 63%|██████▎   | 3262/5153 [00:03<00:01, 1051.82it/s]
 65%|██████▌   | 3368/5153 [00:03<00:01, 1051.99it/s]
 67%|██████▋   | 3474/5153 [00:03<00:01, 1051.87it/s]
 69%|██████▉   | 3580/5153 [00:03<00:01, 1051.92it/s]
 72%|███████▏  | 3686/5153 [00:03<00:01, 1051.23it/s]
 74%|███████▎  | 3792/5153 [00:03<00:01, 1051.75it/s]
 76%|███████▌  | 3898/5153 [00:03<00:01, 1052.16it/s]
 78%|███████▊  | 4004/5153 [00:03<00:01, 1052.85it/s]
 80%|███████▉  | 4111/5153 [00:03<00:00, 1055.15it/s]
 82%|████████▏ | 4217/5153 [00:04<00:00, 1055.71it/s]
 84%|████████▍ | 4323/5153 [00:04<00:00, 1053.56it/s]
 86%|████████▌ | 4429/5153 [00:04<00:00, 1051.72it/s]
 88%|████████▊ | 4535/5153 [00:04<00:00, 1052.13it/s]
 90%|█████████ | 4641/5153 [00:04<00:00, 1052.03it/s]
 92%|█████████▏| 4747/5153 [00:04<00:00, 1051.58it/s]
 94%|█████████▍| 4853/5153 [00:04<00:00, 1052.35it/s]
 96%|█████████▌| 4959/5153 [00:04<00:00, 1052.12it/s]
 98%|█████████▊| 5065/5153 [00:04<00:00, 1052.29it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1048.17it/s]
2024-11-21:14:58:56,616 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-FFN1.5x
#
# Epoch = 0 to 2406 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-FFN1.5x/rwkv-init.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-FFN1.5x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 0, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 1536, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-19-23-43-14', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': '04b-pre-x59-FFN1.5x'}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-FFN1.5x/rwkv-init.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 132 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
266 M     Trainable params
0         Non-trainable params
266 M     Total params
1,067.237 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240919_234433-0uw4p0tr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 04b-pre-x59-FFN1.5x 2024-09-19-23-43-14
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/0uw4p0tr
slurmstepd: error: *** JOB 64227097 ON udc-an36-19 CANCELLED AT 2024-09-22T23:42:59 DUE TO TIME LIMIT ***

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)18=72, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59
#
# Epoch = 1858 to 4264 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 560 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59/rwkv-1857.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 560, 'epoch_count': 2407, 'epoch_begin': 1858, 'epoch_save': 10, 'micro_bsz': 18, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 0, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 40960, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-08-07-15-23-13', 'betas': (0.9, 0.99), 'real_bsz': 72, 'run_name': 'L12 D768 F8 x059', 'my_pile_prev_p': 1847}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59/rwkv-1857.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 65.6 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
166 M     Trainable params
0         Non-trainable params
166 M     Total params
665.248   Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240807_152356-p7uu4xi4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L12 D768 F8 x059 2024-08-07-15-23-13
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/p7uu4xi4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py:437: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
  rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/train.py", line 443, in <module>
    trainer.fit(model, data_loader)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 36, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 88, in launch
    return function(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
    results = self._run_stage()
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
    self._run_train()
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
    self.fit_loop.run()
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 213, in advance
    batch_output = self.batch_loop.run(kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 202, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 370, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1754, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 280, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, opt_idx, closure, model, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
    return self.precision_plugin.optimizer_step(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 132, in optimizer_step
    closure_result = closure()
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 149, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 144, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 305, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 207, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, optimizer_idx, *args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 118, in backward
    deepspeed_engine.backward(tensor, *args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1967, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2057, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 
[rank2]: Traceback (most recent call last):
[rank2]:   File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/train.py", line 443, in <module>
[rank2]:     trainer.fit(model, data_loader)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
[rank2]:     return trainer_fn(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
[rank2]:     self._run(model, ckpt_path=self.ckpt_path)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
[rank2]:     self._run_train()
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
[rank2]:     self.fit_loop.run()
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank2]:     self.advance(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
[rank2]:     self._outputs = self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank2]:     self.advance(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 213, in advance
[rank2]:     batch_output = self.batch_loop.run(kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank2]:     self.advance(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
[rank2]:     outputs = self.optimizer_loop.run(optimizers, kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank2]:     self.advance(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 202, in advance
[rank2]:     result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
[rank2]:     self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 370, in _optimizer_step
[rank2]:     self.trainer._call_lightning_module_hook(
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1754, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 280, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, opt_idx, closure, model, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 132, in optimizer_step
[rank2]:     closure_result = closure()
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 149, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 144, in closure
[rank2]:     self._backward_fn(step_output.closure_loss)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 305, in backward_fn
[rank2]:     self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 207, in backward
[rank2]:     self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, optimizer_idx, *args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 118, in backward
[rank2]:     deepspeed_engine.backward(tensor, *args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1967, in backward
[rank2]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2057, in backward
[rank2]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank2]:     scaled_loss.backward(retain_graph=retain_graph)
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
[rank2]:     torch.autograd.backward(
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank2]:     _engine_run_backward(
[rank2]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank2]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank2]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU  has a total capacity of 39.38 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 36.96 GiB memory in use. Of the allocated memory 34.15 GiB is allocated by PyTorch, and 182.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/train.py", line 443, in <module>
[rank1]:     trainer.fit(model, data_loader)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
[rank1]:     return trainer_fn(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
[rank1]:     self._run(model, ckpt_path=self.ckpt_path)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
[rank1]:     self._run_train()
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
[rank1]:     self.fit_loop.run()
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank1]:     self.advance(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
[rank1]:     self._outputs = self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank1]:     self.advance(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 213, in advance
[rank1]:     batch_output = self.batch_loop.run(kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank1]:     self.advance(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
[rank1]:     outputs = self.optimizer_loop.run(optimizers, kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank1]:     self.advance(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 202, in advance
[rank1]:     result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
[rank1]:     self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 370, in _optimizer_step
[rank1]:     self.trainer._call_lightning_module_hook(
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1754, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 280, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, opt_idx, closure, model, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 132, in optimizer_step
[rank1]:     closure_result = closure()
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 149, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 144, in closure
[rank1]:     self._backward_fn(step_output.closure_loss)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 305, in backward_fn
[rank1]:     self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 207, in backward
[rank1]:     self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, optimizer_idx, *args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 118, in backward
[rank1]:     deepspeed_engine.backward(tensor, *args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1967, in backward
[rank1]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2057, in backward
[rank1]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank1]:     scaled_loss.backward(retain_graph=retain_graph)
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU  has a total capacity of 39.38 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 36.96 GiB memory in use. Of the allocated memory 34.15 GiB is allocated by PyTorch, and 182.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/train.py", line 443, in <module>
[rank0]:     trainer.fit(model, data_loader)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 36, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 88, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
[rank0]:     self._run(model, ckpt_path=self.ckpt_path)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
[rank0]:     self._run_train()
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
[rank0]:     self._outputs = self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 213, in advance
[rank0]:     batch_output = self.batch_loop.run(kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
[rank0]:     outputs = self.optimizer_loop.run(optimizers, kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 202, in advance
[rank0]:     result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
[rank0]:     self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 370, in _optimizer_step
[rank0]:     self.trainer._call_lightning_module_hook(
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1754, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 280, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, opt_idx, closure, model, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 132, in optimizer_step
[rank0]:     closure_result = closure()
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 149, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 144, in closure
[rank0]:     self._backward_fn(step_output.closure_loss)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 305, in backward_fn
[rank0]:     self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 207, in backward
[rank0]:     self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, optimizer_idx, *args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 118, in backward
[rank0]:     deepspeed_engine.backward(tensor, *args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1967, in backward
[rank0]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2057, in backward
[rank0]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank0]:     scaled_loss.backward(retain_graph=retain_graph)
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 
[rank3]: Traceback (most recent call last):
[rank3]:   File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/train.py", line 443, in <module>
[rank3]:     trainer.fit(model, data_loader)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
[rank3]:     return trainer_fn(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
[rank3]:     self._run(model, ckpt_path=self.ckpt_path)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
[rank3]:     self._run_train()
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
[rank3]:     self.fit_loop.run()
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank3]:     self.advance(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
[rank3]:     self._outputs = self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank3]:     self.advance(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 213, in advance
[rank3]:     batch_output = self.batch_loop.run(kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank3]:     self.advance(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
[rank3]:     outputs = self.optimizer_loop.run(optimizers, kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
[rank3]:     self.advance(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 202, in advance
[rank3]:     result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
[rank3]:     self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 370, in _optimizer_step
[rank3]:     self.trainer._call_lightning_module_hook(
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1754, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 280, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, opt_idx, closure, model, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 132, in optimizer_step
[rank3]:     closure_result = closure()
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 149, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 144, in closure
[rank3]:     self._backward_fn(step_output.closure_loss)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 305, in backward_fn
[rank3]:     self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 207, in backward
[rank3]:     self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, optimizer_idx, *args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/deepspeed.py", line 118, in backward
[rank3]:     deepspeed_engine.backward(tensor, *args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1967, in backward
[rank3]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2057, in backward
[rank3]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank3]:     scaled_loss.backward(retain_graph=retain_graph)
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
[rank3]:     torch.autograd.backward(
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank3]:     _engine_run_backward(
[rank3]:   File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank3]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU  has a total capacity of 39.38 GiB of which 2.59 GiB is free. Including non-PyTorch memory, this process has 36.67 GiB memory in use. Of the allocated memory 34.15 GiB is allocated by PyTorch, and 182.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
wandb: - 0.016 MB of 0.016 MB uploaded
wandb: \ 0.016 MB of 0.016 MB uploaded
wandb: | 0.016 MB of 0.016 MB uploaded
wandb: / 0.016 MB of 0.016 MB uploaded
wandb: - 0.029 MB of 0.055 MB uploaded
wandb: \ 0.055 MB of 0.055 MB uploaded
wandb: 🚀 View run L12 D768 F8 x059 2024-08-07-15-23-13 at: https://wandb.ai/xsel/rwkv-hpc/runs/p7uu4xi4
wandb: ⭐️ View project at: https://wandb.ai/xsel/rwkv-hpc
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240807_152356-p7uu4xi4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.

========================================
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:05<00:45,  5.03s/it]
100%|██████████| 10/10 [00:05<00:00,  1.98it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.96s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.95s/it]
100%|██████████| 10/10 [00:04<00:00,  2.02it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.92s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.97s/it]
100%|██████████| 10/10 [00:04<00:00,  2.00it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:05<00:45,  5.02s/it]
100%|██████████| 10/10 [00:05<00:00,  1.99it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  5.00s/it]
100%|██████████| 10/10 [00:04<00:00,  2.00it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.99s/it]
100%|██████████| 10/10 [00:04<00:00,  2.00it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.98s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.97s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.96s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.96s/it]
100%|██████████| 10/10 [00:04<00:00,  2.02it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:43,  4.81s/it]
100%|██████████| 10/10 [00:04<00:00,  2.08it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.95s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.97s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:42,  4.76s/it]
100%|██████████| 10/10 [00:04<00:00,  2.08it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:42,  4.73s/it]
100%|██████████| 10/10 [00:04<00:00,  2.10it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.97s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.97s/it]
100%|██████████| 10/10 [00:05<00:00,  2.00it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.98s/it]
100%|██████████| 10/10 [00:04<00:00,  2.01it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.96s/it]
100%|██████████| 10/10 [00:04<00:00,  2.00it/s]

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59
#
# Epoch = 2335 to 4741 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59/rwkv-2334.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 2335, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-08-13-15-42-06', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': 'L24 D1024 F8 x059', 'my_pile_prev_p': 2324}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59/rwkv-2334.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 233 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
367 M     Trainable params
0         Non-trainable params
367 M     Total params
1,469.891 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240813_154331-w42mvbjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L24 D1024 F8 x059 2024-08-13-15-42-06
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/w42mvbjq
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py:437: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
  rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")
wandb: - 0.016 MB of 0.016 MB uploaded
wandb: \ 0.016 MB of 0.016 MB uploaded
wandb: | 0.030 MB of 0.030 MB uploaded (0.002 MB deduped)
wandb: / 0.037 MB of 0.037 MB uploaded (0.002 MB deduped)
wandb: 
wandb: Run history:
wandb:   GRAD: head weight ▂▁▄▂▃▂▁▄▃▂▂▃▂▃▂█▂▂▃▃▂▃▁▄▁▄▃▂▆▂▄▃▄▄▂▂▂▃▃▃
wandb: GRAD: ln_out weight ▅▁▄▃▂▁▂▄▄▂▃▂▁▂▃▄▂▁▃▃▂█▂▂▃▃▄▂▅▂▂▂▃▄▅▂▄▁▃▂
wandb:             Gtokens ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                kt/s ▅▃▃▄▄▆▄▁▆▇▆▃▃▃▅▃▃▄▃▁▃█▅▃▁▆▃▅▅▁▅▄▄▄▃▅▂▃▄▇
wandb:                loss █▄▅▄▆▂▅▃▆▃▄▅▄▇▅▄▅▆▅▇▅▅▄▂▃▅▅▅▆▄▅▇▄▄▃▇▄▆▁█
wandb:                  lr ██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:                  wd ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:   GRAD: head weight 0.18744
wandb: GRAD: ln_out weight 0.02187
wandb:             Gtokens 198.78891
wandb:                kt/s 95.99151
wandb:                loss 2.25781
wandb:                  lr 6e-05
wandb:                  wd 0.001
wandb: 
wandb: 🚀 View run L24 D1024 F8 x059 2024-08-13-15-42-06 at: https://wandb.ai/xsel/rwkv-hpc/runs/w42mvbjq
wandb: ⭐️ View project at: https://wandb.ai/xsel/rwkv-hpc
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240813_154331-w42mvbjq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x
#
# Epoch = 1053 to 3459 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x/rwkv-1052.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 1053, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 16, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-06-20-23-19', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': '04b-pre-x59-16x', 'my_pile_prev_p': 1042}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x
#
# Epoch = 1053 to 3459 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x/rwkv-1052.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 1053, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 16, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-06-20-23-19', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': '04b-pre-x59-16x', 'my_pile_prev_p': 1042}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x/rwkv-1052.pth... ##########
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x59-16x/rwkv-1052.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 217 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
351 M     Trainable params
0         Non-trainable params
351 M     Total params
1,406.976 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 217 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
351 M     Trainable params
0         Non-trainable params
351 M     Total params
1,406.976 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240906_202445-mmncrilt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 04b-pre-x59-16x 2024-09-06-20-23-19
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/mmncrilt
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240906_202451-0ya4ldvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 04b-pre-x59-16x 2024-09-06-20-23-19
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/0ya4ldvj
slurmstepd: error: *** JOB 63913490 ON udc-an36-19 CANCELLED AT 2024-09-09T20:23:00 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 63913608 ON udc-an36-1 CANCELLED AT 2024-09-09T20:23:00 DUE TO TIME LIMIT ***

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:57:58,691 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:58,691 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:57:58,761 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  1%|▏         | 72/5153 [00:00<00:07, 719.89it/s]
  3%|▎         | 146/5153 [00:00<00:06, 728.60it/s]
  4%|▍         | 221/5153 [00:00<00:06, 737.74it/s]
  6%|▌         | 297/5153 [00:00<00:06, 744.73it/s]
  7%|▋         | 373/5153 [00:00<00:06, 749.17it/s]
  9%|▊         | 449/5153 [00:00<00:06, 752.82it/s]
 10%|█         | 525/5153 [00:00<00:06, 755.12it/s]
 12%|█▏        | 602/5153 [00:00<00:06, 758.19it/s]
 13%|█▎        | 679/5153 [00:00<00:05, 761.24it/s]
 15%|█▍        | 756/5153 [00:01<00:05, 763.43it/s]
 16%|█▌        | 833/5153 [00:01<00:05, 765.43it/s]
 18%|█▊        | 910/5153 [00:01<00:05, 766.52it/s]
 19%|█▉        | 987/5153 [00:01<00:05, 767.20it/s]
 21%|██        | 1065/5153 [00:01<00:05, 768.24it/s]
 22%|██▏       | 1142/5153 [00:01<00:05, 768.31it/s]
 24%|██▎       | 1220/5153 [00:01<00:05, 769.28it/s]
 25%|██▌       | 1297/5153 [00:01<00:05, 769.44it/s]
 27%|██▋       | 1375/5153 [00:01<00:04, 770.27it/s]
 28%|██▊       | 1453/5153 [00:01<00:04, 769.43it/s]
 30%|██▉       | 1530/5153 [00:02<00:04, 768.85it/s]
 31%|███       | 1607/5153 [00:02<00:04, 768.64it/s]
 33%|███▎      | 1684/5153 [00:02<00:04, 769.04it/s]
 34%|███▍      | 1762/5153 [00:02<00:04, 770.05it/s]
 36%|███▌      | 1840/5153 [00:02<00:04, 769.90it/s]
 37%|███▋      | 1918/5153 [00:02<00:04, 770.07it/s]
 39%|███▊      | 1996/5153 [00:02<00:04, 770.69it/s]
 40%|████      | 2074/5153 [00:02<00:03, 771.64it/s]
 42%|████▏     | 2152/5153 [00:02<00:03, 772.31it/s]
 43%|████▎     | 2230/5153 [00:02<00:03, 773.40it/s]
 45%|████▍     | 2308/5153 [00:03<00:03, 773.39it/s]
 46%|████▋     | 2386/5153 [00:03<00:03, 773.85it/s]
 48%|████▊     | 2464/5153 [00:03<00:03, 773.72it/s]
 49%|████▉     | 2542/5153 [00:03<00:03, 774.14it/s]
 51%|█████     | 2620/5153 [00:03<00:03, 774.19it/s]
 52%|█████▏    | 2698/5153 [00:03<00:03, 774.32it/s]
 54%|█████▍    | 2776/5153 [00:03<00:03, 773.26it/s]
 55%|█████▌    | 2854/5153 [00:03<00:02, 773.14it/s]
 57%|█████▋    | 2932/5153 [00:03<00:02, 772.67it/s]
 58%|█████▊    | 3010/5153 [00:03<00:02, 772.27it/s]
 60%|█████▉    | 3088/5153 [00:04<00:02, 772.51it/s]
 61%|██████▏   | 3166/5153 [00:04<00:02, 772.03it/s]
 63%|██████▎   | 3244/5153 [00:04<00:02, 772.33it/s]
 64%|██████▍   | 3322/5153 [00:04<00:02, 772.36it/s]
 66%|██████▌   | 3400/5153 [00:04<00:02, 772.38it/s]
 67%|██████▋   | 3478/5153 [00:04<00:02, 773.11it/s]
 69%|██████▉   | 3556/5153 [00:04<00:02, 773.47it/s]
 71%|███████   | 3634/5153 [00:04<00:01, 773.64it/s]
 72%|███████▏  | 3712/5153 [00:04<00:01, 773.53it/s]
 74%|███████▎  | 3790/5153 [00:04<00:01, 774.31it/s]
 75%|███████▌  | 3868/5153 [00:05<00:01, 774.43it/s]
 77%|███████▋  | 3946/5153 [00:05<00:01, 774.62it/s]
 78%|███████▊  | 4024/5153 [00:05<00:01, 772.91it/s]
 80%|███████▉  | 4102/5153 [00:05<00:01, 772.86it/s]
 81%|████████  | 4180/5153 [00:05<00:01, 772.39it/s]
 83%|████████▎ | 4258/5153 [00:05<00:01, 772.24it/s]
 84%|████████▍ | 4336/5153 [00:05<00:01, 771.50it/s]
 86%|████████▌ | 4414/5153 [00:05<00:00, 771.78it/s]
 87%|████████▋ | 4492/5153 [00:05<00:00, 771.61it/s]
 89%|████████▊ | 4570/5153 [00:05<00:00, 771.27it/s]
 90%|█████████ | 4648/5153 [00:06<00:00, 770.84it/s]
 92%|█████████▏| 4726/5153 [00:06<00:00, 764.67it/s]
 93%|█████████▎| 4803/5153 [00:06<00:00, 762.84it/s]
 95%|█████████▍| 4880/5153 [00:06<00:00, 761.35it/s]
 96%|█████████▌| 4957/5153 [00:06<00:00, 760.32it/s]
 98%|█████████▊| 5034/5153 [00:06<00:00, 761.47it/s]
 99%|█████████▉| 5112/5153 [00:06<00:00, 764.35it/s]
100%|██████████| 5153/5153 [00:06<00:00, 768.06it/s]
2024-11-21:14:58:05,538 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:05<00:47,  5.23s/it]
100%|██████████| 10/10 [00:05<00:00,  1.91it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:12:59,665 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:12:59,666 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:12:59,737 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  1%|▏         | 73/5153 [00:00<00:07, 723.63it/s]
  3%|▎         | 147/5153 [00:00<00:06, 731.26it/s]
  4%|▍         | 221/5153 [00:00<00:06, 735.03it/s]
  6%|▌         | 295/5153 [00:00<00:06, 734.98it/s]
  7%|▋         | 370/5153 [00:00<00:06, 739.33it/s]
  9%|▊         | 447/5153 [00:00<00:06, 747.17it/s]
 10%|█         | 523/5153 [00:00<00:06, 749.06it/s]
 12%|█▏        | 599/5153 [00:00<00:06, 750.18it/s]
 13%|█▎        | 675/5153 [00:00<00:05, 752.32it/s]
 15%|█▍        | 751/5153 [00:01<00:05, 754.45it/s]
 16%|█▌        | 827/5153 [00:01<00:05, 753.79it/s]
 18%|█▊        | 903/5153 [00:01<00:05, 755.41it/s]
 19%|█▉        | 979/5153 [00:01<00:05, 755.09it/s]
 20%|██        | 1056/5153 [00:01<00:05, 756.89it/s]
 22%|██▏       | 1134/5153 [00:01<00:05, 761.53it/s]
 24%|██▎       | 1212/5153 [00:01<00:05, 765.34it/s]
 25%|██▌       | 1290/5153 [00:01<00:05, 767.20it/s]
 27%|██▋       | 1368/5153 [00:01<00:04, 768.17it/s]
 28%|██▊       | 1445/5153 [00:01<00:04, 765.61it/s]
 30%|██▉       | 1522/5153 [00:02<00:04, 765.01it/s]
 31%|███       | 1600/5153 [00:02<00:04, 767.08it/s]
 33%|███▎      | 1677/5153 [00:02<00:04, 766.49it/s]
 34%|███▍      | 1754/5153 [00:02<00:04, 762.83it/s]
 36%|███▌      | 1831/5153 [00:02<00:04, 761.76it/s]
 37%|███▋      | 1908/5153 [00:02<00:04, 761.79it/s]
 39%|███▊      | 1985/5153 [00:02<00:04, 764.13it/s]
 40%|████      | 2063/5153 [00:02<00:04, 766.03it/s]
 42%|████▏     | 2140/5153 [00:02<00:03, 767.01it/s]
 43%|████▎     | 2218/5153 [00:02<00:03, 768.58it/s]
 45%|████▍     | 2296/5153 [00:03<00:03, 769.44it/s]
 46%|████▌     | 2374/5153 [00:03<00:03, 770.89it/s]
 48%|████▊     | 2452/5153 [00:03<00:03, 771.97it/s]
 49%|████▉     | 2530/5153 [00:03<00:03, 773.01it/s]
 51%|█████     | 2608/5153 [00:03<00:03, 773.65it/s]
 52%|█████▏    | 2686/5153 [00:03<00:03, 774.12it/s]
 54%|█████▎    | 2764/5153 [00:03<00:03, 774.19it/s]
 55%|█████▌    | 2842/5153 [00:03<00:02, 775.09it/s]
 57%|█████▋    | 2920/5153 [00:03<00:02, 774.95it/s]
 58%|█████▊    | 2998/5153 [00:03<00:02, 774.31it/s]
 60%|█████▉    | 3076/5153 [00:04<00:02, 773.92it/s]
 61%|██████    | 3154/5153 [00:04<00:02, 773.13it/s]
 63%|██████▎   | 3232/5153 [00:04<00:02, 768.60it/s]
 64%|██████▍   | 3309/5153 [00:04<00:02, 766.77it/s]
 66%|██████▌   | 3386/5153 [00:04<00:02, 764.39it/s]
 67%|██████▋   | 3464/5153 [00:04<00:02, 766.47it/s]
 69%|██████▊   | 3542/5153 [00:04<00:02, 768.31it/s]
 70%|███████   | 3620/5153 [00:04<00:01, 769.75it/s]
 72%|███████▏  | 3698/5153 [00:04<00:01, 770.68it/s]
 73%|███████▎  | 3776/5153 [00:04<00:01, 772.61it/s]
 75%|███████▍  | 3854/5153 [00:05<00:01, 770.70it/s]
 76%|███████▋  | 3932/5153 [00:05<00:01, 771.77it/s]
 78%|███████▊  | 4010/5153 [00:05<00:01, 772.94it/s]
 79%|███████▉  | 4088/5153 [00:05<00:01, 774.23it/s]
 81%|████████  | 4166/5153 [00:05<00:01, 771.01it/s]
 82%|████████▏ | 4244/5153 [00:05<00:01, 767.94it/s]
 84%|████████▍ | 4322/5153 [00:05<00:01, 768.80it/s]
 85%|████████▌ | 4400/5153 [00:05<00:00, 769.74it/s]
 87%|████████▋ | 4477/5153 [00:05<00:00, 768.52it/s]
 88%|████████▊ | 4554/5153 [00:05<00:00, 765.76it/s]
 90%|████████▉ | 4631/5153 [00:06<00:00, 764.10it/s]
 91%|█████████▏| 4708/5153 [00:06<00:00, 763.64it/s]
 93%|█████████▎| 4785/5153 [00:06<00:00, 763.73it/s]
 94%|█████████▍| 4862/5153 [00:06<00:00, 761.73it/s]
 96%|█████████▌| 4940/5153 [00:06<00:00, 764.73it/s]
 97%|█████████▋| 5018/5153 [00:06<00:00, 767.93it/s]
 99%|█████████▉| 5096/5153 [00:06<00:00, 770.77it/s]
100%|██████████| 5153/5153 [00:06<00:00, 765.06it/s]
2024-11-21:15:13:06,538 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:42,  4.74s/it]
100%|██████████| 10/10 [00:04<00:00,  2.11it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:28:03,644 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:28:03,644 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:28:03,714 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  1%|▏         | 73/5153 [00:00<00:07, 722.78it/s]
  3%|▎         | 148/5153 [00:00<00:06, 736.68it/s]
  4%|▍         | 224/5153 [00:00<00:06, 743.34it/s]
  6%|▌         | 300/5153 [00:00<00:06, 748.71it/s]
  7%|▋         | 377/5153 [00:00<00:06, 753.07it/s]
  9%|▉         | 454/5153 [00:00<00:06, 755.83it/s]
 10%|█         | 531/5153 [00:00<00:06, 757.99it/s]
 12%|█▏        | 608/5153 [00:00<00:05, 759.88it/s]
 13%|█▎        | 685/5153 [00:00<00:05, 761.44it/s]
 15%|█▍        | 762/5153 [00:01<00:05, 762.68it/s]
 16%|█▋        | 839/5153 [00:01<00:05, 764.21it/s]
 18%|█▊        | 916/5153 [00:01<00:05, 764.96it/s]
 19%|█▉        | 993/5153 [00:01<00:05, 765.57it/s]
 21%|██        | 1070/5153 [00:01<00:05, 765.87it/s]
 22%|██▏       | 1147/5153 [00:01<00:05, 766.60it/s]
 24%|██▍       | 1224/5153 [00:01<00:05, 767.62it/s]
 25%|██▌       | 1301/5153 [00:01<00:05, 768.11it/s]
 27%|██▋       | 1378/5153 [00:01<00:04, 768.50it/s]
 28%|██▊       | 1456/5153 [00:01<00:04, 769.16it/s]
 30%|██▉       | 1534/5153 [00:02<00:04, 769.77it/s]
 31%|███▏      | 1612/5153 [00:02<00:04, 770.05it/s]
 33%|███▎      | 1690/5153 [00:02<00:04, 770.66it/s]
 34%|███▍      | 1768/5153 [00:02<00:04, 770.99it/s]
 36%|███▌      | 1846/5153 [00:02<00:04, 771.18it/s]
 37%|███▋      | 1924/5153 [00:02<00:04, 771.05it/s]
 39%|███▉      | 2002/5153 [00:02<00:04, 771.18it/s]
 40%|████      | 2080/5153 [00:02<00:03, 771.15it/s]
 42%|████▏     | 2158/5153 [00:02<00:03, 771.57it/s]
 43%|████▎     | 2236/5153 [00:02<00:03, 771.95it/s]
 45%|████▍     | 2314/5153 [00:03<00:03, 772.14it/s]
 46%|████▋     | 2392/5153 [00:03<00:03, 772.64it/s]
 48%|████▊     | 2470/5153 [00:03<00:03, 772.97it/s]
 49%|████▉     | 2548/5153 [00:03<00:03, 773.38it/s]
 51%|█████     | 2626/5153 [00:03<00:03, 773.72it/s]
 52%|█████▏    | 2704/5153 [00:03<00:03, 773.71it/s]
 54%|█████▍    | 2782/5153 [00:03<00:03, 774.02it/s]
 56%|█████▌    | 2860/5153 [00:03<00:02, 773.84it/s]
 57%|█████▋    | 2938/5153 [00:03<00:02, 773.02it/s]
 59%|█████▊    | 3016/5153 [00:03<00:02, 772.39it/s]
 60%|██████    | 3094/5153 [00:04<00:02, 772.86it/s]
 62%|██████▏   | 3172/5153 [00:04<00:02, 773.38it/s]
 63%|██████▎   | 3250/5153 [00:04<00:02, 773.40it/s]
 65%|██████▍   | 3328/5153 [00:04<00:02, 773.71it/s]
 66%|██████▌   | 3406/5153 [00:04<00:02, 774.64it/s]
 68%|██████▊   | 3484/5153 [00:04<00:02, 774.72it/s]
 69%|██████▉   | 3562/5153 [00:04<00:02, 773.67it/s]
 71%|███████   | 3640/5153 [00:04<00:01, 772.96it/s]
 72%|███████▏  | 3718/5153 [00:04<00:01, 772.73it/s]
 74%|███████▎  | 3796/5153 [00:04<00:01, 772.26it/s]
 75%|███████▌  | 3874/5153 [00:05<00:01, 772.84it/s]
 77%|███████▋  | 3952/5153 [00:05<00:01, 768.63it/s]
 78%|███████▊  | 4030/5153 [00:05<00:01, 769.61it/s]
 80%|███████▉  | 4108/5153 [00:05<00:01, 771.31it/s]
 81%|████████  | 4186/5153 [00:05<00:01, 772.53it/s]
 83%|████████▎ | 4264/5153 [00:05<00:01, 771.29it/s]
 84%|████████▍ | 4342/5153 [00:05<00:01, 771.95it/s]
 86%|████████▌ | 4420/5153 [00:05<00:00, 772.56it/s]
 87%|████████▋ | 4498/5153 [00:05<00:00, 772.80it/s]
 89%|████████▉ | 4576/5153 [00:05<00:00, 772.80it/s]
 90%|█████████ | 4654/5153 [00:06<00:00, 773.23it/s]
 92%|█████████▏| 4732/5153 [00:06<00:00, 773.56it/s]
 93%|█████████▎| 4810/5153 [00:06<00:00, 773.69it/s]
 95%|█████████▍| 4888/5153 [00:06<00:00, 773.04it/s]
 96%|█████████▋| 4966/5153 [00:06<00:00, 773.72it/s]
 98%|█████████▊| 5044/5153 [00:06<00:00, 774.26it/s]
 99%|█████████▉| 5122/5153 [00:06<00:00, 775.31it/s]
100%|██████████| 5153/5153 [00:06<00:00, 769.63it/s]
2024-11-21:15:28:10,474 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:42,  4.77s/it]
100%|██████████| 10/10 [00:04<00:00,  2.08it/s]

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-tunefull-x58
#
# Epoch = 2407 to 4813 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-tunefull-x58/rwkv-2406.pth', 'wandb': '', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-tunefull-x58', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 2407, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x058', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-23-16-19-00', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': '04b-tunefull-x58', 'my_pile_prev_p': 2405}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-tunefull-x58/rwkv-2406.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb  --proj_dir /sfs ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 233 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
367 M     Trainable params
0         Non-trainable params
367 M     Total params
1,469.399 Total estimated model params size (MB)
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py:437: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
  rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)12=48, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/02b-pre-x59
#
# Epoch = 0 to 2406 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 840 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/02b-pre-x59/rwkv-init.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/02b-pre-x59', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 840, 'epoch_count': 2407, 'epoch_begin': 0, 'epoch_save': 10, 'micro_bsz': 12, 'n_layer': 12, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-10-03-11-56-51', 'betas': (0.9, 0.99), 'real_bsz': 48, 'run_name': '02b-pre-x59'}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/02b-pre-x59/rwkv-init.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 116 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
250 M     Trainable params
0         Non-trainable params
250 M     Total params
1,003.389 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20241003_115751-mqvt5b5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 02b-pre-x59 2024-10-03-11-56-51
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/mqvt5b5m
slurmstepd: error: *** JOB 64649129 ON udc-an36-19 CANCELLED AT 2024-10-06T11:56:49 DUE TO TIME LIMIT ***

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)16=64, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x595
#
# Epoch = 0 to 2406 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 630 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x595/rwkv-init.pth', 'wandb': '', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x595', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 630, 'epoch_count': 2407, 'epoch_begin': 0, 'epoch_save': 10, 'micro_bsz': 16, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 2, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x0595', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 46068, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-18-22-41-37', 'betas': (0.9, 0.99), 'real_bsz': 64, 'run_name': '04b-pre-x595'}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x595/rwkv-init.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb  --proj_dir /sfs ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 44.0 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
144 M     Trainable params
0         Non-trainable params
144 M     Total params
578.617   Total estimated model params size (MB)
slurmstepd: error: *** JOB 64220238 ON udc-ba02-38 CANCELLED AT 2024-09-21T22:41:46 DUE TO TIME LIMIT ***

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)3=12, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-tunefull-x58
#
# Epoch = 896 to 3302 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 3360 steps, 40320 samples, 82575360 tokens
#
# Model = 32 n_layer, 2560 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-tunefull-x58/rwkv-895.pth', 'wandb': '', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-tunefull-x58', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 3360, 'epoch_count': 2407, 'epoch_begin': 896, 'epoch_save': 10, 'micro_bsz': 3, 'n_layer': 32, 'n_embd': 2560, 'dim_att': 2560, 'dim_ffn': 8960, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x058', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-23-17-34-39', 'betas': (0.9, 0.99), 'real_bsz': 12, 'run_name': '3b-tunefull-x58', 'my_pile_prev_p': 885}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-tunefull-x58/rwkv-895.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb  --proj_dir /sfs ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 167 M 
1 | blocks | ModuleList | 1.9 B 
2 | ln_out | LayerNorm  | 5.1 K 
3 | head   | Linear     | 167 M 
--------------------------------------
2.3 B     Trainable params
0         Non-trainable params
2.3 B     Total params
9,106.268 Total estimated model params size (MB)

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:55:45,310 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:45,311 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:55:45,355 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1021.68it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1030.21it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1033.48it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1034.80it/s]
 10%|█         | 519/5153 [00:00<00:04, 1035.50it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1038.49it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1041.23it/s]
 16%|█▌        | 834/5153 [00:00<00:04, 1033.27it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1038.53it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1042.80it/s]
 22%|██▏       | 1152/5153 [00:01<00:03, 1045.46it/s]
 24%|██▍       | 1258/5153 [00:01<00:03, 1048.18it/s]
 26%|██▋       | 1363/5153 [00:01<00:03, 1048.43it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1049.08it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1048.23it/s]
 33%|███▎      | 1679/5153 [00:01<00:03, 1045.42it/s]
 35%|███▍      | 1784/5153 [00:01<00:03, 1041.92it/s]
 37%|███▋      | 1889/5153 [00:01<00:03, 1042.76it/s]
 39%|███▊      | 1994/5153 [00:01<00:03, 1044.28it/s]
 41%|████      | 2099/5153 [00:02<00:02, 1032.91it/s]
 43%|████▎     | 2205/5153 [00:02<00:02, 1038.24it/s]
 45%|████▍     | 2311/5153 [00:02<00:02, 1042.64it/s]
 47%|████▋     | 2417/5153 [00:02<00:02, 1045.08it/s]
 49%|████▉     | 2523/5153 [00:02<00:02, 1046.77it/s]
 51%|█████     | 2628/5153 [00:02<00:02, 1047.25it/s]
 53%|█████▎    | 2734/5153 [00:02<00:02, 1048.23it/s]
 55%|█████▌    | 2840/5153 [00:02<00:02, 1049.03it/s]
 57%|█████▋    | 2945/5153 [00:02<00:02, 1047.17it/s]
 59%|█████▉    | 3050/5153 [00:02<00:02, 1046.11it/s]
 61%|██████    | 3155/5153 [00:03<00:01, 1045.56it/s]
 63%|██████▎   | 3260/5153 [00:03<00:01, 1045.31it/s]
 65%|██████▌   | 3365/5153 [00:03<00:01, 1039.01it/s]
 67%|██████▋   | 3470/5153 [00:03<00:01, 1041.66it/s]
 69%|██████▉   | 3576/5153 [00:03<00:01, 1045.70it/s]
 71%|███████▏  | 3682/5153 [00:03<00:01, 1048.49it/s]
 73%|███████▎  | 3787/5153 [00:03<00:01, 1048.75it/s]
 76%|███████▌  | 3893/5153 [00:03<00:01, 1050.04it/s]
 78%|███████▊  | 3999/5153 [00:03<00:01, 1049.90it/s]
 80%|███████▉  | 4105/5153 [00:03<00:00, 1051.42it/s]
 82%|████████▏ | 4211/5153 [00:04<00:00, 1050.27it/s]
 84%|████████▍ | 4317/5153 [00:04<00:00, 1048.63it/s]
 86%|████████▌ | 4423/5153 [00:04<00:00, 1049.08it/s]
 88%|████████▊ | 4529/5153 [00:04<00:00, 1049.44it/s]
 90%|████████▉ | 4634/5153 [00:04<00:00, 1049.54it/s]
 92%|█████████▏| 4740/5153 [00:04<00:00, 1050.18it/s]
 94%|█████████▍| 4846/5153 [00:04<00:00, 1050.76it/s]
 96%|█████████▌| 4952/5153 [00:04<00:00, 1050.16it/s]
 98%|█████████▊| 5058/5153 [00:04<00:00, 1051.30it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1045.34it/s]
2024-11-21:14:55:50,328 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:02<00:26,  2.98s/it]
100%|██████████| 10/10 [00:03<00:00,  3.31it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:05:34,269 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:05:34,269 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:05:34,313 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1027.19it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1030.65it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1018.29it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1027.31it/s]
 10%|█         | 521/5153 [00:00<00:04, 1033.81it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1038.61it/s]
 14%|█▍        | 732/5153 [00:00<00:04, 1042.61it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1044.88it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1045.93it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1047.75it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1050.08it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1052.30it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1053.02it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1040.23it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1044.00it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1047.84it/s]
 35%|███▍      | 1790/5153 [00:01<00:03, 1050.07it/s]
 37%|███▋      | 1896/5153 [00:01<00:03, 1050.87it/s]
 39%|███▉      | 2002/5153 [00:01<00:02, 1052.47it/s]
 41%|████      | 2108/5153 [00:02<00:02, 1053.69it/s]
 43%|████▎     | 2214/5153 [00:02<00:02, 1052.83it/s]
 45%|████▌     | 2320/5153 [00:02<00:02, 1052.29it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1054.20it/s]
 49%|████▉     | 2533/5153 [00:02<00:02, 1056.98it/s]
 51%|█████     | 2640/5153 [00:02<00:02, 1057.93it/s]
 53%|█████▎    | 2746/5153 [00:02<00:02, 1047.00it/s]
 55%|█████▌    | 2851/5153 [00:02<00:02, 1046.24it/s]
 57%|█████▋    | 2957/5153 [00:02<00:02, 1049.29it/s]
 59%|█████▉    | 3063/5153 [00:02<00:01, 1050.04it/s]
 61%|██████▏   | 3169/5153 [00:03<00:01, 1051.37it/s]
 64%|██████▎   | 3275/5153 [00:03<00:01, 1052.30it/s]
 66%|██████▌   | 3381/5153 [00:03<00:01, 1051.58it/s]
 68%|██████▊   | 3487/5153 [00:03<00:01, 1051.52it/s]
 70%|██████▉   | 3593/5153 [00:03<00:01, 1051.88it/s]
 72%|███████▏  | 3699/5153 [00:03<00:01, 1051.98it/s]
 74%|███████▍  | 3805/5153 [00:03<00:01, 1054.13it/s]
 76%|███████▌  | 3911/5153 [00:03<00:01, 1055.41it/s]
 78%|███████▊  | 4017/5153 [00:03<00:01, 1056.08it/s]
 80%|████████  | 4123/5153 [00:03<00:00, 1056.99it/s]
 82%|████████▏ | 4229/5153 [00:04<00:00, 1056.89it/s]
 84%|████████▍ | 4335/5153 [00:04<00:00, 1053.80it/s]
 86%|████████▌ | 4441/5153 [00:04<00:00, 1054.69it/s]
 88%|████████▊ | 4547/5153 [00:04<00:00, 1054.66it/s]
 90%|█████████ | 4653/5153 [00:04<00:00, 1053.94it/s]
 92%|█████████▏| 4759/5153 [00:04<00:00, 1052.46it/s]
 94%|█████████▍| 4865/5153 [00:04<00:00, 1050.57it/s]
 96%|█████████▋| 4971/5153 [00:04<00:00, 1050.71it/s]
 99%|█████████▊| 5077/5153 [00:04<00:00, 1051.07it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.57it/s]
2024-11-21:15:05:39,265 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:02<00:26,  2.99s/it]
100%|██████████| 10/10 [00:02<00:00,  3.34it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:15:24,578 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:15:24,578 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:15:24,624 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.53it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1036.40it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1038.51it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1042.26it/s]
 10%|█         | 524/5153 [00:00<00:04, 1045.16it/s]
 12%|█▏        | 631/5153 [00:00<00:04, 1050.39it/s]
 14%|█▍        | 738/5153 [00:00<00:04, 1054.06it/s]
 16%|█▋        | 844/5153 [00:00<00:04, 1054.83it/s]
 18%|█▊        | 950/5153 [00:00<00:04, 1043.80it/s]
 21%|██        | 1057/5153 [00:01<00:03, 1050.07it/s]
 23%|██▎       | 1164/5153 [00:01<00:03, 1054.44it/s]
 25%|██▍       | 1271/5153 [00:01<00:03, 1056.24it/s]
 27%|██▋       | 1377/5153 [00:01<00:03, 1057.05it/s]
 29%|██▉       | 1483/5153 [00:01<00:03, 1056.92it/s]
 31%|███       | 1590/5153 [00:01<00:03, 1058.27it/s]
 33%|███▎      | 1696/5153 [00:01<00:03, 1057.66it/s]
 35%|███▍      | 1803/5153 [00:01<00:03, 1058.50it/s]
 37%|███▋      | 1909/5153 [00:01<00:03, 1057.97it/s]
 39%|███▉      | 2016/5153 [00:01<00:02, 1059.39it/s]
 41%|████      | 2122/5153 [00:02<00:02, 1053.34it/s]
 43%|████▎     | 2229/5153 [00:02<00:02, 1057.41it/s]
 45%|████▌     | 2336/5153 [00:02<00:02, 1059.76it/s]
 47%|████▋     | 2443/5153 [00:02<00:02, 1062.15it/s]
 49%|████▉     | 2550/5153 [00:02<00:02, 1062.07it/s]
 52%|█████▏    | 2657/5153 [00:02<00:02, 1060.90it/s]
 54%|█████▎    | 2764/5153 [00:02<00:02, 1061.13it/s]
 56%|█████▌    | 2871/5153 [00:02<00:02, 1059.58it/s]
 58%|█████▊    | 2977/5153 [00:02<00:02, 1057.95it/s]
 60%|█████▉    | 3083/5153 [00:02<00:01, 1058.51it/s]
 62%|██████▏   | 3189/5153 [00:03<00:01, 1058.04it/s]
 64%|██████▍   | 3296/5153 [00:03<00:01, 1058.82it/s]
 66%|██████▌   | 3402/5153 [00:03<00:01, 1059.15it/s]
 68%|██████▊   | 3509/5153 [00:03<00:01, 1061.63it/s]
 70%|███████   | 3616/5153 [00:03<00:01, 1061.31it/s]
 72%|███████▏  | 3723/5153 [00:03<00:01, 1060.86it/s]
 74%|███████▍  | 3830/5153 [00:03<00:01, 1059.68it/s]
 76%|███████▋  | 3936/5153 [00:03<00:01, 1058.92it/s]
 78%|███████▊  | 4042/5153 [00:03<00:01, 1058.12it/s]
 80%|████████  | 4148/5153 [00:03<00:00, 1057.57it/s]
 83%|████████▎ | 4254/5153 [00:04<00:00, 1057.00it/s]
 85%|████████▍ | 4360/5153 [00:04<00:00, 1056.50it/s]
 87%|████████▋ | 4467/5153 [00:04<00:00, 1057.78it/s]
 89%|████████▊ | 4573/5153 [00:04<00:00, 1058.30it/s]
 91%|█████████ | 4680/5153 [00:04<00:00, 1058.90it/s]
 93%|█████████▎| 4786/5153 [00:04<00:00, 1058.27it/s]
 95%|█████████▍| 4892/5153 [00:04<00:00, 1057.34it/s]
 97%|█████████▋| 4998/5153 [00:04<00:00, 1053.84it/s]
 99%|█████████▉| 5104/5153 [00:04<00:00, 1053.61it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1056.02it/s]
2024-11-21:15:15:29,547 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.05s/it]
100%|██████████| 10/10 [00:03<00:00,  3.28it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:25:08,032 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:25:08,032 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:25:08,076 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1025.75it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1032.72it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1032.88it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1033.54it/s]
 10%|█         | 519/5153 [00:00<00:04, 1033.99it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1038.45it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1043.19it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1045.29it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1045.93it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1034.23it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1039.01it/s]
 24%|██▍       | 1257/5153 [00:01<00:03, 1042.49it/s]
 26%|██▋       | 1362/5153 [00:01<00:03, 1043.04it/s]
 28%|██▊       | 1467/5153 [00:01<00:03, 1043.91it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1045.41it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1046.49it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1048.37it/s]
 37%|███▋      | 1888/5153 [00:01<00:03, 1048.60it/s]
 39%|███▊      | 1994/5153 [00:01<00:03, 1049.73it/s]
 41%|████      | 2100/5153 [00:02<00:02, 1050.80it/s]
 43%|████▎     | 2206/5153 [00:02<00:02, 1049.73it/s]
 45%|████▍     | 2311/5153 [00:02<00:02, 1041.60it/s]
 47%|████▋     | 2416/5153 [00:02<00:02, 1043.72it/s]
 49%|████▉     | 2522/5153 [00:02<00:02, 1046.98it/s]
 51%|█████     | 2628/5153 [00:02<00:02, 1048.26it/s]
 53%|█████▎    | 2733/5153 [00:02<00:02, 1048.57it/s]
 55%|█████▌    | 2839/5153 [00:02<00:02, 1049.35it/s]
 57%|█████▋    | 2945/5153 [00:02<00:02, 1049.62it/s]
 59%|█████▉    | 3051/5153 [00:02<00:02, 1050.72it/s]
 61%|██████▏   | 3157/5153 [00:03<00:01, 1050.78it/s]
 63%|██████▎   | 3263/5153 [00:03<00:01, 1052.57it/s]
 65%|██████▌   | 3369/5153 [00:03<00:01, 1052.92it/s]
 67%|██████▋   | 3475/5153 [00:03<00:01, 1051.08it/s]
 69%|██████▉   | 3581/5153 [00:03<00:01, 1050.12it/s]
 72%|███████▏  | 3687/5153 [00:03<00:01, 1050.02it/s]
 74%|███████▎  | 3793/5153 [00:03<00:01, 1050.08it/s]
 76%|███████▌  | 3899/5153 [00:03<00:01, 1046.90it/s]
 78%|███████▊  | 4004/5153 [00:03<00:01, 1046.00it/s]
 80%|███████▉  | 4109/5153 [00:03<00:01, 1043.81it/s]
 82%|████████▏ | 4214/5153 [00:04<00:00, 1043.92it/s]
 84%|████████▍ | 4319/5153 [00:04<00:00, 1045.53it/s]
 86%|████████▌ | 4425/5153 [00:04<00:00, 1048.03it/s]
 88%|████████▊ | 4531/5153 [00:04<00:00, 1049.62it/s]
 90%|████████▉ | 4637/5153 [00:04<00:00, 1050.58it/s]
 92%|█████████▏| 4743/5153 [00:04<00:00, 1050.44it/s]
 94%|█████████▍| 4849/5153 [00:04<00:00, 1049.96it/s]
 96%|█████████▌| 4955/5153 [00:04<00:00, 1050.37it/s]
 98%|█████████▊| 5061/5153 [00:04<00:00, 1050.34it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1046.37it/s]
2024-11-21:15:25:13,042 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.06s/it]
100%|██████████| 10/10 [00:03<00:00,  3.27it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:35:22,679 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:35:22,679 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:35:22,724 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1022.83it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1029.06it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1033.93it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1038.11it/s]
 10%|█         | 521/5153 [00:00<00:04, 1040.04it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1041.89it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1041.58it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1042.34it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1042.43it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1032.64it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1037.25it/s]
 24%|██▍       | 1257/5153 [00:01<00:03, 1042.27it/s]
 26%|██▋       | 1363/5153 [00:01<00:03, 1045.70it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1048.03it/s]
 31%|███       | 1575/5153 [00:01<00:03, 1049.43it/s]
 33%|███▎      | 1681/5153 [00:01<00:03, 1050.06it/s]
 35%|███▍      | 1787/5153 [00:01<00:03, 1049.60it/s]
 37%|███▋      | 1892/5153 [00:01<00:03, 1049.08it/s]
 39%|███▉      | 1997/5153 [00:01<00:03, 1048.66it/s]
 41%|████      | 2102/5153 [00:02<00:02, 1048.98it/s]
 43%|████▎     | 2207/5153 [00:02<00:02, 1048.56it/s]
 45%|████▍     | 2312/5153 [00:02<00:02, 1039.19it/s]
 47%|████▋     | 2418/5153 [00:02<00:02, 1043.09it/s]
 49%|████▉     | 2524/5153 [00:02<00:02, 1046.69it/s]
 51%|█████     | 2630/5153 [00:02<00:02, 1048.18it/s]
 53%|█████▎    | 2735/5153 [00:02<00:02, 1045.99it/s]
 55%|█████▌    | 2840/5153 [00:02<00:02, 1045.21it/s]
 57%|█████▋    | 2945/5153 [00:02<00:02, 1046.24it/s]
 59%|█████▉    | 3050/5153 [00:02<00:02, 1046.04it/s]
 61%|██████    | 3155/5153 [00:03<00:01, 1046.03it/s]
 63%|██████▎   | 3260/5153 [00:03<00:01, 1045.23it/s]
 65%|██████▌   | 3365/5153 [00:03<00:01, 1045.57it/s]
 67%|██████▋   | 3470/5153 [00:03<00:01, 1045.65it/s]
 69%|██████▉   | 3575/5153 [00:03<00:01, 1046.49it/s]
 71%|███████▏  | 3680/5153 [00:03<00:01, 1047.48it/s]
 73%|███████▎  | 3785/5153 [00:03<00:01, 1047.55it/s]
 75%|███████▌  | 3890/5153 [00:03<00:01, 1045.60it/s]
 78%|███████▊  | 3995/5153 [00:03<00:01, 1045.24it/s]
 80%|███████▉  | 4100/5153 [00:03<00:01, 1045.68it/s]
 82%|████████▏ | 4205/5153 [00:04<00:00, 1046.69it/s]
 84%|████████▎ | 4310/5153 [00:04<00:00, 1046.76it/s]
 86%|████████▌ | 4415/5153 [00:04<00:00, 1047.65it/s]
 88%|████████▊ | 4521/5153 [00:04<00:00, 1048.56it/s]
 90%|████████▉ | 4626/5153 [00:04<00:00, 1048.56it/s]
 92%|█████████▏| 4732/5153 [00:04<00:00, 1049.73it/s]
 94%|█████████▍| 4838/5153 [00:04<00:00, 1050.03it/s]
 96%|█████████▌| 4944/5153 [00:04<00:00, 1050.92it/s]
 98%|█████████▊| 5050/5153 [00:04<00:00, 1051.80it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1045.77it/s]
2024-11-21:15:35:27,694 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.03s/it]
100%|██████████| 10/10 [00:03<00:00,  3.30it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:45:10,108 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:45:10,108 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:45:10,152 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 105/5153 [00:00<00:04, 1041.29it/s]
  4%|▍         | 210/5153 [00:00<00:04, 1045.08it/s]
  6%|▌         | 316/5153 [00:00<00:04, 1048.77it/s]
  8%|▊         | 421/5153 [00:00<00:04, 1038.87it/s]
 10%|█         | 527/5153 [00:00<00:04, 1043.13it/s]
 12%|█▏        | 633/5153 [00:00<00:04, 1046.87it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1049.38it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1051.55it/s]
 18%|█▊        | 952/5153 [00:00<00:03, 1054.70it/s]
 21%|██        | 1059/5153 [00:01<00:03, 1056.45it/s]
 23%|██▎       | 1166/5153 [00:01<00:03, 1057.99it/s]
 25%|██▍       | 1272/5153 [00:01<00:03, 1058.35it/s]
 27%|██▋       | 1379/5153 [00:01<00:03, 1060.13it/s]
 29%|██▉       | 1486/5153 [00:01<00:03, 1059.83it/s]
 31%|███       | 1593/5153 [00:01<00:03, 1060.21it/s]
 33%|███▎      | 1700/5153 [00:01<00:03, 1041.85it/s]
 35%|███▌      | 1806/5153 [00:01<00:03, 1046.84it/s]
 37%|███▋      | 1912/5153 [00:01<00:03, 1050.25it/s]
 39%|███▉      | 2018/5153 [00:01<00:02, 1053.01it/s]
 41%|████      | 2125/5153 [00:02<00:02, 1056.31it/s]
 43%|████▎     | 2232/5153 [00:02<00:02, 1058.18it/s]
 45%|████▌     | 2338/5153 [00:02<00:02, 1058.62it/s]
 47%|████▋     | 2445/5153 [00:02<00:02, 1061.29it/s]
 50%|████▉     | 2552/5153 [00:02<00:02, 1063.60it/s]
 52%|█████▏    | 2659/5153 [00:02<00:02, 1062.56it/s]
 54%|█████▎    | 2766/5153 [00:02<00:02, 1064.33it/s]
 56%|█████▌    | 2873/5153 [00:02<00:02, 1055.76it/s]
 58%|█████▊    | 2979/5153 [00:02<00:02, 1056.43it/s]
 60%|█████▉    | 3085/5153 [00:02<00:01, 1056.60it/s]
 62%|██████▏   | 3192/5153 [00:03<00:01, 1058.36it/s]
 64%|██████▍   | 3299/5153 [00:03<00:01, 1059.72it/s]
 66%|██████▌   | 3406/5153 [00:03<00:01, 1061.08it/s]
 68%|██████▊   | 3513/5153 [00:03<00:01, 1061.84it/s]
 70%|███████   | 3620/5153 [00:03<00:01, 1061.86it/s]
 72%|███████▏  | 3727/5153 [00:03<00:01, 1061.62it/s]
 74%|███████▍  | 3834/5153 [00:03<00:01, 1062.16it/s]
 76%|███████▋  | 3941/5153 [00:03<00:01, 1061.95it/s]
 79%|███████▊  | 4048/5153 [00:03<00:01, 1061.88it/s]
 81%|████████  | 4155/5153 [00:03<00:00, 1062.15it/s]
 83%|████████▎ | 4262/5153 [00:04<00:00, 1060.53it/s]
 85%|████████▍ | 4369/5153 [00:04<00:00, 1060.25it/s]
 87%|████████▋ | 4476/5153 [00:04<00:00, 1059.25it/s]
 89%|████████▉ | 4582/5153 [00:04<00:00, 1059.33it/s]
 91%|█████████ | 4689/5153 [00:04<00:00, 1060.61it/s]
 93%|█████████▎| 4796/5153 [00:04<00:00, 1060.90it/s]
 95%|█████████▌| 4903/5153 [00:04<00:00, 1060.22it/s]
 97%|█████████▋| 5010/5153 [00:04<00:00, 1059.87it/s]
 99%|█████████▉| 5117/5153 [00:04<00:00, 1060.88it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1057.20it/s]
2024-11-21:15:45:15,068 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:02<00:26,  2.98s/it]
100%|██████████| 10/10 [00:03<00:00,  3.27it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:55:01,694 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:55:01,694 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:55:01,737 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1025.72it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1028.08it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1031.50it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1018.61it/s]
 10%|█         | 519/5153 [00:00<00:04, 1027.29it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1034.12it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1039.05it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1042.71it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1044.15it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1045.89it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1047.59it/s]
 24%|██▍       | 1257/5153 [00:01<00:03, 1048.47it/s]
 26%|██▋       | 1362/5153 [00:01<00:03, 1047.66it/s]
 28%|██▊       | 1468/5153 [00:01<00:03, 1048.47it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1049.46it/s]
 33%|███▎      | 1679/5153 [00:01<00:03, 1028.72it/s]
 35%|███▍      | 1784/5153 [00:01<00:03, 1033.89it/s]
 37%|███▋      | 1889/5153 [00:01<00:03, 1038.09it/s]
 39%|███▊      | 1995/5153 [00:01<00:03, 1042.32it/s]
 41%|████      | 2101/5153 [00:02<00:02, 1046.33it/s]
 43%|████▎     | 2207/5153 [00:02<00:02, 1049.86it/s]
 45%|████▍     | 2313/5153 [00:02<00:02, 1050.89it/s]
 47%|████▋     | 2419/5153 [00:02<00:02, 1051.76it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1052.89it/s]
 51%|█████     | 2631/5153 [00:02<00:02, 1051.48it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1051.66it/s]
 55%|█████▌    | 2843/5153 [00:02<00:02, 1051.92it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1042.08it/s]
 59%|█████▉    | 3054/5153 [00:02<00:02, 1042.58it/s]
 61%|██████▏   | 3159/5153 [00:03<00:01, 1043.91it/s]
 63%|██████▎   | 3265/5153 [00:03<00:01, 1046.68it/s]
 65%|██████▌   | 3371/5153 [00:03<00:01, 1048.55it/s]
 67%|██████▋   | 3477/5153 [00:03<00:01, 1049.23it/s]
 70%|██████▉   | 3582/5153 [00:03<00:01, 1048.89it/s]
 72%|███████▏  | 3687/5153 [00:03<00:01, 1047.85it/s]
 74%|███████▎  | 3793/5153 [00:03<00:01, 1048.79it/s]
 76%|███████▌  | 3898/5153 [00:03<00:01, 1047.98it/s]
 78%|███████▊  | 4003/5153 [00:03<00:01, 1046.56it/s]
 80%|███████▉  | 4109/5153 [00:03<00:00, 1047.90it/s]
 82%|████████▏ | 4214/5153 [00:04<00:00, 1046.63it/s]
 84%|████████▍ | 4319/5153 [00:04<00:00, 1046.90it/s]
 86%|████████▌ | 4424/5153 [00:04<00:00, 1047.22it/s]
 88%|████████▊ | 4529/5153 [00:04<00:00, 1046.16it/s]
 90%|████████▉ | 4635/5153 [00:04<00:00, 1048.26it/s]
 92%|█████████▏| 4741/5153 [00:04<00:00, 1049.89it/s]
 94%|█████████▍| 4847/5153 [00:04<00:00, 1050.23it/s]
 96%|█████████▌| 4953/5153 [00:04<00:00, 1049.47it/s]
 98%|█████████▊| 5058/5153 [00:04<00:00, 1049.12it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1045.27it/s]
2024-11-21:15:55:06,709 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.13s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)24=96, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-FFN1.5x
#
# Epoch = 21 to 2427 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 420 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-FFN1.5x/rwkv-20.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-FFN1.5x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 420, 'epoch_count': 2407, 'epoch_begin': 21, 'epoch_save': 10, 'micro_bsz': 24, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 1152, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-09-19-22-57-04', 'betas': (0.9, 0.99), 'real_bsz': 96, 'run_name': '01b-pre-x59-FFN1.5x', 'my_pile_prev_p': 10}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-FFN1.5x/rwkv-20.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 37.3 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
138 M     Trainable params
0         Non-trainable params
138 M     Total params
552.002   Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240919_225809-ywf5igsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 01b-pre-x59-FFN1.5x 2024-09-19-22-57-04
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/ywf5igsl
wandb: Network error (ConnectionError), entering retry loop.
slurmstepd: error: *** JOB 64227068 ON udc-an36-13 CANCELLED AT 2024-09-22T22:56:53 DUE TO TIME LIMIT ***

========================================
grep: /home/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-tunepart-x58/eval_log.txt: No such file or directory
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.12s/it]
100%|██████████| 10/10 [00:03<00:00,  3.20it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.08s/it]
100%|██████████| 10/10 [00:03<00:00,  3.24it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.25it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.26it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.24it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.24it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.17s/it]
100%|██████████| 10/10 [00:03<00:00,  3.07it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.09s/it]
100%|██████████| 10/10 [00:03<00:00,  3.24it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.24it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.12s/it]
100%|██████████| 10/10 [00:03<00:00,  3.20it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.14s/it]
100%|██████████| 10/10 [00:03<00:00,  3.12it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.11s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.15s/it]
100%|██████████| 10/10 [00:03<00:00,  3.14it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.13s/it]
100%|██████████| 10/10 [00:03<00:00,  3.20it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.06s/it]
100%|██████████| 10/10 [00:03<00:00,  3.25it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.06s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.08s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.14s/it]
100%|██████████| 10/10 [00:03<00:00,  3.18it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.11s/it]
100%|██████████| 10/10 [00:03<00:00,  3.21it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.13s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.08s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.07s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.06s/it]
100%|██████████| 10/10 [00:03<00:00,  3.22it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.09s/it]
100%|██████████| 10/10 [00:03<00:00,  3.21it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
slurmstepd: error: *** JOB 62552389 ON udc-ba04-38 CANCELLED AT 2024-07-16T13:33:08 DUE TO TIME LIMIT ***

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)8=32, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-tunefull-x58
#
# Epoch = 2407 to 4813 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 1260 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 2048 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-tunefull-x58/rwkv-2406.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-tunefull-x58', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 1260, 'epoch_count': 2407, 'epoch_begin': 2407, 'epoch_save': 10, 'micro_bsz': 8, 'n_layer': 24, 'n_embd': 2048, 'dim_att': 2048, 'dim_ffn': 7168, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x058', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-23-16-26-51', 'betas': (0.9, 0.99), 'real_bsz': 32, 'run_name': '1b5-tunefull-x58', 'my_pile_prev_p': 2396}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/1b5-tunefull-x58/rwkv-2406.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 134 M 
1 | blocks | ModuleList | 931 M 
2 | ln_out | LayerNorm  | 4.1 K 
3 | head   | Linear     | 134 M 
--------------------------------------
1.2 B     Trainable params
0         Non-trainable params
1.2 B     Total params
4,801.069 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20241123_162848-fatig8yp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 1b5-tunefull-x58 2024-11-23-16-26-51
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/fatig8yp
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py:437: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
  rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")
wandb: - 0.016 MB of 0.016 MB uploaded
wandb: \ 0.016 MB of 0.030 MB uploaded
wandb: 
wandb: Run history:
wandb:   GRAD: head weight ▃▅▅▇▃▄▄█▄▃▃▄▄▂▂▂▂▇▃▁▅▆▂▄▄▃▂▄▅▅▃▃▄▅▁▃▅▅▇▆
wandb: GRAD: ln_out weight ▁█▄▆▂▄▁▃▃▃▂▄▄▃▂▄▂▄▄▆▃▄▃▂▄▁▂▁▃▅▁▅▅▆▁▁▂▃▅▄
wandb:             Gtokens ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                kt/s ▇█▄█▅▆▄▅▇▃▃▇█▄▆▂▆▇▇▇▇▁▆▂▅▂▆▄▇▃▂▃▄▆▅▇▆█▅▇
wandb:                loss ▆▆▄▇▄▆▆█▆▃▅▄▅▅▃▄▄▆▅▃▅█▄▆▅▃▅▄▃▆▅▆▇▆▁▅▄▆▆▆
wandb:                  lr ▁███████████████████████████████████████
wandb:                  wd ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:   GRAD: head weight 0.39487
wandb: GRAD: ln_out weight 0.02336
wandb:             Gtokens 198.78884
wandb:                kt/s 56.61476
wandb:                loss 1.9668
wandb:                  lr 3e-05
wandb:                  wd 0.001
wandb: 
wandb: 🚀 View run 1b5-tunefull-x58 2024-11-23-16-26-51 at: https://wandb.ai/xsel/rwkv-hpc/runs/fatig8yp
wandb: ⭐️ View project at: https://wandb.ai/xsel/rwkv-hpc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_162848-fatig8yp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)3=12, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59-16x
#
# Epoch = 544 to 2950 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 3360 steps, 40320 samples, 82575360 tokens
#
# Model = 32 n_layer, 2560 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59-16x/rwkv-543.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59-16x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 3360, 'epoch_count': 2407, 'epoch_begin': 544, 'epoch_save': 10, 'micro_bsz': 3, 'n_layer': 32, 'n_embd': 2560, 'dim_att': 2560, 'dim_ffn': 8960, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 16, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-21-15-32-37', 'betas': (0.9, 0.99), 'real_bsz': 12, 'run_name': '3b-pre-x59-16x', 'my_pile_prev_p': 533}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59-16x/rwkv-543.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 167 M 
1 | blocks | ModuleList | 1.8 B 
2 | ln_out | LayerNorm  | 5.1 K 
3 | head   | Linear     | 167 M 
--------------------------------------
2.1 B     Trainable params
0         Non-trainable params
2.1 B     Total params
8,583.619 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20241121_153432-5dqtwgu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 3b-pre-x59-16x 2024-11-21-15-32-37
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/5dqtwgu6

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:51:13,043 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:13,043 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:13,088 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1031.73it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1038.04it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1022.06it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1028.41it/s]
 10%|█         | 521/5153 [00:00<00:04, 1032.25it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1037.34it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1040.95it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1044.11it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1045.13it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1047.08it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1049.46it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1051.57it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1053.50it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1054.09it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1051.55it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1039.21it/s]
 35%|███▍      | 1790/5153 [00:01<00:03, 1042.49it/s]
 37%|███▋      | 1895/5153 [00:01<00:03, 1043.19it/s]
 39%|███▉      | 2000/5153 [00:01<00:03, 1044.50it/s]
 41%|████      | 2106/5153 [00:02<00:02, 1046.48it/s]
 43%|████▎     | 2211/5153 [00:02<00:02, 1047.24it/s]
 45%|████▍     | 2316/5153 [00:02<00:02, 1047.19it/s]
 47%|████▋     | 2421/5153 [00:02<00:02, 1047.75it/s]
 49%|████▉     | 2527/5153 [00:02<00:02, 1050.19it/s]
 51%|█████     | 2633/5153 [00:02<00:02, 1050.50it/s]
 53%|█████▎    | 2739/5153 [00:02<00:02, 1052.85it/s]
 55%|█████▌    | 2845/5153 [00:02<00:02, 1052.03it/s]
 57%|█████▋    | 2951/5153 [00:02<00:02, 1037.51it/s]
 59%|█████▉    | 3057/5153 [00:02<00:02, 1042.32it/s]
 61%|██████▏   | 3163/5153 [00:03<00:01, 1044.84it/s]
 63%|██████▎   | 3269/5153 [00:03<00:01, 1046.74it/s]
 65%|██████▌   | 3375/5153 [00:03<00:01, 1047.94it/s]
 68%|██████▊   | 3480/5153 [00:03<00:01, 1048.40it/s]
 70%|██████▉   | 3586/5153 [00:03<00:01, 1049.84it/s]
 72%|███████▏  | 3691/5153 [00:03<00:01, 1049.47it/s]
 74%|███████▎  | 3797/5153 [00:03<00:01, 1051.60it/s]
 76%|███████▌  | 3903/5153 [00:03<00:01, 1052.62it/s]
 78%|███████▊  | 4009/5153 [00:03<00:01, 1052.36it/s]
 80%|███████▉  | 4115/5153 [00:03<00:00, 1051.96it/s]
 82%|████████▏ | 4221/5153 [00:04<00:00, 1040.00it/s]
 84%|████████▍ | 4327/5153 [00:04<00:00, 1043.11it/s]
 86%|████████▌ | 4433/5153 [00:04<00:00, 1045.54it/s]
 88%|████████▊ | 4539/5153 [00:04<00:00, 1047.87it/s]
 90%|█████████ | 4645/5153 [00:04<00:00, 1049.31it/s]
 92%|█████████▏| 4751/5153 [00:04<00:00, 1051.07it/s]
 94%|█████████▍| 4857/5153 [00:04<00:00, 1051.64it/s]
 96%|█████████▋| 4963/5153 [00:04<00:00, 1053.19it/s]
 98%|█████████▊| 5070/5153 [00:04<00:00, 1057.39it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.22it/s]
2024-11-21:14:51:18,053 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:51:49,973 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:49,973 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:51:50,017 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1024.11it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1030.53it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1031.46it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1014.35it/s]
 10%|█         | 519/5153 [00:00<00:04, 1022.11it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1031.24it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1036.77it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1042.34it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1046.70it/s]
 20%|██        | 1047/5153 [00:01<00:03, 1050.22it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1053.31it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1053.38it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1054.41it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1053.69it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1052.62it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1052.39it/s]
 35%|███▍      | 1790/5153 [00:01<00:03, 1039.84it/s]
 37%|███▋      | 1896/5153 [00:01<00:03, 1044.22it/s]
 39%|███▉      | 2002/5153 [00:01<00:03, 1048.44it/s]
 41%|████      | 2108/5153 [00:02<00:02, 1049.59it/s]
 43%|████▎     | 2214/5153 [00:02<00:02, 1052.54it/s]
 45%|████▌     | 2320/5153 [00:02<00:02, 1052.71it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1053.40it/s]
 49%|████▉     | 2532/5153 [00:02<00:02, 1051.98it/s]
 51%|█████     | 2638/5153 [00:02<00:02, 1050.37it/s]
 53%|█████▎    | 2744/5153 [00:02<00:02, 1048.85it/s]
 55%|█████▌    | 2849/5153 [00:02<00:02, 1047.30it/s]
 57%|█████▋    | 2954/5153 [00:02<00:02, 1031.53it/s]
 59%|█████▉    | 3060/5153 [00:02<00:02, 1037.29it/s]
 61%|██████▏   | 3166/5153 [00:03<00:01, 1041.68it/s]
 63%|██████▎   | 3272/5153 [00:03<00:01, 1046.81it/s]
 66%|██████▌   | 3378/5153 [00:03<00:01, 1050.42it/s]
 68%|██████▊   | 3484/5153 [00:03<00:01, 1052.48it/s]
 70%|██████▉   | 3590/5153 [00:03<00:01, 1054.19it/s]
 72%|███████▏  | 3696/5153 [00:03<00:01, 1054.44it/s]
 74%|███████▍  | 3802/5153 [00:03<00:01, 1053.84it/s]
 76%|███████▌  | 3908/5153 [00:03<00:01, 1051.12it/s]
 78%|███████▊  | 4014/5153 [00:03<00:01, 1050.08it/s]
 80%|███████▉  | 4120/5153 [00:03<00:00, 1049.94it/s]
 82%|████████▏ | 4226/5153 [00:04<00:00, 1051.21it/s]
 84%|████████▍ | 4332/5153 [00:04<00:00, 1040.95it/s]
 86%|████████▌ | 4438/5153 [00:04<00:00, 1045.05it/s]
 88%|████████▊ | 4544/5153 [00:04<00:00, 1049.35it/s]
 90%|█████████ | 4650/5153 [00:04<00:00, 1051.50it/s]
 92%|█████████▏| 4756/5153 [00:04<00:00, 1053.69it/s]
 94%|█████████▍| 4862/5153 [00:04<00:00, 1054.32it/s]
 96%|█████████▋| 4968/5153 [00:04<00:00, 1053.75it/s]
 98%|█████████▊| 5074/5153 [00:04<00:00, 1052.34it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.20it/s]
2024-11-21:14:51:54,980 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:52:26,896 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:26,896 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:26,940 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.78it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1040.55it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1044.48it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1047.84it/s]
 10%|█         | 525/5153 [00:00<00:04, 1049.23it/s]
 12%|█▏        | 632/5153 [00:00<00:04, 1053.85it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1056.33it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1041.67it/s]
 18%|█▊        | 952/5153 [00:00<00:04, 1047.60it/s]
 21%|██        | 1059/5153 [00:01<00:03, 1052.32it/s]
 23%|██▎       | 1166/5153 [00:01<00:03, 1055.55it/s]
 25%|██▍       | 1273/5153 [00:01<00:03, 1057.82it/s]
 27%|██▋       | 1380/5153 [00:01<00:03, 1059.77it/s]
 29%|██▉       | 1487/5153 [00:01<00:03, 1059.86it/s]
 31%|███       | 1594/5153 [00:01<00:03, 1060.94it/s]
 33%|███▎      | 1701/5153 [00:01<00:03, 1060.42it/s]
 35%|███▌      | 1808/5153 [00:01<00:03, 1061.66it/s]
 37%|███▋      | 1915/5153 [00:01<00:03, 1060.51it/s]
 39%|███▉      | 2022/5153 [00:01<00:02, 1059.75it/s]
 41%|████▏     | 2128/5153 [00:02<00:02, 1047.53it/s]
 43%|████▎     | 2235/5153 [00:02<00:02, 1051.70it/s]
 45%|████▌     | 2342/5153 [00:02<00:02, 1054.83it/s]
 48%|████▊     | 2449/5153 [00:02<00:02, 1058.19it/s]
 50%|████▉     | 2556/5153 [00:02<00:02, 1060.24it/s]
 52%|█████▏    | 2663/5153 [00:02<00:02, 1060.25it/s]
 54%|█████▍    | 2771/5153 [00:02<00:02, 1063.22it/s]
 56%|█████▌    | 2878/5153 [00:02<00:02, 1062.92it/s]
 58%|█████▊    | 2985/5153 [00:02<00:02, 1062.06it/s]
 60%|██████    | 3092/5153 [00:02<00:01, 1062.02it/s]
 62%|██████▏   | 3199/5153 [00:03<00:01, 1062.47it/s]
 64%|██████▍   | 3306/5153 [00:03<00:01, 1062.46it/s]
 66%|██████▌   | 3413/5153 [00:03<00:01, 1048.63it/s]
 68%|██████▊   | 3520/5153 [00:03<00:01, 1052.87it/s]
 70%|███████   | 3627/5153 [00:03<00:01, 1056.00it/s]
 72%|███████▏  | 3733/5153 [00:03<00:01, 1056.74it/s]
 75%|███████▍  | 3840/5153 [00:03<00:01, 1058.22it/s]
 77%|███████▋  | 3947/5153 [00:03<00:01, 1060.02it/s]
 79%|███████▊  | 4054/5153 [00:03<00:01, 1059.88it/s]
 81%|████████  | 4161/5153 [00:03<00:00, 1060.78it/s]
 83%|████████▎ | 4268/5153 [00:04<00:00, 1058.34it/s]
 85%|████████▍ | 4374/5153 [00:04<00:00, 1057.60it/s]
 87%|████████▋ | 4480/5153 [00:04<00:00, 1057.41it/s]
 89%|████████▉ | 4587/5153 [00:04<00:00, 1058.24it/s]
 91%|█████████ | 4693/5153 [00:04<00:00, 1046.73it/s]
 93%|█████████▎| 4800/5153 [00:04<00:00, 1051.09it/s]
 95%|█████████▌| 4906/5153 [00:04<00:00, 1053.63it/s]
 97%|█████████▋| 5012/5153 [00:04<00:00, 1055.33it/s]
 99%|█████████▉| 5119/5153 [00:04<00:00, 1057.81it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1056.07it/s]
2024-11-21:14:52:31,863 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:53:03,020 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:03,020 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:03,065 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1023.68it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1029.88it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1012.85it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1023.14it/s]
 10%|█         | 519/5153 [00:00<00:04, 1030.26it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1035.79it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1038.79it/s]
 16%|█▌        | 834/5153 [00:00<00:04, 1041.42it/s]
 18%|█▊        | 939/5153 [00:00<00:04, 1042.91it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1045.34it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1046.73it/s]
 24%|██▍       | 1255/5153 [00:01<00:03, 1047.32it/s]
 26%|██▋       | 1360/5153 [00:01<00:03, 1047.57it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1048.31it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1037.71it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1040.33it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1043.39it/s]
 37%|███▋      | 1888/5153 [00:01<00:03, 1043.40it/s]
 39%|███▊      | 1993/5153 [00:01<00:03, 1043.23it/s]
 41%|████      | 2098/5153 [00:02<00:02, 1044.95it/s]
 43%|████▎     | 2204/5153 [00:02<00:02, 1046.48it/s]
 45%|████▍     | 2309/5153 [00:02<00:02, 1046.46it/s]
 47%|████▋     | 2415/5153 [00:02<00:02, 1048.39it/s]
 49%|████▉     | 2521/5153 [00:02<00:02, 1051.08it/s]
 51%|█████     | 2627/5153 [00:02<00:02, 1051.79it/s]
 53%|█████▎    | 2733/5153 [00:02<00:02, 1051.54it/s]
 55%|█████▌    | 2839/5153 [00:02<00:02, 1037.14it/s]
 57%|█████▋    | 2944/5153 [00:02<00:02, 1039.82it/s]
 59%|█████▉    | 3049/5153 [00:02<00:02, 1042.75it/s]
 61%|██████    | 3154/5153 [00:03<00:01, 1043.94it/s]
 63%|██████▎   | 3259/5153 [00:03<00:01, 1044.74it/s]
 65%|██████▌   | 3364/5153 [00:03<00:01, 1045.11it/s]
 67%|██████▋   | 3469/5153 [00:03<00:01, 1044.49it/s]
 69%|██████▉   | 3574/5153 [00:03<00:01, 1044.64it/s]
 71%|███████▏  | 3679/5153 [00:03<00:01, 1043.72it/s]
 73%|███████▎  | 3784/5153 [00:03<00:01, 1044.19it/s]
 75%|███████▌  | 3890/5153 [00:03<00:01, 1046.26it/s]
 78%|███████▊  | 3996/5153 [00:03<00:01, 1049.21it/s]
 80%|███████▉  | 4102/5153 [00:03<00:01, 1050.80it/s]
 82%|████████▏ | 4208/5153 [00:04<00:00, 1043.69it/s]
 84%|████████▎ | 4314/5153 [00:04<00:00, 1046.52it/s]
 86%|████████▌ | 4419/5153 [00:04<00:00, 1047.21it/s]
 88%|████████▊ | 4524/5153 [00:04<00:00, 1047.28it/s]
 90%|████████▉ | 4629/5153 [00:04<00:00, 1046.84it/s]
 92%|█████████▏| 4734/5153 [00:04<00:00, 1045.86it/s]
 94%|█████████▍| 4839/5153 [00:04<00:00, 1043.76it/s]
 96%|█████████▌| 4944/5153 [00:04<00:00, 1043.23it/s]
 98%|█████████▊| 5049/5153 [00:04<00:00, 1042.66it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1043.39it/s]
2024-11-21:14:53:08,046 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:53:39,865 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:39,866 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:53:39,911 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 99/5153 [00:00<00:05, 984.57it/s]
  4%|▍         | 203/5153 [00:00<00:04, 1017.04it/s]
  6%|▌         | 308/5153 [00:00<00:04, 1027.04it/s]
  8%|▊         | 412/5153 [00:00<00:04, 1031.91it/s]
 10%|█         | 516/5153 [00:00<00:04, 1034.20it/s]
 12%|█▏        | 620/5153 [00:00<00:04, 1035.09it/s]
 14%|█▍        | 726/5153 [00:00<00:04, 1040.84it/s]
 16%|█▌        | 831/5153 [00:00<00:04, 1043.69it/s]
 18%|█▊        | 936/5153 [00:00<00:04, 1043.96it/s]
 20%|██        | 1041/5153 [00:01<00:03, 1045.09it/s]
 22%|██▏       | 1146/5153 [00:01<00:03, 1045.38it/s]
 24%|██▍       | 1252/5153 [00:01<00:03, 1047.18it/s]
 26%|██▋       | 1357/5153 [00:01<00:03, 1035.95it/s]
 28%|██▊       | 1462/5153 [00:01<00:03, 1038.10it/s]
 30%|███       | 1567/5153 [00:01<00:03, 1041.12it/s]
 32%|███▏      | 1672/5153 [00:01<00:03, 1041.88it/s]
 34%|███▍      | 1777/5153 [00:01<00:03, 1044.08it/s]
 37%|███▋      | 1883/5153 [00:01<00:03, 1046.77it/s]
 39%|███▊      | 1989/5153 [00:01<00:03, 1047.71it/s]
 41%|████      | 2095/5153 [00:02<00:02, 1049.42it/s]
 43%|████▎     | 2200/5153 [00:02<00:02, 1047.93it/s]
 45%|████▍     | 2305/5153 [00:02<00:02, 1047.85it/s]
 47%|████▋     | 2411/5153 [00:02<00:02, 1048.52it/s]
 49%|████▉     | 2516/5153 [00:02<00:02, 1048.41it/s]
 51%|█████     | 2621/5153 [00:02<00:02, 1033.37it/s]
 53%|█████▎    | 2726/5153 [00:02<00:02, 1035.90it/s]
 55%|█████▍    | 2831/5153 [00:02<00:02, 1039.48it/s]
 57%|█████▋    | 2936/5153 [00:02<00:02, 1042.43it/s]
 59%|█████▉    | 3041/5153 [00:02<00:02, 1043.79it/s]
 61%|██████    | 3147/5153 [00:03<00:01, 1047.81it/s]
 63%|██████▎   | 3254/5153 [00:03<00:01, 1051.94it/s]
 65%|██████▌   | 3360/5153 [00:03<00:01, 1053.19it/s]
 67%|██████▋   | 3466/5153 [00:03<00:01, 1051.33it/s]
 69%|██████▉   | 3572/5153 [00:03<00:01, 1049.28it/s]
 71%|███████▏  | 3678/5153 [00:03<00:01, 1049.46it/s]
 73%|███████▎  | 3784/5153 [00:03<00:01, 1050.03it/s]
 75%|███████▌  | 3890/5153 [00:03<00:01, 1040.22it/s]
 78%|███████▊  | 3995/5153 [00:03<00:01, 1043.09it/s]
 80%|███████▉  | 4100/5153 [00:03<00:01, 1044.24it/s]
 82%|████████▏ | 4206/5153 [00:04<00:00, 1048.04it/s]
 84%|████████▎ | 4312/5153 [00:04<00:00, 1049.28it/s]
 86%|████████▌ | 4418/5153 [00:04<00:00, 1051.63it/s]
 88%|████████▊ | 4524/5153 [00:04<00:00, 1053.25it/s]
 90%|████████▉ | 4630/5153 [00:04<00:00, 1051.95it/s]
 92%|█████████▏| 4736/5153 [00:04<00:00, 1051.49it/s]
 94%|█████████▍| 4842/5153 [00:04<00:00, 1050.12it/s]
 96%|█████████▌| 4948/5153 [00:04<00:00, 1050.33it/s]
 98%|█████████▊| 5054/5153 [00:04<00:00, 1049.84it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1044.75it/s]
2024-11-21:14:53:44,888 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:54:16,794 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:16,794 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:16,840 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1033.18it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1036.83it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1038.13it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1025.09it/s]
 10%|█         | 521/5153 [00:00<00:04, 1032.92it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1041.07it/s]
 14%|█▍        | 733/5153 [00:00<00:04, 1046.10it/s]
 16%|█▋        | 839/5153 [00:00<00:04, 1049.43it/s]
 18%|█▊        | 945/5153 [00:00<00:04, 1050.36it/s]
 20%|██        | 1051/5153 [00:01<00:03, 1051.88it/s]
 22%|██▏       | 1157/5153 [00:01<00:03, 1052.63it/s]
 25%|██▍       | 1263/5153 [00:01<00:03, 1051.84it/s]
 27%|██▋       | 1369/5153 [00:01<00:03, 1052.58it/s]
 29%|██▊       | 1475/5153 [00:01<00:03, 1053.13it/s]
 31%|███       | 1581/5153 [00:01<00:03, 1053.71it/s]
 33%|███▎      | 1687/5153 [00:01<00:03, 1044.26it/s]
 35%|███▍      | 1794/5153 [00:01<00:03, 1049.27it/s]
 37%|███▋      | 1901/5153 [00:01<00:03, 1052.98it/s]
 39%|███▉      | 2007/5153 [00:01<00:02, 1054.83it/s]
 41%|████      | 2113/5153 [00:02<00:02, 1056.01it/s]
 43%|████▎     | 2219/5153 [00:02<00:02, 1057.08it/s]
 45%|████▌     | 2325/5153 [00:02<00:02, 1057.34it/s]
 47%|████▋     | 2431/5153 [00:02<00:02, 1058.08it/s]
 49%|████▉     | 2537/5153 [00:02<00:02, 1056.42it/s]
 51%|█████▏    | 2643/5153 [00:02<00:02, 1055.50it/s]
 53%|█████▎    | 2749/5153 [00:02<00:02, 1056.15it/s]
 55%|█████▌    | 2855/5153 [00:02<00:02, 1056.54it/s]
 57%|█████▋    | 2961/5153 [00:02<00:02, 1043.04it/s]
 60%|█████▉    | 3067/5153 [00:02<00:01, 1047.40it/s]
 62%|██████▏   | 3173/5153 [00:03<00:01, 1050.02it/s]
 64%|██████▎   | 3279/5153 [00:03<00:01, 1050.63it/s]
 66%|██████▌   | 3385/5153 [00:03<00:01, 1051.66it/s]
 68%|██████▊   | 3491/5153 [00:03<00:01, 1052.43it/s]
 70%|██████▉   | 3597/5153 [00:03<00:01, 1054.42it/s]
 72%|███████▏  | 3703/5153 [00:03<00:01, 1054.01it/s]
 74%|███████▍  | 3809/5153 [00:03<00:01, 1054.40it/s]
 76%|███████▌  | 3915/5153 [00:03<00:01, 1054.33it/s]
 78%|███████▊  | 4021/5153 [00:03<00:01, 1053.04it/s]
 80%|████████  | 4127/5153 [00:03<00:00, 1054.06it/s]
 82%|████████▏ | 4233/5153 [00:04<00:00, 1044.88it/s]
 84%|████████▍ | 4339/5153 [00:04<00:00, 1047.54it/s]
 86%|████████▋ | 4445/5153 [00:04<00:00, 1050.51it/s]
 88%|████████▊ | 4551/5153 [00:04<00:00, 1050.61it/s]
 90%|█████████ | 4657/5153 [00:04<00:00, 1051.52it/s]
 92%|█████████▏| 4763/5153 [00:04<00:00, 1053.23it/s]
 94%|█████████▍| 4869/5153 [00:04<00:00, 1053.84it/s]
 97%|█████████▋| 4975/5153 [00:04<00:00, 1053.24it/s]
 99%|█████████▊| 5081/5153 [00:04<00:00, 1052.18it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.81it/s]
2024-11-21:14:54:21,787 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:54:55,643 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:55,643 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:55,689 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1032.38it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1036.95it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1036.92it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1036.55it/s]
 10%|█         | 521/5153 [00:00<00:04, 1036.97it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1039.93it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1042.42it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1032.02it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1039.05it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1044.79it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1047.72it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1049.10it/s]
 26%|██▋       | 1365/5153 [00:01<00:03, 1048.12it/s]
 29%|██▊       | 1471/5153 [00:01<00:03, 1050.04it/s]
 31%|███       | 1577/5153 [00:01<00:03, 1050.25it/s]
 33%|███▎      | 1683/5153 [00:01<00:03, 1050.52it/s]
 35%|███▍      | 1789/5153 [00:01<00:03, 1050.82it/s]
 37%|███▋      | 1895/5153 [00:01<00:03, 1050.36it/s]
 39%|███▉      | 2001/5153 [00:01<00:03, 1041.16it/s]
 41%|████      | 2107/5153 [00:02<00:02, 1044.94it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1048.37it/s]
 45%|████▌     | 2319/5153 [00:02<00:02, 1048.93it/s]
 47%|████▋     | 2425/5153 [00:02<00:02, 1050.60it/s]
 49%|████▉     | 2531/5153 [00:02<00:02, 1052.16it/s]
 51%|█████     | 2637/5153 [00:02<00:02, 1051.90it/s]
 53%|█████▎    | 2743/5153 [00:02<00:02, 1051.64it/s]
 55%|█████▌    | 2849/5153 [00:02<00:02, 1051.15it/s]
 57%|█████▋    | 2955/5153 [00:02<00:02, 1050.76it/s]
 59%|█████▉    | 3061/5153 [00:02<00:01, 1051.03it/s]
 61%|██████▏   | 3167/5153 [00:03<00:01, 1052.33it/s]
 64%|██████▎   | 3273/5153 [00:03<00:01, 1039.70it/s]
 66%|██████▌   | 3379/5153 [00:03<00:01, 1043.43it/s]
 68%|██████▊   | 3485/5153 [00:03<00:01, 1047.52it/s]
 70%|██████▉   | 3591/5153 [00:03<00:01, 1048.46it/s]
 72%|███████▏  | 3696/5153 [00:03<00:01, 1048.46it/s]
 74%|███████▍  | 3802/5153 [00:03<00:01, 1050.34it/s]
 76%|███████▌  | 3908/5153 [00:03<00:01, 1050.29it/s]
 78%|███████▊  | 4014/5153 [00:03<00:01, 1049.82it/s]
 80%|███████▉  | 4119/5153 [00:03<00:00, 1049.57it/s]
 82%|████████▏ | 4224/5153 [00:04<00:00, 1049.36it/s]
 84%|████████▍ | 4330/5153 [00:04<00:00, 1049.88it/s]
 86%|████████▌ | 4436/5153 [00:04<00:00, 1050.24it/s]
 88%|████████▊ | 4542/5153 [00:04<00:00, 1041.77it/s]
 90%|█████████ | 4648/5153 [00:04<00:00, 1045.19it/s]
 92%|█████████▏| 4754/5153 [00:04<00:00, 1049.18it/s]
 94%|█████████▍| 4860/5153 [00:04<00:00, 1049.71it/s]
 96%|█████████▋| 4965/5153 [00:04<00:00, 1049.32it/s]
 98%|█████████▊| 5071/5153 [00:04<00:00, 1050.02it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.15it/s]
2024-11-21:14:55:00,654 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'

========================================
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:43,  4.83s/it]
100%|██████████| 10/10 [00:04<00:00,  2.06it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:04<00:44,  4.92s/it]
100%|██████████| 10/10 [00:04<00:00,  2.02it/s]

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)24=96, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-16x
#
# Epoch = 711 to 3117 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 420 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0006 to 6e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-16x/rwkv-710.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-16x', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 420, 'epoch_count': 2407, 'epoch_begin': 711, 'epoch_save': 10, 'micro_bsz': 24, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0006, 'lr_final': 6e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 16, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-08-07-21-54-41', 'betas': (0.9, 0.99), 'real_bsz': 96, 'run_name': '01b-pre-x59-16x', 'my_pile_prev_p': 700}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pre-x59-16x/rwkv-710.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 61.2 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
161 M     Trainable params
0         Non-trainable params
161 M     Total params
647.553   Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240807_215528-967kabno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 01b-pre-x59-16x 2024-08-07-21-54-41
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/967kabno
slurmstepd: error: *** JOB 63165632 ON udc-an36-31 CANCELLED AT 2024-08-10T21:54:31 DUE TO TIME LIMIT ***

========================================

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)24=96, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x52
#
# Epoch = 965 to 3371 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 420 steps, 40320 samples, 82575360 tokens
#
# Model = 12 n_layer, 768 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x52/rwkv-964.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x52', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 420, 'epoch_count': 2407, 'epoch_begin': 965, 'epoch_save': 10, 'micro_bsz': 24, 'n_layer': 12, 'n_embd': 768, 'dim_att': 768, 'dim_ffn': 2688, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x052', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-07-24-23-20-25', 'betas': (0.9, 0.99), 'real_bsz': 96, 'run_name': 'L12 D768 F8 x052', 'my_pile_prev_p': 954}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/01b-pretrain-x52/rwkv-964.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 50.3 M
1 | blocks | ModuleList | 92.1 M
2 | ln_out | LayerNorm  | 1.5 K 
3 | head   | Linear     | 50.3 M
--------------------------------------
192 M     Trainable params
0         Non-trainable params
192 M     Total params
771.232   Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240724_232105-lc4kms7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L12 D768 F8 x052 2024-07-24-23-20-25
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/lc4kms7p
slurmstepd: error: *** JOB 62707551 ON udc-an36-19 CANCELLED AT 2024-07-27T23:20:11 DUE TO TIME LIMIT ***

========================================
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)8=32, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52
#
# Epoch = 833 to 3239 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 1260 steps, 40320 samples, 82575360 tokens
#
# Model = 24 n_layer, 1024 n_embd, 2048 ctx_len
#
# Adam = lr 0.0008 to 8e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52/rwkv-832.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 1260, 'epoch_count': 2407, 'epoch_begin': 833, 'epoch_save': 10, 'micro_bsz': 8, 'n_layer': 24, 'n_embd': 1024, 'dim_att': 1024, 'dim_ffn': 3584, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0008, 'lr_final': 8e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x052', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 40960, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-08-14-10-37-30', 'betas': (0.9, 0.99), 'real_bsz': 32, 'run_name': 'L24 D1024 F8 x052', 'my_pile_prev_p': 822}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/04b-pre-x52/rwkv-832.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/qumulo/qhome/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 67.1 M
1 | blocks | ModuleList | 327 M 
2 | ln_out | LayerNorm  | 2.0 K 
3 | head   | Linear     | 67.1 M
--------------------------------------
461 M     Trainable params
0         Non-trainable params
461 M     Total params
1,846.886 Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: | Waiting for wandb.init()...
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20240814_103830-rcfsk0xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L24 D1024 F8 x052 2024-08-14-10-37-30
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/rcfsk0xy
slurmstepd: error: *** JOB 63382163 ON udc-an28-7 CANCELLED AT 2024-08-17T10:37:21 DUE TO TIME LIMIT ***

========================================
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.14s/it]
100%|██████████| 10/10 [00:03<00:00,  3.16it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.12s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.19s/it]
100%|██████████| 10/10 [00:03<00:00,  3.12it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.14s/it]
100%|██████████| 10/10 [00:03<00:00,  3.19it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.17s/it]
100%|██████████| 10/10 [00:03<00:00,  3.16it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.16s/it]
100%|██████████| 10/10 [00:03<00:00,  3.10it/s]

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:42:05,516 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:05,516 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:05,561 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1023.52it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1029.00it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1034.65it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1035.69it/s]
 10%|█         | 520/5153 [00:00<00:04, 1019.52it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1026.29it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1031.58it/s]
 16%|█▌        | 834/5153 [00:00<00:04, 1035.85it/s]
 18%|█▊        | 939/5153 [00:00<00:04, 1038.24it/s]
 20%|██        | 1044/5153 [00:01<00:03, 1040.98it/s]
 22%|██▏       | 1149/5153 [00:01<00:03, 1042.91it/s]
 24%|██▍       | 1255/5153 [00:01<00:03, 1045.13it/s]
 26%|██▋       | 1360/5153 [00:01<00:03, 1046.24it/s]
 28%|██▊       | 1465/5153 [00:01<00:03, 1046.46it/s]
 30%|███       | 1570/5153 [00:01<00:03, 1045.12it/s]
 33%|███▎      | 1675/5153 [00:01<00:03, 1042.90it/s]
 35%|███▍      | 1780/5153 [00:01<00:03, 1027.48it/s]
 37%|███▋      | 1885/5153 [00:01<00:03, 1031.93it/s]
 39%|███▊      | 1990/5153 [00:01<00:03, 1034.41it/s]
 41%|████      | 2095/5153 [00:02<00:02, 1036.30it/s]
 43%|████▎     | 2200/5153 [00:02<00:02, 1037.75it/s]
 45%|████▍     | 2305/5153 [00:02<00:02, 1040.03it/s]
 47%|████▋     | 2410/5153 [00:02<00:02, 1041.64it/s]
 49%|████▉     | 2515/5153 [00:02<00:02, 1043.75it/s]
 51%|█████     | 2621/5153 [00:02<00:02, 1045.69it/s]
 53%|█████▎    | 2726/5153 [00:02<00:02, 1045.77it/s]
 55%|█████▍    | 2831/5153 [00:02<00:02, 1044.92it/s]
 57%|█████▋    | 2936/5153 [00:02<00:02, 1044.44it/s]
 59%|█████▉    | 3041/5153 [00:02<00:02, 1035.35it/s]
 61%|██████    | 3146/5153 [00:03<00:01, 1037.56it/s]
 63%|██████▎   | 3251/5153 [00:03<00:01, 1040.41it/s]
 65%|██████▌   | 3356/5153 [00:03<00:01, 1041.34it/s]
 67%|██████▋   | 3461/5153 [00:03<00:01, 1042.03it/s]
 69%|██████▉   | 3566/5153 [00:03<00:01, 1042.30it/s]
 71%|███████   | 3671/5153 [00:03<00:01, 1042.67it/s]
 73%|███████▎  | 3776/5153 [00:03<00:01, 1044.04it/s]
 75%|███████▌  | 3881/5153 [00:03<00:01, 1038.81it/s]
 77%|███████▋  | 3986/5153 [00:03<00:01, 1040.68it/s]
 79%|███████▉  | 4091/5153 [00:03<00:01, 1041.81it/s]
 81%|████████▏ | 4196/5153 [00:04<00:00, 1041.95it/s]
 83%|████████▎ | 4301/5153 [00:04<00:00, 1040.92it/s]
 86%|████████▌ | 4406/5153 [00:04<00:00, 1041.17it/s]
 88%|████████▊ | 4511/5153 [00:04<00:00, 1042.83it/s]
 90%|████████▉ | 4616/5153 [00:04<00:00, 1040.95it/s]
 92%|█████████▏| 4721/5153 [00:04<00:00, 1039.89it/s]
 94%|█████████▎| 4826/5153 [00:04<00:00, 1040.94it/s]
 96%|█████████▌| 4931/5153 [00:04<00:00, 1041.69it/s]
 98%|█████████▊| 5036/5153 [00:04<00:00, 1041.78it/s]
100%|█████████▉| 5141/5153 [00:04<00:00, 1042.51it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1039.74it/s]
2024-11-21:14:42:10,561 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:42:43,353 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:43,353 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:43,399 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.94it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1034.62it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1039.40it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1043.77it/s]
 10%|█         | 524/5153 [00:00<00:04, 1046.97it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1040.89it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1048.27it/s]
 16%|█▋        | 843/5153 [00:00<00:04, 1052.96it/s]
 18%|█▊        | 950/5153 [00:00<00:03, 1055.54it/s]
 20%|██        | 1056/5153 [00:01<00:03, 1055.51it/s]
 23%|██▎       | 1162/5153 [00:01<00:03, 1056.01it/s]
 25%|██▍       | 1269/5153 [00:01<00:03, 1057.67it/s]
 27%|██▋       | 1375/5153 [00:01<00:03, 1057.67it/s]
 29%|██▊       | 1481/5153 [00:01<00:03, 1056.00it/s]
 31%|███       | 1587/5153 [00:01<00:03, 1056.26it/s]
 33%|███▎      | 1693/5153 [00:01<00:03, 1055.00it/s]
 35%|███▍      | 1799/5153 [00:01<00:03, 1043.33it/s]
 37%|███▋      | 1905/5153 [00:01<00:03, 1047.62it/s]
 39%|███▉      | 2012/5153 [00:01<00:02, 1051.74it/s]
 41%|████      | 2119/5153 [00:02<00:02, 1054.51it/s]
 43%|████▎     | 2225/5153 [00:02<00:02, 1055.97it/s]
 45%|████▌     | 2331/5153 [00:02<00:02, 1056.21it/s]
 47%|████▋     | 2437/5153 [00:02<00:02, 1056.39it/s]
 49%|████▉     | 2543/5153 [00:02<00:02, 1057.25it/s]
 51%|█████▏    | 2650/5153 [00:02<00:02, 1058.88it/s]
 54%|█████▎    | 2757/5153 [00:02<00:02, 1060.12it/s]
 56%|█████▌    | 2864/5153 [00:02<00:02, 1060.32it/s]
 58%|█████▊    | 2971/5153 [00:02<00:02, 1059.34it/s]
 60%|█████▉    | 3077/5153 [00:02<00:01, 1050.84it/s]
 62%|██████▏   | 3183/5153 [00:03<00:01, 1052.57it/s]
 64%|██████▍   | 3290/5153 [00:03<00:01, 1055.50it/s]
 66%|██████▌   | 3397/5153 [00:03<00:01, 1057.73it/s]
 68%|██████▊   | 3504/5153 [00:03<00:01, 1058.77it/s]
 70%|███████   | 3610/5153 [00:03<00:01, 1058.24it/s]
 72%|███████▏  | 3716/5153 [00:03<00:01, 1056.64it/s]
 74%|███████▍  | 3822/5153 [00:03<00:01, 1055.11it/s]
 76%|███████▌  | 3928/5153 [00:03<00:01, 1049.67it/s]
 78%|███████▊  | 4034/5153 [00:03<00:01, 1052.09it/s]
 80%|████████  | 4141/5153 [00:03<00:00, 1054.31it/s]
 82%|████████▏ | 4247/5153 [00:04<00:00, 1055.93it/s]
 84%|████████▍ | 4354/5153 [00:04<00:00, 1057.48it/s]
 87%|████████▋ | 4461/5153 [00:04<00:00, 1058.64it/s]
 89%|████████▊ | 4568/5153 [00:04<00:00, 1059.79it/s]
 91%|█████████ | 4675/5153 [00:04<00:00, 1061.19it/s]
 93%|█████████▎| 4782/5153 [00:04<00:00, 1063.52it/s]
 95%|█████████▍| 4889/5153 [00:04<00:00, 1061.75it/s]
 97%|█████████▋| 4996/5153 [00:04<00:00, 1060.33it/s]
 99%|█████████▉| 5103/5153 [00:04<00:00, 1060.57it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.98it/s]
2024-11-21:14:42:48,326 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:43:21,360 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:21,361 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:21,405 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1028.81it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1033.01it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1031.99it/s]
  8%|▊         | 415/5153 [00:00<00:04, 1032.41it/s]
 10%|█         | 519/5153 [00:00<00:04, 1033.79it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1039.20it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1043.50it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1044.15it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1044.35it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1045.93it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1048.44it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1034.42it/s]
 26%|██▋       | 1361/5153 [00:01<00:03, 1037.18it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1039.73it/s]
 30%|███       | 1571/5153 [00:01<00:03, 1042.30it/s]
 33%|███▎      | 1676/5153 [00:01<00:03, 1043.63it/s]
 35%|███▍      | 1781/5153 [00:01<00:03, 1043.91it/s]
 37%|███▋      | 1886/5153 [00:01<00:03, 1043.14it/s]
 39%|███▊      | 1991/5153 [00:01<00:03, 1043.49it/s]
 41%|████      | 2096/5153 [00:02<00:02, 1045.31it/s]
 43%|████▎     | 2202/5153 [00:02<00:02, 1047.17it/s]
 45%|████▍     | 2308/5153 [00:02<00:02, 1048.34it/s]
 47%|████▋     | 2414/5153 [00:02<00:02, 1048.81it/s]
 49%|████▉     | 2519/5153 [00:02<00:02, 1039.57it/s]
 51%|█████     | 2624/5153 [00:02<00:02, 1040.48it/s]
 53%|█████▎    | 2729/5153 [00:02<00:02, 1043.10it/s]
 55%|█████▍    | 2834/5153 [00:02<00:02, 1043.89it/s]
 57%|█████▋    | 2939/5153 [00:02<00:02, 1044.82it/s]
 59%|█████▉    | 3044/5153 [00:02<00:02, 1045.34it/s]
 61%|██████    | 3149/5153 [00:03<00:01, 1046.45it/s]
 63%|██████▎   | 3254/5153 [00:03<00:01, 1045.83it/s]
 65%|██████▌   | 3359/5153 [00:03<00:01, 1046.52it/s]
 67%|██████▋   | 3465/5153 [00:03<00:01, 1048.00it/s]
 69%|██████▉   | 3570/5153 [00:03<00:01, 1048.51it/s]
 71%|███████▏  | 3675/5153 [00:03<00:01, 1048.59it/s]
 73%|███████▎  | 3780/5153 [00:03<00:01, 1048.90it/s]
 75%|███████▌  | 3885/5153 [00:03<00:01, 1044.07it/s]
 77%|███████▋  | 3990/5153 [00:03<00:01, 1045.23it/s]
 79%|███████▉  | 4095/5153 [00:03<00:01, 1046.51it/s]
 82%|████████▏ | 4201/5153 [00:04<00:00, 1049.28it/s]
 84%|████████▎ | 4307/5153 [00:04<00:00, 1050.48it/s]
 86%|████████▌ | 4413/5153 [00:04<00:00, 1052.11it/s]
 88%|████████▊ | 4519/5153 [00:04<00:00, 1053.79it/s]
 90%|████████▉ | 4625/5153 [00:04<00:00, 1054.20it/s]
 92%|█████████▏| 4731/5153 [00:04<00:00, 1054.35it/s]
 94%|█████████▍| 4837/5153 [00:04<00:00, 1054.54it/s]
 96%|█████████▌| 4943/5153 [00:04<00:00, 1054.64it/s]
 98%|█████████▊| 5049/5153 [00:04<00:00, 1055.18it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1045.87it/s]
2024-11-21:14:43:26,383 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:43:57,749 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:57,749 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:43:57,794 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1030.50it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1037.58it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1039.83it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1042.37it/s]
 10%|█         | 524/5153 [00:00<00:04, 1043.07it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1047.38it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1049.89it/s]
 16%|█▋        | 841/5153 [00:00<00:04, 1039.26it/s]
 18%|█▊        | 947/5153 [00:00<00:04, 1043.89it/s]
 20%|██        | 1053/5153 [00:01<00:03, 1047.16it/s]
 23%|██▎       | 1160/5153 [00:01<00:03, 1051.62it/s]
 25%|██▍       | 1266/5153 [00:01<00:03, 1052.15it/s]
 27%|██▋       | 1373/5153 [00:01<00:03, 1055.04it/s]
 29%|██▊       | 1479/5153 [00:01<00:03, 1054.73it/s]
 31%|███       | 1585/5153 [00:01<00:03, 1056.12it/s]
 33%|███▎      | 1692/5153 [00:01<00:03, 1057.55it/s]
 35%|███▍      | 1798/5153 [00:01<00:03, 1057.84it/s]
 37%|███▋      | 1904/5153 [00:01<00:03, 1056.59it/s]
 39%|███▉      | 2010/5153 [00:01<00:02, 1054.84it/s]
 41%|████      | 2116/5153 [00:02<00:02, 1042.17it/s]
 43%|████▎     | 2222/5153 [00:02<00:02, 1046.07it/s]
 45%|████▌     | 2327/5153 [00:02<00:02, 1047.04it/s]
 47%|████▋     | 2433/5153 [00:02<00:02, 1048.91it/s]
 49%|████▉     | 2539/5153 [00:02<00:02, 1050.58it/s]
 51%|█████▏    | 2645/5153 [00:02<00:02, 1052.06it/s]
 53%|█████▎    | 2751/5153 [00:02<00:02, 1053.58it/s]
 55%|█████▌    | 2858/5153 [00:02<00:02, 1056.04it/s]
 58%|█████▊    | 2965/5153 [00:02<00:02, 1057.23it/s]
 60%|█████▉    | 3071/5153 [00:02<00:01, 1057.52it/s]
 62%|██████▏   | 3177/5153 [00:03<00:01, 1056.71it/s]
 64%|██████▎   | 3283/5153 [00:03<00:01, 1054.65it/s]
 66%|██████▌   | 3389/5153 [00:03<00:01, 1046.07it/s]
 68%|██████▊   | 3495/5153 [00:03<00:01, 1047.49it/s]
 70%|██████▉   | 3601/5153 [00:03<00:01, 1049.95it/s]
 72%|███████▏  | 3707/5153 [00:03<00:01, 1050.48it/s]
 74%|███████▍  | 3813/5153 [00:03<00:01, 1047.91it/s]
 76%|███████▌  | 3919/5153 [00:03<00:01, 1049.32it/s]
 78%|███████▊  | 4025/5153 [00:03<00:01, 1051.34it/s]
 80%|████████  | 4131/5153 [00:03<00:00, 1053.76it/s]
 82%|████████▏ | 4238/5153 [00:04<00:00, 1055.61it/s]
 84%|████████▍ | 4344/5153 [00:04<00:00, 1055.39it/s]
 86%|████████▋ | 4450/5153 [00:04<00:00, 1055.26it/s]
 88%|████████▊ | 4556/5153 [00:04<00:00, 1054.47it/s]
 90%|█████████ | 4662/5153 [00:04<00:00, 1053.46it/s]
 93%|█████████▎| 4768/5153 [00:04<00:00, 1052.45it/s]
 95%|█████████▍| 4874/5153 [00:04<00:00, 1052.61it/s]
 97%|█████████▋| 4980/5153 [00:04<00:00, 1050.82it/s]
 99%|█████████▊| 5086/5153 [00:04<00:00, 1050.81it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.93it/s]
2024-11-21:14:44:02,741 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:44:34,470 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:34,470 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:34,514 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1025.68it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1026.89it/s]
  6%|▌         | 309/5153 [00:00<00:04, 1015.96it/s]
  8%|▊         | 413/5153 [00:00<00:04, 1024.16it/s]
 10%|█         | 517/5153 [00:00<00:04, 1028.54it/s]
 12%|█▏        | 623/5153 [00:00<00:04, 1035.87it/s]
 14%|█▍        | 729/5153 [00:00<00:04, 1040.72it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1044.44it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1044.91it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1044.32it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1046.28it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1046.64it/s]
 26%|██▋       | 1361/5153 [00:01<00:03, 1046.44it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1033.69it/s]
 30%|███       | 1571/5153 [00:01<00:03, 1038.43it/s]
 33%|███▎      | 1676/5153 [00:01<00:03, 1041.40it/s]
 35%|███▍      | 1782/5153 [00:01<00:03, 1044.32it/s]
 37%|███▋      | 1887/5153 [00:01<00:03, 1045.51it/s]
 39%|███▊      | 1993/5153 [00:01<00:03, 1047.06it/s]
 41%|████      | 2099/5153 [00:02<00:02, 1048.02it/s]
 43%|████▎     | 2204/5153 [00:02<00:02, 1047.12it/s]
 45%|████▍     | 2309/5153 [00:02<00:02, 1046.01it/s]
 47%|████▋     | 2414/5153 [00:02<00:02, 1046.64it/s]
 49%|████▉     | 2520/5153 [00:02<00:02, 1048.62it/s]
 51%|█████     | 2625/5153 [00:02<00:02, 1048.16it/s]
 53%|█████▎    | 2730/5153 [00:02<00:02, 1040.84it/s]
 55%|█████▌    | 2835/5153 [00:02<00:02, 1042.69it/s]
 57%|█████▋    | 2940/5153 [00:02<00:02, 1044.16it/s]
 59%|█████▉    | 3046/5153 [00:02<00:02, 1047.11it/s]
 61%|██████    | 3152/5153 [00:03<00:01, 1049.58it/s]
 63%|██████▎   | 3258/5153 [00:03<00:01, 1051.72it/s]
 65%|██████▌   | 3364/5153 [00:03<00:01, 1051.56it/s]
 67%|██████▋   | 3470/5153 [00:03<00:01, 1049.41it/s]
 69%|██████▉   | 3575/5153 [00:03<00:01, 1047.74it/s]
 71%|███████▏  | 3680/5153 [00:03<00:01, 1047.19it/s]
 73%|███████▎  | 3785/5153 [00:03<00:01, 1045.70it/s]
 75%|███████▌  | 3890/5153 [00:03<00:01, 1040.18it/s]
 78%|███████▊  | 3995/5153 [00:03<00:01, 1041.23it/s]
 80%|███████▉  | 4100/5153 [00:03<00:01, 1043.42it/s]
 82%|████████▏ | 4206/5153 [00:04<00:00, 1045.89it/s]
 84%|████████▎ | 4311/5153 [00:04<00:00, 1046.13it/s]
 86%|████████▌ | 4417/5153 [00:04<00:00, 1047.91it/s]
 88%|████████▊ | 4523/5153 [00:04<00:00, 1048.87it/s]
 90%|████████▉ | 4628/5153 [00:04<00:00, 1044.23it/s]
 92%|█████████▏| 4733/5153 [00:04<00:00, 1044.57it/s]
 94%|█████████▍| 4838/5153 [00:04<00:00, 1045.60it/s]
 96%|█████████▌| 4943/5153 [00:04<00:00, 1046.42it/s]
 98%|█████████▊| 5049/5153 [00:04<00:00, 1047.76it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1044.19it/s]
2024-11-21:14:44:39,492 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:45:11,196 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:11,196 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:11,241 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1037.13it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1042.23it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1028.53it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1034.90it/s]
 10%|█         | 524/5153 [00:00<00:04, 1040.20it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1044.47it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1048.49it/s]
 16%|█▋        | 842/5153 [00:00<00:04, 1050.82it/s]
 18%|█▊        | 948/5153 [00:00<00:03, 1052.65it/s]
 20%|██        | 1054/5153 [00:01<00:03, 1053.39it/s]
 23%|██▎       | 1161/5153 [00:01<00:03, 1055.93it/s]
 25%|██▍       | 1267/5153 [00:01<00:03, 1055.79it/s]
 27%|██▋       | 1373/5153 [00:01<00:03, 1056.62it/s]
 29%|██▊       | 1479/5153 [00:01<00:03, 1043.03it/s]
 31%|███       | 1585/5153 [00:01<00:03, 1045.61it/s]
 33%|███▎      | 1691/5153 [00:01<00:03, 1048.12it/s]
 35%|███▍      | 1796/5153 [00:01<00:03, 1048.42it/s]
 37%|███▋      | 1902/5153 [00:01<00:03, 1050.14it/s]
 39%|███▉      | 2008/5153 [00:01<00:02, 1050.80it/s]
 41%|████      | 2114/5153 [00:02<00:02, 1052.86it/s]
 43%|████▎     | 2221/5153 [00:02<00:02, 1055.31it/s]
 45%|████▌     | 2328/5153 [00:02<00:02, 1056.79it/s]
 47%|████▋     | 2435/5153 [00:02<00:02, 1059.55it/s]
 49%|████▉     | 2541/5153 [00:02<00:02, 1058.02it/s]
 51%|█████▏    | 2647/5153 [00:02<00:02, 1056.28it/s]
 53%|█████▎    | 2753/5153 [00:02<00:02, 1046.53it/s]
 55%|█████▌    | 2859/5153 [00:02<00:02, 1048.04it/s]
 58%|█████▊    | 2965/5153 [00:02<00:02, 1050.12it/s]
 60%|█████▉    | 3071/5153 [00:02<00:01, 1051.27it/s]
 62%|██████▏   | 3177/5153 [00:03<00:01, 1051.78it/s]
 64%|██████▎   | 3283/5153 [00:03<00:01, 1051.45it/s]
 66%|██████▌   | 3389/5153 [00:03<00:01, 1052.98it/s]
 68%|██████▊   | 3495/5153 [00:03<00:01, 1054.08it/s]
 70%|██████▉   | 3601/5153 [00:03<00:01, 1055.20it/s]
 72%|███████▏  | 3707/5153 [00:03<00:01, 1055.83it/s]
 74%|███████▍  | 3813/5153 [00:03<00:01, 1053.15it/s]
 76%|███████▌  | 3919/5153 [00:03<00:01, 1048.59it/s]
 78%|███████▊  | 4025/5153 [00:03<00:01, 1049.23it/s]
 80%|████████  | 4131/5153 [00:03<00:00, 1052.20it/s]
 82%|████████▏ | 4237/5153 [00:04<00:00, 1052.78it/s]
 84%|████████▍ | 4343/5153 [00:04<00:00, 1050.48it/s]
 86%|████████▋ | 4449/5153 [00:04<00:00, 1051.88it/s]
 88%|████████▊ | 4555/5153 [00:04<00:00, 1052.10it/s]
 90%|█████████ | 4661/5153 [00:04<00:00, 1053.53it/s]
 93%|█████████▎| 4767/5153 [00:04<00:00, 1053.67it/s]
 95%|█████████▍| 4873/5153 [00:04<00:00, 1055.39it/s]
 97%|█████████▋| 4979/5153 [00:04<00:00, 1056.70it/s]
 99%|█████████▊| 5085/5153 [00:04<00:00, 1056.36it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1051.42it/s]
2024-11-21:14:45:16,186 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:45:47,554 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:47,554 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:45:47,599 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1024.54it/s]
  4%|▍         | 206/5153 [00:00<00:04, 1027.51it/s]
  6%|▌         | 309/5153 [00:00<00:04, 1015.63it/s]
  8%|▊         | 412/5153 [00:00<00:04, 1020.60it/s]
 10%|█         | 516/5153 [00:00<00:04, 1025.14it/s]
 12%|█▏        | 620/5153 [00:00<00:04, 1029.76it/s]
 14%|█▍        | 725/5153 [00:00<00:04, 1034.66it/s]
 16%|█▌        | 830/5153 [00:00<00:04, 1037.11it/s]
 18%|█▊        | 934/5153 [00:00<00:04, 1037.81it/s]
 20%|██        | 1039/5153 [00:01<00:03, 1039.30it/s]
 22%|██▏       | 1144/5153 [00:01<00:03, 1040.20it/s]
 24%|██▍       | 1249/5153 [00:01<00:03, 1040.99it/s]
 26%|██▋       | 1354/5153 [00:01<00:03, 1041.68it/s]
 28%|██▊       | 1459/5153 [00:01<00:03, 1040.48it/s]
 30%|███       | 1564/5153 [00:01<00:03, 1029.59it/s]
 32%|███▏      | 1669/5153 [00:01<00:03, 1033.16it/s]
 34%|███▍      | 1774/5153 [00:01<00:03, 1036.70it/s]
 36%|███▋      | 1879/5153 [00:01<00:03, 1038.98it/s]
 39%|███▊      | 1984/5153 [00:01<00:03, 1039.79it/s]
 41%|████      | 2089/5153 [00:02<00:02, 1041.51it/s]
 43%|████▎     | 2194/5153 [00:02<00:02, 1041.10it/s]
 45%|████▍     | 2299/5153 [00:02<00:02, 1040.46it/s]
 47%|████▋     | 2404/5153 [00:02<00:02, 1041.04it/s]
 49%|████▊     | 2509/5153 [00:02<00:02, 1041.77it/s]
 51%|█████     | 2614/5153 [00:02<00:02, 1042.23it/s]
 53%|█████▎    | 2719/5153 [00:02<00:02, 1032.52it/s]
 55%|█████▍    | 2824/5153 [00:02<00:02, 1035.63it/s]
 57%|█████▋    | 2929/5153 [00:02<00:02, 1038.18it/s]
 59%|█████▉    | 3034/5153 [00:02<00:02, 1039.72it/s]
 61%|██████    | 3139/5153 [00:03<00:01, 1041.41it/s]
 63%|██████▎   | 3245/5153 [00:03<00:01, 1044.83it/s]
 65%|██████▌   | 3350/5153 [00:03<00:01, 1045.92it/s]
 67%|██████▋   | 3455/5153 [00:03<00:01, 1046.28it/s]
 69%|██████▉   | 3560/5153 [00:03<00:01, 1046.58it/s]
 71%|███████   | 3665/5153 [00:03<00:01, 1045.03it/s]
 73%|███████▎  | 3770/5153 [00:03<00:01, 1046.28it/s]
 75%|███████▌  | 3875/5153 [00:03<00:01, 1041.46it/s]
 77%|███████▋  | 3980/5153 [00:03<00:01, 1035.91it/s]
 79%|███████▉  | 4085/5153 [00:03<00:01, 1038.39it/s]
 81%|████████▏ | 4190/5153 [00:04<00:00, 1040.90it/s]
 83%|████████▎ | 4295/5153 [00:04<00:00, 1040.42it/s]
 85%|████████▌ | 4400/5153 [00:04<00:00, 1041.79it/s]
 87%|████████▋ | 4505/5153 [00:04<00:00, 1041.78it/s]
 89%|████████▉ | 4610/5153 [00:04<00:00, 1041.80it/s]
 92%|█████████▏| 4715/5153 [00:04<00:00, 1040.50it/s]
 94%|█████████▎| 4820/5153 [00:04<00:00, 1039.89it/s]
 96%|█████████▌| 4924/5153 [00:04<00:00, 1039.81it/s]
 98%|█████████▊| 5028/5153 [00:04<00:00, 1039.84it/s]
100%|█████████▉| 5132/5153 [00:04<00:00, 1039.57it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1038.71it/s]
2024-11-21:14:45:52,604 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:46:25,578 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:25,578 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:46:25,623 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1021.88it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1027.56it/s]
  6%|▌         | 310/5153 [00:00<00:04, 1018.47it/s]
  8%|▊         | 414/5153 [00:00<00:04, 1026.66it/s]
 10%|█         | 519/5153 [00:00<00:04, 1031.86it/s]
 12%|█▏        | 624/5153 [00:00<00:04, 1037.70it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1041.97it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1042.41it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1042.03it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1041.81it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1043.84it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1046.05it/s]
 26%|██▋       | 1362/5153 [00:01<00:03, 1047.32it/s]
 28%|██▊       | 1467/5153 [00:01<00:03, 1047.94it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1036.64it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1040.10it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1044.52it/s]
 37%|███▋      | 1889/5153 [00:01<00:03, 1048.28it/s]
 39%|███▊      | 1995/5153 [00:01<00:03, 1050.70it/s]
 41%|████      | 2101/5153 [00:02<00:02, 1053.00it/s]
 43%|████▎     | 2207/5153 [00:02<00:02, 1054.93it/s]
 45%|████▍     | 2313/5153 [00:02<00:02, 1055.91it/s]
 47%|████▋     | 2419/5153 [00:02<00:02, 1055.95it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1056.33it/s]
 51%|█████     | 2631/5153 [00:02<00:02, 1056.22it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1056.93it/s]
 55%|█████▌    | 2843/5153 [00:02<00:02, 1048.99it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1051.19it/s]
 59%|█████▉    | 3055/5153 [00:02<00:01, 1053.17it/s]
 61%|██████▏   | 3161/5153 [00:03<00:01, 1053.22it/s]
 63%|██████▎   | 3268/5153 [00:03<00:01, 1055.59it/s]
 65%|██████▌   | 3374/5153 [00:03<00:01, 1055.00it/s]
 68%|██████▊   | 3480/5153 [00:03<00:01, 1053.84it/s]
 70%|██████▉   | 3586/5153 [00:03<00:01, 1055.21it/s]
 72%|███████▏  | 3692/5153 [00:03<00:01, 1054.66it/s]
 74%|███████▎  | 3799/5153 [00:03<00:01, 1056.45it/s]
 76%|███████▌  | 3905/5153 [00:03<00:01, 1049.76it/s]
 78%|███████▊  | 4011/5153 [00:03<00:01, 1050.14it/s]
 80%|███████▉  | 4118/5153 [00:03<00:00, 1053.11it/s]
 82%|████████▏ | 4225/5153 [00:04<00:00, 1055.61it/s]
 84%|████████▍ | 4331/5153 [00:04<00:00, 1054.87it/s]
 86%|████████▌ | 4437/5153 [00:04<00:00, 1055.33it/s]
 88%|████████▊ | 4543/5153 [00:04<00:00, 1056.71it/s]
 90%|█████████ | 4649/5153 [00:04<00:00, 1056.44it/s]
 92%|█████████▏| 4755/5153 [00:04<00:00, 1057.39it/s]
 94%|█████████▍| 4861/5153 [00:04<00:00, 1056.96it/s]
 96%|█████████▋| 4967/5153 [00:04<00:00, 1057.46it/s]
 98%|█████████▊| 5073/5153 [00:04<00:00, 1056.98it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.95it/s]
2024-11-21:14:46:30,574 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:47:03,096 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:03,096 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:03,140 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1023.34it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.82it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1036.86it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1038.94it/s]
 10%|█         | 521/5153 [00:00<00:04, 1038.18it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1041.26it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1043.17it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1043.62it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1044.80it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1045.71it/s]
 22%|██▏       | 1152/5153 [00:01<00:03, 1049.02it/s]
 24%|██▍       | 1257/5153 [00:01<00:03, 1036.39it/s]
 26%|██▋       | 1363/5153 [00:01<00:03, 1041.64it/s]
 29%|██▊       | 1469/5153 [00:01<00:03, 1046.33it/s]
 31%|███       | 1575/5153 [00:01<00:03, 1048.33it/s]
 33%|███▎      | 1680/5153 [00:01<00:03, 1048.24it/s]
 35%|███▍      | 1786/5153 [00:01<00:03, 1049.04it/s]
 37%|███▋      | 1891/5153 [00:01<00:03, 1048.72it/s]
 39%|███▉      | 1997/5153 [00:01<00:03, 1049.50it/s]
 41%|████      | 2102/5153 [00:02<00:02, 1049.10it/s]
 43%|████▎     | 2208/5153 [00:02<00:02, 1049.55it/s]
 45%|████▍     | 2314/5153 [00:02<00:02, 1051.19it/s]
 47%|████▋     | 2420/5153 [00:02<00:02, 1052.37it/s]
 49%|████▉     | 2526/5153 [00:02<00:02, 1040.60it/s]
 51%|█████     | 2632/5153 [00:02<00:02, 1044.00it/s]
 53%|█████▎    | 2738/5153 [00:02<00:02, 1048.47it/s]
 55%|█████▌    | 2844/5153 [00:02<00:02, 1049.01it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1048.18it/s]
 59%|█████▉    | 3055/5153 [00:02<00:01, 1049.13it/s]
 61%|██████▏   | 3160/5153 [00:03<00:01, 1049.36it/s]
 63%|██████▎   | 3266/5153 [00:03<00:01, 1050.77it/s]
 65%|██████▌   | 3372/5153 [00:03<00:01, 1050.05it/s]
 67%|██████▋   | 3478/5153 [00:03<00:01, 1050.53it/s]
 70%|██████▉   | 3584/5153 [00:03<00:01, 1051.26it/s]
 72%|███████▏  | 3690/5153 [00:03<00:01, 1050.72it/s]
 74%|███████▎  | 3796/5153 [00:03<00:01, 1046.60it/s]
 76%|███████▌  | 3901/5153 [00:03<00:01, 1046.70it/s]
 78%|███████▊  | 4007/5153 [00:03<00:01, 1049.00it/s]
 80%|███████▉  | 4113/5153 [00:03<00:00, 1050.75it/s]
 82%|████████▏ | 4219/5153 [00:04<00:00, 1047.49it/s]
 84%|████████▍ | 4324/5153 [00:04<00:00, 1048.18it/s]
 86%|████████▌ | 4429/5153 [00:04<00:00, 1048.05it/s]
 88%|████████▊ | 4535/5153 [00:04<00:00, 1049.74it/s]
 90%|█████████ | 4640/5153 [00:04<00:00, 1049.19it/s]
 92%|█████████▏| 4746/5153 [00:04<00:00, 1049.75it/s]
 94%|█████████▍| 4852/5153 [00:04<00:00, 1050.76it/s]
 96%|█████████▌| 4958/5153 [00:04<00:00, 1050.19it/s]
 98%|█████████▊| 5064/5153 [00:04<00:00, 1049.98it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.25it/s]
2024-11-21:14:47:08,109 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:47:40,404 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:40,404 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:40,451 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1024.56it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1033.18it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1038.74it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1041.98it/s]
 10%|█         | 522/5153 [00:00<00:04, 1044.40it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1030.95it/s]
 14%|█▍        | 733/5153 [00:00<00:04, 1038.43it/s]
 16%|█▋        | 839/5153 [00:00<00:04, 1043.13it/s]
 18%|█▊        | 945/5153 [00:00<00:04, 1047.75it/s]
 20%|██        | 1051/5153 [00:01<00:03, 1050.70it/s]
 22%|██▏       | 1158/5153 [00:01<00:03, 1053.64it/s]
 25%|██▍       | 1265/5153 [00:01<00:03, 1056.65it/s]
 27%|██▋       | 1372/5153 [00:01<00:03, 1058.95it/s]
 29%|██▊       | 1478/5153 [00:01<00:03, 1059.24it/s]
 31%|███       | 1584/5153 [00:01<00:03, 1059.07it/s]
 33%|███▎      | 1691/5153 [00:01<00:03, 1060.17it/s]
 35%|███▍      | 1798/5153 [00:01<00:03, 1059.58it/s]
 37%|███▋      | 1904/5153 [00:01<00:03, 1041.61it/s]
 39%|███▉      | 2009/5153 [00:01<00:03, 1042.82it/s]
 41%|████      | 2115/5153 [00:02<00:02, 1046.68it/s]
 43%|████▎     | 2221/5153 [00:02<00:02, 1049.26it/s]
 45%|████▌     | 2327/5153 [00:02<00:02, 1051.16it/s]
 47%|████▋     | 2434/5153 [00:02<00:02, 1054.53it/s]
 49%|████▉     | 2541/5153 [00:02<00:02, 1056.81it/s]
 51%|█████▏    | 2647/5153 [00:02<00:02, 1056.99it/s]
 53%|█████▎    | 2753/5153 [00:02<00:02, 1057.38it/s]
 55%|█████▌    | 2859/5153 [00:02<00:02, 1058.03it/s]
 58%|█████▊    | 2965/5153 [00:02<00:02, 1057.43it/s]
 60%|█████▉    | 3071/5153 [00:02<00:01, 1057.64it/s]
 62%|██████▏   | 3177/5153 [00:03<00:01, 1043.29it/s]
 64%|██████▎   | 3283/5153 [00:03<00:01, 1047.08it/s]
 66%|██████▌   | 3389/5153 [00:03<00:01, 1050.24it/s]
 68%|██████▊   | 3495/5153 [00:03<00:01, 1051.65it/s]
 70%|██████▉   | 3602/5153 [00:03<00:01, 1054.26it/s]
 72%|███████▏  | 3708/5153 [00:03<00:01, 1055.69it/s]
 74%|███████▍  | 3814/5153 [00:03<00:01, 1054.95it/s]
 76%|███████▌  | 3920/5153 [00:03<00:01, 1052.94it/s]
 78%|███████▊  | 4027/5153 [00:03<00:01, 1055.28it/s]
 80%|████████  | 4134/5153 [00:03<00:00, 1057.48it/s]
 82%|████████▏ | 4240/5153 [00:04<00:00, 1058.16it/s]
 84%|████████▍ | 4347/5153 [00:04<00:00, 1058.83it/s]
 86%|████████▋ | 4453/5153 [00:04<00:00, 1058.00it/s]
 88%|████████▊ | 4559/5153 [00:04<00:00, 1057.67it/s]
 91%|█████████ | 4665/5153 [00:04<00:00, 1057.25it/s]
 93%|█████████▎| 4771/5153 [00:04<00:00, 1057.61it/s]
 95%|█████████▍| 4877/5153 [00:04<00:00, 1057.69it/s]
 97%|█████████▋| 4983/5153 [00:04<00:00, 1057.82it/s]
 99%|█████████▉| 5090/5153 [00:04<00:00, 1059.01it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1052.76it/s]
2024-11-21:14:47:45,389 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:48:17,680 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:17,680 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:17,725 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1032.75it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1035.47it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1038.15it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1024.35it/s]
 10%|█         | 522/5153 [00:00<00:04, 1032.67it/s]
 12%|█▏        | 629/5153 [00:00<00:04, 1042.05it/s]
 14%|█▍        | 735/5153 [00:00<00:04, 1047.07it/s]
 16%|█▋        | 841/5153 [00:00<00:04, 1051.06it/s]
 18%|█▊        | 948/5153 [00:00<00:03, 1055.68it/s]
 20%|██        | 1055/5153 [00:01<00:03, 1057.30it/s]
 23%|██▎       | 1161/5153 [00:01<00:03, 1057.95it/s]
 25%|██▍       | 1267/5153 [00:01<00:03, 1058.40it/s]
 27%|██▋       | 1373/5153 [00:01<00:03, 1057.97it/s]
 29%|██▊       | 1479/5153 [00:01<00:03, 1057.93it/s]
 31%|███       | 1585/5153 [00:01<00:03, 1057.93it/s]
 33%|███▎      | 1691/5153 [00:01<00:03, 1042.99it/s]
 35%|███▍      | 1797/5153 [00:01<00:03, 1047.07it/s]
 37%|███▋      | 1903/5153 [00:01<00:03, 1050.16it/s]
 39%|███▉      | 2009/5153 [00:01<00:02, 1052.64it/s]
 41%|████      | 2116/5153 [00:02<00:02, 1056.00it/s]
 43%|████▎     | 2223/5153 [00:02<00:02, 1058.64it/s]
 45%|████▌     | 2330/5153 [00:02<00:02, 1059.21it/s]
 47%|████▋     | 2437/5153 [00:02<00:02, 1059.74it/s]
 49%|████▉     | 2543/5153 [00:02<00:02, 1059.57it/s]
 51%|█████▏    | 2649/5153 [00:02<00:02, 1059.64it/s]
 53%|█████▎    | 2756/5153 [00:02<00:02, 1060.63it/s]
 56%|█████▌    | 2863/5153 [00:02<00:02, 1060.97it/s]
 58%|█████▊    | 2970/5153 [00:02<00:02, 1060.23it/s]
 60%|█████▉    | 3077/5153 [00:02<00:01, 1050.18it/s]
 62%|██████▏   | 3183/5153 [00:03<00:01, 1052.16it/s]
 64%|██████▍   | 3290/5153 [00:03<00:01, 1054.99it/s]
 66%|██████▌   | 3397/5153 [00:03<00:01, 1056.27it/s]
 68%|██████▊   | 3504/5153 [00:03<00:01, 1059.06it/s]
 70%|███████   | 3611/5153 [00:03<00:01, 1059.57it/s]
 72%|███████▏  | 3717/5153 [00:03<00:01, 1059.32it/s]
 74%|███████▍  | 3823/5153 [00:03<00:01, 1057.79it/s]
 76%|███████▌  | 3929/5153 [00:03<00:01, 1056.01it/s]
 78%|███████▊  | 4036/5153 [00:03<00:01, 1057.99it/s]
 80%|████████  | 4143/5153 [00:03<00:00, 1058.61it/s]
 82%|████████▏ | 4249/5153 [00:04<00:00, 1057.21it/s]
 85%|████████▍ | 4355/5153 [00:04<00:00, 1055.85it/s]
 87%|████████▋ | 4461/5153 [00:04<00:00, 1056.98it/s]
 89%|████████▊ | 4568/5153 [00:04<00:00, 1058.93it/s]
 91%|█████████ | 4674/5153 [00:04<00:00, 1057.11it/s]
 93%|█████████▎| 4781/5153 [00:04<00:00, 1059.23it/s]
 95%|█████████▍| 4887/5153 [00:04<00:00, 1057.80it/s]
 97%|█████████▋| 4993/5153 [00:04<00:00, 1057.41it/s]
 99%|█████████▉| 5099/5153 [00:04<00:00, 1057.25it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.59it/s]
2024-11-21:14:48:22,655 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:48:53,846 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:53,846 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:48:53,891 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 102/5153 [00:00<00:04, 1019.66it/s]
  4%|▍         | 205/5153 [00:00<00:04, 1024.65it/s]
  6%|▌         | 308/5153 [00:00<00:04, 1026.86it/s]
  8%|▊         | 412/5153 [00:00<00:04, 1029.67it/s]
 10%|█         | 516/5153 [00:00<00:04, 1032.30it/s]
 12%|█▏        | 621/5153 [00:00<00:04, 1037.10it/s]
 14%|█▍        | 726/5153 [00:00<00:04, 1039.87it/s]
 16%|█▌        | 831/5153 [00:00<00:04, 1042.50it/s]
 18%|█▊        | 937/5153 [00:00<00:04, 1045.35it/s]
 20%|██        | 1043/5153 [00:01<00:03, 1047.44it/s]
 22%|██▏       | 1148/5153 [00:01<00:03, 1046.32it/s]
 24%|██▍       | 1253/5153 [00:01<00:03, 1030.71it/s]
 26%|██▋       | 1358/5153 [00:01<00:03, 1035.83it/s]
 28%|██▊       | 1464/5153 [00:01<00:03, 1041.08it/s]
 30%|███       | 1570/5153 [00:01<00:03, 1044.31it/s]
 33%|███▎      | 1675/5153 [00:01<00:03, 1045.80it/s]
 35%|███▍      | 1781/5153 [00:01<00:03, 1048.88it/s]
 37%|███▋      | 1887/5153 [00:01<00:03, 1049.51it/s]
 39%|███▊      | 1992/5153 [00:01<00:03, 1049.01it/s]
 41%|████      | 2098/5153 [00:02<00:02, 1050.11it/s]
 43%|████▎     | 2204/5153 [00:02<00:02, 1051.34it/s]
 45%|████▍     | 2310/5153 [00:02<00:02, 1051.56it/s]
 47%|████▋     | 2416/5153 [00:02<00:02, 1050.76it/s]
 49%|████▉     | 2522/5153 [00:02<00:02, 1041.54it/s]
 51%|█████     | 2628/5153 [00:02<00:02, 1044.47it/s]
 53%|█████▎    | 2734/5153 [00:02<00:02, 1046.90it/s]
 55%|█████▌    | 2840/5153 [00:02<00:02, 1049.02it/s]
 57%|█████▋    | 2946/5153 [00:02<00:02, 1050.02it/s]
 59%|█████▉    | 3052/5153 [00:02<00:01, 1051.02it/s]
 61%|██████▏   | 3158/5153 [00:03<00:01, 1050.33it/s]
 63%|██████▎   | 3264/5153 [00:03<00:01, 1050.19it/s]
 65%|██████▌   | 3370/5153 [00:03<00:01, 1049.50it/s]
 67%|██████▋   | 3475/5153 [00:03<00:01, 1049.12it/s]
 69%|██████▉   | 3581/5153 [00:03<00:01, 1049.94it/s]
 72%|███████▏  | 3686/5153 [00:03<00:01, 1047.60it/s]
 74%|███████▎  | 3791/5153 [00:03<00:01, 1044.66it/s]
 76%|███████▌  | 3896/5153 [00:03<00:01, 1044.69it/s]
 78%|███████▊  | 4001/5153 [00:03<00:01, 1046.10it/s]
 80%|███████▉  | 4106/5153 [00:03<00:01, 1046.16it/s]
 82%|████████▏ | 4212/5153 [00:04<00:00, 1050.06it/s]
 84%|████████▍ | 4318/5153 [00:04<00:00, 1052.65it/s]
 86%|████████▌ | 4424/5153 [00:04<00:00, 1053.48it/s]
 88%|████████▊ | 4530/5153 [00:04<00:00, 1053.52it/s]
 90%|████████▉ | 4636/5153 [00:04<00:00, 1052.83it/s]
 92%|█████████▏| 4742/5153 [00:04<00:00, 1051.94it/s]
 94%|█████████▍| 4848/5153 [00:04<00:00, 1050.79it/s]
 96%|█████████▌| 4954/5153 [00:04<00:00, 1049.74it/s]
 98%|█████████▊| 5059/5153 [00:04<00:00, 1048.69it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1046.15it/s]
2024-11-21:14:48:58,859 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:49:30,425 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:30,425 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:30,470 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1036.60it/s]
  4%|▍         | 210/5153 [00:00<00:04, 1047.68it/s]
  6%|▌         | 317/5153 [00:00<00:04, 1054.72it/s]
  8%|▊         | 424/5153 [00:00<00:04, 1058.19it/s]
 10%|█         | 531/5153 [00:00<00:04, 1059.50it/s]
 12%|█▏        | 639/5153 [00:00<00:04, 1063.55it/s]
 14%|█▍        | 746/5153 [00:00<00:04, 1065.44it/s]
 17%|█▋        | 854/5153 [00:00<00:04, 1067.27it/s]
 19%|█▊        | 962/5153 [00:00<00:03, 1069.86it/s]
 21%|██        | 1069/5153 [00:01<00:03, 1055.23it/s]
 23%|██▎       | 1177/5153 [00:01<00:03, 1061.01it/s]
 25%|██▍       | 1285/5153 [00:01<00:03, 1064.61it/s]
 27%|██▋       | 1392/5153 [00:01<00:03, 1065.38it/s]
 29%|██▉       | 1500/5153 [00:01<00:03, 1067.16it/s]
 31%|███       | 1608/5153 [00:01<00:03, 1068.83it/s]
 33%|███▎      | 1716/5153 [00:01<00:03, 1069.25it/s]
 35%|███▌      | 1823/5153 [00:01<00:03, 1066.51it/s]
 37%|███▋      | 1930/5153 [00:01<00:03, 1063.61it/s]
 40%|███▉      | 2037/5153 [00:01<00:02, 1062.61it/s]
 42%|████▏     | 2144/5153 [00:02<00:02, 1062.11it/s]
 44%|████▎     | 2251/5153 [00:02<00:02, 1061.69it/s]
 46%|████▌     | 2358/5153 [00:02<00:02, 1049.92it/s]
 48%|████▊     | 2465/5153 [00:02<00:02, 1054.14it/s]
 50%|████▉     | 2572/5153 [00:02<00:02, 1058.64it/s]
 52%|█████▏    | 2679/5153 [00:02<00:02, 1061.61it/s]
 54%|█████▍    | 2787/5153 [00:02<00:02, 1066.13it/s]
 56%|█████▌    | 2895/5153 [00:02<00:02, 1067.97it/s]
 58%|█████▊    | 3003/5153 [00:02<00:02, 1068.60it/s]
 60%|██████    | 3110/5153 [00:02<00:01, 1066.91it/s]
 62%|██████▏   | 3217/5153 [00:03<00:01, 1064.97it/s]
 65%|██████▍   | 3324/5153 [00:03<00:01, 1063.72it/s]
 67%|██████▋   | 3431/5153 [00:03<00:01, 1062.95it/s]
 69%|██████▊   | 3538/5153 [00:03<00:01, 1063.23it/s]
 71%|███████   | 3646/5153 [00:03<00:01, 1065.35it/s]
 73%|███████▎  | 3753/5153 [00:03<00:01, 1066.44it/s]
 75%|███████▍  | 3860/5153 [00:03<00:01, 1062.23it/s]
 77%|███████▋  | 3967/5153 [00:03<00:01, 1060.19it/s]
 79%|███████▉  | 4075/5153 [00:03<00:01, 1063.41it/s]
 81%|████████  | 4183/5153 [00:03<00:00, 1066.52it/s]
 83%|████████▎ | 4290/5153 [00:04<00:00, 1065.58it/s]
 85%|████████▌ | 4397/5153 [00:04<00:00, 1065.91it/s]
 87%|████████▋ | 4504/5153 [00:04<00:00, 1065.11it/s]
 89%|████████▉ | 4611/5153 [00:04<00:00, 1064.94it/s]
 92%|█████████▏| 4718/5153 [00:04<00:00, 1064.10it/s]
 94%|█████████▎| 4825/5153 [00:04<00:00, 1063.83it/s]
 96%|█████████▌| 4932/5153 [00:04<00:00, 1063.50it/s]
 98%|█████████▊| 5039/5153 [00:04<00:00, 1064.90it/s]
100%|█████████▉| 5146/5153 [00:04<00:00, 1065.44it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1063.30it/s]
2024-11-21:14:49:35,360 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:50:08,841 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:08,841 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:50:08,887 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 105/5153 [00:00<00:04, 1042.14it/s]
  4%|▍         | 210/5153 [00:00<00:04, 1042.58it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1042.85it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1042.14it/s]
 10%|█         | 525/5153 [00:00<00:04, 1041.66it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1030.61it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1038.74it/s]
 16%|█▋        | 842/5153 [00:00<00:04, 1043.49it/s]
 18%|█▊        | 948/5153 [00:00<00:04, 1046.89it/s]
 20%|██        | 1054/5153 [00:01<00:03, 1049.04it/s]
 23%|██▎       | 1161/5153 [00:01<00:03, 1052.73it/s]
 25%|██▍       | 1267/5153 [00:01<00:03, 1052.43it/s]
 27%|██▋       | 1373/5153 [00:01<00:03, 1053.53it/s]
 29%|██▊       | 1479/5153 [00:01<00:03, 1053.61it/s]
 31%|███       | 1585/5153 [00:01<00:03, 1054.67it/s]
 33%|███▎      | 1691/5153 [00:01<00:03, 1054.43it/s]
 35%|███▍      | 1797/5153 [00:01<00:03, 1054.08it/s]
 37%|███▋      | 1903/5153 [00:01<00:03, 1038.14it/s]
 39%|███▉      | 2009/5153 [00:01<00:03, 1041.75it/s]
 41%|████      | 2116/5153 [00:02<00:02, 1047.75it/s]
 43%|████▎     | 2223/5153 [00:02<00:02, 1051.90it/s]
 45%|████▌     | 2330/5153 [00:02<00:02, 1055.15it/s]
 47%|████▋     | 2436/5153 [00:02<00:02, 1056.30it/s]
 49%|████▉     | 2542/5153 [00:02<00:02, 1055.73it/s]
 51%|█████▏    | 2648/5153 [00:02<00:02, 1054.99it/s]
 53%|█████▎    | 2754/5153 [00:02<00:02, 1054.96it/s]
 56%|█████▌    | 2860/5153 [00:02<00:02, 1054.78it/s]
 58%|█████▊    | 2966/5153 [00:02<00:02, 1053.06it/s]
 60%|█████▉    | 3072/5153 [00:02<00:01, 1053.43it/s]
 62%|██████▏   | 3178/5153 [00:03<00:01, 1044.44it/s]
 64%|██████▎   | 3284/5153 [00:03<00:01, 1048.14it/s]
 66%|██████▌   | 3390/5153 [00:03<00:01, 1051.33it/s]
 68%|██████▊   | 3496/5153 [00:03<00:01, 1052.82it/s]
 70%|██████▉   | 3602/5153 [00:03<00:01, 1054.79it/s]
 72%|███████▏  | 3708/5153 [00:03<00:01, 1055.00it/s]
 74%|███████▍  | 3814/5153 [00:03<00:01, 1053.22it/s]
 76%|███████▌  | 3920/5153 [00:03<00:01, 1051.11it/s]
 78%|███████▊  | 4026/5153 [00:03<00:01, 1050.66it/s]
 80%|████████  | 4132/5153 [00:03<00:00, 1052.76it/s]
 82%|████████▏ | 4238/5153 [00:04<00:00, 1053.69it/s]
 84%|████████▍ | 4344/5153 [00:04<00:00, 1052.44it/s]
 86%|████████▋ | 4450/5153 [00:04<00:00, 1053.95it/s]
 88%|████████▊ | 4556/5153 [00:04<00:00, 1054.83it/s]
 90%|█████████ | 4662/5153 [00:04<00:00, 1056.11it/s]
 93%|█████████▎| 4768/5153 [00:04<00:00, 1055.17it/s]
 95%|█████████▍| 4874/5153 [00:04<00:00, 1055.67it/s]
 97%|█████████▋| 4980/5153 [00:04<00:00, 1055.78it/s]
 99%|█████████▊| 5086/5153 [00:04<00:00, 1056.36it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1051.13it/s]
2024-11-21:14:50:13,833 INFO     [evaluator.py:489] Running loglikelihood requests
Traceback (most recent call last):
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/test-lm-eval.py", line 35, in <module>
    res = run_lm_eval.do_eval(path, isverbose=False, benchmarks=["lambada_openai"])
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 427, in do_eval
    results = adapter.run_eval(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 385, in run_eval
    results = evaluator.evaluate(
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/evaluator.py", line 500, in evaluate
    resps = getattr(lm, reqtype)(cloned_reqs)
  File "/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lm_eval/api/model.py", line 378, in loglikelihood
    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)
  File "/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/src/run_lm_eval.py", line 343, in _loglikelihood_tokens
    outputs, _ = self.pretrained.forward(src, None, full_output=True)
  File "/home/xl6yq/workspace-rwkv/RWKV-LM/rwkv/model.py", line 2844, in forward
    mlp_weights = (w[f'{bbb}mlp.fc1.weight'], w[f'{bbb}mlp.fc2.weight'])
KeyError: 'blocks.0.mlp.fc1.weight'

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)3=12, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59
#
# Epoch = 656 to 3062 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 3360 steps, 40320 samples, 82575360 tokens
#
# Model = 32 n_layer, 2560 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59/rwkv-655.pth', 'wandb': '', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 3360, 'epoch_count': 2407, 'epoch_begin': 656, 'epoch_save': 10, 'micro_bsz': 3, 'n_layer': 32, 'n_embd': 2560, 'dim_att': 2560, 'dim_ffn': 8960, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x059', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-23-16-39-11', 'betas': (0.9, 0.99), 'real_bsz': 12, 'run_name': '3b-pre-x59', 'my_pile_prev_p': 645}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x59/rwkv-655.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb  --proj_dir /sfs ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 167 M 
1 | blocks | ModuleList | 1.9 B 
2 | ln_out | LayerNorm  | 5.1 K 
3 | head   | Linear     | 167 M 
--------------------------------------
2.3 B     Trainable params
0         Non-trainable params
2.3 B     Total params
9,107.907 Total estimated model params size (MB)

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
INFO:pytorch_lightning.utilities.rank_zero:########## work in progress ##########
INFO:pytorch_lightning.utilities.rank_zero:
############################################################################
#
# RWKV-5 BF16 on 1x4 GPU, bsz 1x4x(Per GPU)3=12, deepspeed_stage_2 
#
# Data = /scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup (binidx), ProjDir = /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x52
#
# Epoch = 826 to 3232 (will continue afterwards), save every 10 epoch
#
# Each "epoch" = 3360 steps, 40320 samples, 82575360 tokens
#
# Model = 32 n_layer, 2560 n_embd, 2048 ctx_len
#
# Adam = lr 0.0003 to 3e-05, warmup 10 steps, beta (0.9, 0.99), eps 1e-08
#
# Found torch 2.3.1+cu121, recommend latest torch
# Found deepspeed 0.14.4, recommend latest deepspeed
# Found pytorch_lightning 1.9.5, recommend 1.9.5
#
############################################################################

INFO:pytorch_lightning.utilities.rank_zero:{'load_model': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x52/rwkv-825.pth', 'wandb': 'rwkv-hpc', 'proj_dir': '/sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x52', 'random_seed': -1, 'train_type': '', 'data_file': '/scratch/xl6yq/data/rwkv-data/pile_dedup/pile_dedup', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 2048, 'epoch_steps': 3360, 'epoch_count': 2407, 'epoch_begin': 826, 'epoch_save': 10, 'micro_bsz': 3, 'n_layer': 32, 'n_embd': 2560, 'dim_att': 2560, 'dim_ffn': 8960, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 0.0003, 'lr_final': 3e-05, 'warmup_steps': 10, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 0, 'dropout': 0, 'weight_decay': 0.001, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 97064741, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': 'x052', 'my_exit': 99999999, 'my_exit_tokens': 198788818379, 'svdfac': 8, 'finetune': 0, 'NoReLu': 0, 'NoDiag': 1, 'head_K': 0, 'load_token_cls': '', 'lm_eval_0': 0, 'lm_eval_n': 0, 'vram_mb': 81920, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': '4', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-11-21-15-27-15', 'betas': (0.9, 0.99), 'real_bsz': 12, 'run_name': '3b-pre-x52', 'my_pile_prev_p': 815}

INFO:pytorch_lightning.utilities.rank_zero:Current vocab size = 65536 (make sure it's correct)
INFO:pytorch_lightning.utilities.rank_zero:Data has 198788818379 tokens.
INFO:pytorch_lightning.utilities.rank_zero:########## Pile 20b-tokenized stage 3 ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.utilities.rank_zero:########## Loading /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/out/3b-pre-x52/rwkv-825.pth... ##########
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 train.py --load_model 0 --wandb rwkv-hpc --proj_ ...
  rank_zero_warn(
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO:pytorch_lightning.utilities.rank_zero:Enabling DeepSpeed BF16.
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /sfs/gpfs/tardis/home/xl6yq/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
INFO:pytorch_lightning.callbacks.model_summary:
  | Name   | Type       | Params
--------------------------------------
0 | emb    | Embedding  | 167 M 
1 | blocks | ModuleList | 2.7 B 
2 | ln_out | LayerNorm  | 5.1 K 
3 | head   | Linear     | 167 M 
--------------------------------------
3.1 B     Trainable params
0         Non-trainable params
3.1 B     Total params
12,251.996Total estimated model params size (MB)
wandb: Currently logged in as: felixlinatuva (xsel). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in /sfs/weka/scratch/xl6yq/workspace-rwkv/RWKV-LM/RWKV-v5/wandb/run-20241121_153051-s817wbfw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 3b-pre-x52 2024-11-21-15-27-15
wandb: ⭐️ View project at https://wandb.ai/xsel/rwkv-hpc
wandb: 🚀 View run at https://wandb.ai/xsel/rwkv-hpc/runs/s817wbfw

========================================
Loaded Miniforge which replaces Anaconda. 
- The conda/mamba executables are included.
- The default channel is conda-forge.

For details see https://www.rc.virginia.edu/2024/10/transition-from-anaconda-to-miniforge-october-15-2024/
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:42:33,803 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:33,804 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:42:33,848 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1033.49it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1042.04it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1045.67it/s]
  8%|▊         | 421/5153 [00:00<00:04, 1047.78it/s]
 10%|█         | 527/5153 [00:00<00:04, 1048.95it/s]
 12%|█▏        | 633/5153 [00:00<00:04, 1052.25it/s]
 14%|█▍        | 739/5153 [00:00<00:04, 1052.24it/s]
 16%|█▋        | 845/5153 [00:00<00:04, 1052.49it/s]
 18%|█▊        | 951/5153 [00:00<00:04, 1050.34it/s]
 21%|██        | 1057/5153 [00:01<00:03, 1050.81it/s]
 23%|██▎       | 1163/5153 [00:01<00:03, 1053.02it/s]
 25%|██▍       | 1269/5153 [00:01<00:03, 1054.04it/s]
 27%|██▋       | 1376/5153 [00:01<00:03, 1056.91it/s]
 29%|██▉       | 1483/5153 [00:01<00:03, 1058.96it/s]
 31%|███       | 1590/5153 [00:01<00:03, 1059.36it/s]
 33%|███▎      | 1696/5153 [00:01<00:03, 1056.15it/s]
 35%|███▍      | 1802/5153 [00:01<00:03, 1056.14it/s]
 37%|███▋      | 1908/5153 [00:01<00:03, 1053.84it/s]
 39%|███▉      | 2014/5153 [00:01<00:02, 1052.77it/s]
 41%|████      | 2120/5153 [00:02<00:02, 1050.33it/s]
 43%|████▎     | 2226/5153 [00:02<00:02, 1050.35it/s]
 45%|████▌     | 2332/5153 [00:02<00:02, 1052.47it/s]
 47%|████▋     | 2438/5153 [00:02<00:02, 1053.03it/s]
 49%|████▉     | 2545/5153 [00:02<00:02, 1056.83it/s]
 51%|█████▏    | 2652/5153 [00:02<00:02, 1057.97it/s]
 54%|█████▎    | 2759/5153 [00:02<00:02, 1059.18it/s]
 56%|█████▌    | 2866/5153 [00:02<00:02, 1061.23it/s]
 58%|█████▊    | 2973/5153 [00:02<00:02, 1060.41it/s]
 60%|█████▉    | 3080/5153 [00:02<00:01, 1059.17it/s]
 62%|██████▏   | 3186/5153 [00:03<00:01, 1057.80it/s]
 64%|██████▍   | 3292/5153 [00:03<00:01, 1054.01it/s]
 66%|██████▌   | 3398/5153 [00:03<00:01, 1054.38it/s]
 68%|██████▊   | 3504/5153 [00:03<00:01, 1053.97it/s]
 70%|███████   | 3610/5153 [00:03<00:01, 1055.05it/s]
 72%|███████▏  | 3716/5153 [00:03<00:01, 1055.32it/s]
 74%|███████▍  | 3822/5153 [00:03<00:01, 1055.84it/s]
 76%|███████▌  | 3928/5153 [00:03<00:01, 1055.83it/s]
 78%|███████▊  | 4035/5153 [00:03<00:01, 1058.33it/s]
 80%|████████  | 4142/5153 [00:03<00:00, 1059.31it/s]
 82%|████████▏ | 4249/5153 [00:04<00:00, 1059.60it/s]
 85%|████████▍ | 4355/5153 [00:04<00:00, 1059.03it/s]
 87%|████████▋ | 4461/5153 [00:04<00:00, 1054.85it/s]
 89%|████████▊ | 4567/5153 [00:04<00:00, 1055.35it/s]
 91%|█████████ | 4673/5153 [00:04<00:00, 1053.15it/s]
 93%|█████████▎| 4779/5153 [00:04<00:00, 1053.64it/s]
 95%|█████████▍| 4885/5153 [00:04<00:00, 1054.05it/s]
 97%|█████████▋| 4991/5153 [00:04<00:00, 1053.27it/s]
 99%|█████████▉| 5097/5153 [00:04<00:00, 1053.88it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1054.53it/s]
2024-11-21:14:42:38,777 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.02s/it]
100%|██████████| 10/10 [00:03<00:00,  3.29it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:44:58,017 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:58,017 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:44:58,063 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1034.56it/s]
  4%|▍         | 210/5153 [00:00<00:04, 1044.72it/s]
  6%|▌         | 316/5153 [00:00<00:04, 1048.85it/s]
  8%|▊         | 422/5153 [00:00<00:04, 1050.14it/s]
 10%|█         | 528/5153 [00:00<00:04, 1050.55it/s]
 12%|█▏        | 634/5153 [00:00<00:04, 1052.37it/s]
 14%|█▍        | 740/5153 [00:00<00:04, 1054.37it/s]
 16%|█▋        | 847/5153 [00:00<00:04, 1056.72it/s]
 19%|█▊        | 954/5153 [00:00<00:03, 1058.37it/s]
 21%|██        | 1061/5153 [00:01<00:03, 1060.74it/s]
 23%|██▎       | 1168/5153 [00:01<00:03, 1062.67it/s]
 25%|██▍       | 1275/5153 [00:01<00:03, 1064.50it/s]
 27%|██▋       | 1382/5153 [00:01<00:03, 1065.03it/s]
 29%|██▉       | 1489/5153 [00:01<00:03, 1064.01it/s]
 31%|███       | 1596/5153 [00:01<00:03, 1061.52it/s]
 33%|███▎      | 1703/5153 [00:01<00:03, 1057.96it/s]
 35%|███▌      | 1809/5153 [00:01<00:03, 1057.37it/s]
 37%|███▋      | 1916/5153 [00:01<00:03, 1058.18it/s]
 39%|███▉      | 2023/5153 [00:01<00:02, 1060.57it/s]
 41%|████▏     | 2130/5153 [00:02<00:02, 1062.36it/s]
 43%|████▎     | 2237/5153 [00:02<00:02, 1063.87it/s]
 45%|████▌     | 2344/5153 [00:02<00:02, 1065.29it/s]
 48%|████▊     | 2451/5153 [00:02<00:02, 1066.38it/s]
 50%|████▉     | 2558/5153 [00:02<00:02, 1066.41it/s]
 52%|█████▏    | 2665/5153 [00:02<00:02, 1065.06it/s]
 54%|█████▍    | 2772/5153 [00:02<00:02, 1064.19it/s]
 56%|█████▌    | 2879/5153 [00:02<00:02, 1063.24it/s]
 58%|█████▊    | 2986/5153 [00:02<00:02, 1059.62it/s]
 60%|██████    | 3093/5153 [00:02<00:01, 1059.76it/s]
 62%|██████▏   | 3200/5153 [00:03<00:01, 1061.44it/s]
 64%|██████▍   | 3307/5153 [00:03<00:01, 1061.24it/s]
 66%|██████▋   | 3415/5153 [00:03<00:01, 1064.49it/s]
 68%|██████▊   | 3523/5153 [00:03<00:01, 1066.70it/s]
 70%|███████   | 3630/5153 [00:03<00:01, 1067.19it/s]
 73%|███████▎  | 3737/5153 [00:03<00:01, 1067.40it/s]
 75%|███████▍  | 3844/5153 [00:03<00:01, 1067.75it/s]
 77%|███████▋  | 3951/5153 [00:03<00:01, 1065.88it/s]
 79%|███████▉  | 4058/5153 [00:03<00:01, 1064.48it/s]
 81%|████████  | 4165/5153 [00:03<00:00, 1062.36it/s]
 83%|████████▎ | 4272/5153 [00:04<00:00, 1061.24it/s]
 85%|████████▍ | 4379/5153 [00:04<00:00, 1061.46it/s]
 87%|████████▋ | 4486/5153 [00:04<00:00, 1061.52it/s]
 89%|████████▉ | 4593/5153 [00:04<00:00, 1062.48it/s]
 91%|█████████ | 4700/5153 [00:04<00:00, 1062.19it/s]
 93%|█████████▎| 4807/5153 [00:04<00:00, 1062.69it/s]
 95%|█████████▌| 4914/5153 [00:04<00:00, 1062.86it/s]
 97%|█████████▋| 5021/5153 [00:04<00:00, 1062.40it/s]
100%|█████████▉| 5128/5153 [00:04<00:00, 1061.93it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1061.30it/s]
2024-11-21:14:45:02,960 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.02s/it]
100%|██████████| 10/10 [00:03<00:00,  3.29it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:47:21,721 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:21,721 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:47:21,766 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1039.16it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1044.38it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1047.71it/s]
  8%|▊         | 420/5153 [00:00<00:04, 1048.22it/s]
 10%|█         | 525/5153 [00:00<00:04, 1048.35it/s]
 12%|█▏        | 632/5153 [00:00<00:04, 1053.68it/s]
 14%|█▍        | 738/5153 [00:00<00:04, 1055.00it/s]
 16%|█▋        | 844/5153 [00:00<00:04, 1054.77it/s]
 18%|█▊        | 950/5153 [00:00<00:03, 1056.19it/s]
 21%|██        | 1057/5153 [00:01<00:03, 1057.92it/s]
 23%|██▎       | 1164/5153 [00:01<00:03, 1060.58it/s]
 25%|██▍       | 1271/5153 [00:01<00:03, 1061.93it/s]
 27%|██▋       | 1379/5153 [00:01<00:03, 1064.42it/s]
 29%|██▉       | 1486/5153 [00:01<00:03, 1064.48it/s]
 31%|███       | 1593/5153 [00:01<00:03, 1062.63it/s]
 33%|███▎      | 1700/5153 [00:01<00:03, 1059.96it/s]
 35%|███▌      | 1806/5153 [00:01<00:03, 1057.09it/s]
 37%|███▋      | 1912/5153 [00:01<00:03, 1057.38it/s]
 39%|███▉      | 2018/5153 [00:01<00:02, 1056.49it/s]
 41%|████      | 2125/5153 [00:02<00:02, 1058.23it/s]
 43%|████▎     | 2232/5153 [00:02<00:02, 1059.65it/s]
 45%|████▌     | 2339/5153 [00:02<00:02, 1061.07it/s]
 47%|████▋     | 2446/5153 [00:02<00:02, 1061.02it/s]
 50%|████▉     | 2553/5153 [00:02<00:02, 1063.03it/s]
 52%|█████▏    | 2660/5153 [00:02<00:02, 1062.83it/s]
 54%|█████▎    | 2767/5153 [00:02<00:02, 1060.45it/s]
 56%|█████▌    | 2874/5153 [00:02<00:02, 1058.72it/s]
 58%|█████▊    | 2980/5153 [00:02<00:02, 1057.74it/s]
 60%|█████▉    | 3086/5153 [00:02<00:01, 1056.93it/s]
 62%|██████▏   | 3192/5153 [00:03<00:01, 1053.56it/s]
 64%|██████▍   | 3298/5153 [00:03<00:01, 1054.05it/s]
 66%|██████▌   | 3404/5153 [00:03<00:01, 1055.56it/s]
 68%|██████▊   | 3511/5153 [00:03<00:01, 1058.30it/s]
 70%|███████   | 3618/5153 [00:03<00:01, 1059.13it/s]
 72%|███████▏  | 3725/5153 [00:03<00:01, 1060.31it/s]
 74%|███████▍  | 3832/5153 [00:03<00:01, 1060.98it/s]
 76%|███████▋  | 3939/5153 [00:03<00:01, 1059.51it/s]
 78%|███████▊  | 4045/5153 [00:03<00:01, 1057.77it/s]
 81%|████████  | 4151/5153 [00:03<00:00, 1057.64it/s]
 83%|████████▎ | 4257/5153 [00:04<00:00, 1057.77it/s]
 85%|████████▍ | 4363/5153 [00:04<00:00, 1054.27it/s]
 87%|████████▋ | 4469/5153 [00:04<00:00, 1055.78it/s]
 89%|████████▉ | 4575/5153 [00:04<00:00, 1056.18it/s]
 91%|█████████ | 4681/5153 [00:04<00:00, 1056.52it/s]
 93%|█████████▎| 4788/5153 [00:04<00:00, 1057.68it/s]
 95%|█████████▍| 4894/5153 [00:04<00:00, 1058.11it/s]
 97%|█████████▋| 5000/5153 [00:04<00:00, 1058.25it/s]
 99%|█████████▉| 5106/5153 [00:04<00:00, 1058.23it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1057.61it/s]
2024-11-21:14:47:26,680 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:02<00:26,  3.00s/it]
100%|██████████| 10/10 [00:03<00:00,  3.31it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:49:45,216 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:45,216 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:49:45,261 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.81it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1034.40it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1036.46it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1039.58it/s]
 10%|█         | 521/5153 [00:00<00:04, 1041.02it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1045.41it/s]
 14%|█▍        | 732/5153 [00:00<00:04, 1046.03it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1046.75it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1044.95it/s]
 20%|██        | 1047/5153 [00:01<00:03, 1042.17it/s]
 22%|██▏       | 1153/5153 [00:01<00:03, 1045.12it/s]
 24%|██▍       | 1259/5153 [00:01<00:03, 1047.55it/s]
 26%|██▋       | 1365/5153 [00:01<00:03, 1049.34it/s]
 29%|██▊       | 1471/5153 [00:01<00:03, 1051.91it/s]
 31%|███       | 1577/5153 [00:01<00:03, 1053.68it/s]
 33%|███▎      | 1683/5153 [00:01<00:03, 1054.21it/s]
 35%|███▍      | 1789/5153 [00:01<00:03, 1051.13it/s]
 37%|███▋      | 1895/5153 [00:01<00:03, 1050.58it/s]
 39%|███▉      | 2001/5153 [00:01<00:03, 1049.84it/s]
 41%|████      | 2107/5153 [00:02<00:02, 1050.73it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1047.58it/s]
 45%|████▍     | 2318/5153 [00:02<00:02, 1047.88it/s]
 47%|████▋     | 2424/5153 [00:02<00:02, 1049.29it/s]
 49%|████▉     | 2530/5153 [00:02<00:02, 1050.80it/s]
 51%|█████     | 2636/5153 [00:02<00:02, 1052.19it/s]
 53%|█████▎    | 2742/5153 [00:02<00:02, 1053.56it/s]
 55%|█████▌    | 2848/5153 [00:02<00:02, 1055.40it/s]
 57%|█████▋    | 2954/5153 [00:02<00:02, 1055.35it/s]
 59%|█████▉    | 3060/5153 [00:02<00:01, 1054.39it/s]
 61%|██████▏   | 3166/5153 [00:03<00:01, 1053.31it/s]
 63%|██████▎   | 3272/5153 [00:03<00:01, 1053.44it/s]
 66%|██████▌   | 3378/5153 [00:03<00:01, 1050.02it/s]
 68%|██████▊   | 3484/5153 [00:03<00:01, 1049.92it/s]
 70%|██████▉   | 3589/5153 [00:03<00:01, 1049.18it/s]
 72%|███████▏  | 3694/5153 [00:03<00:01, 1049.15it/s]
 74%|███████▎  | 3800/5153 [00:03<00:01, 1051.11it/s]
 76%|███████▌  | 3906/5153 [00:03<00:01, 1051.45it/s]
 78%|███████▊  | 4012/5153 [00:03<00:01, 1053.14it/s]
 80%|███████▉  | 4119/5153 [00:03<00:00, 1055.51it/s]
 82%|████████▏ | 4225/5153 [00:04<00:00, 1056.63it/s]
 84%|████████▍ | 4331/5153 [00:04<00:00, 1055.16it/s]
 86%|████████▌ | 4437/5153 [00:04<00:00, 1053.69it/s]
 88%|████████▊ | 4543/5153 [00:04<00:00, 1050.33it/s]
 90%|█████████ | 4649/5153 [00:04<00:00, 1049.83it/s]
 92%|█████████▏| 4755/5153 [00:04<00:00, 1050.35it/s]
 94%|█████████▍| 4861/5153 [00:04<00:00, 1050.52it/s]
 96%|█████████▋| 4967/5153 [00:04<00:00, 1050.54it/s]
 98%|█████████▊| 5073/5153 [00:04<00:00, 1052.89it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1050.04it/s]
2024-11-21:14:49:50,211 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.01s/it]
100%|██████████| 10/10 [00:03<00:00,  3.31it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:52:09,151 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:09,151 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:52:09,196 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1027.99it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.20it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1034.84it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1039.11it/s]
 10%|█         | 521/5153 [00:00<00:04, 1039.53it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1043.04it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1044.69it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1045.28it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1045.27it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1045.50it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1045.39it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1046.52it/s]
 26%|██▋       | 1362/5153 [00:01<00:03, 1049.23it/s]
 28%|██▊       | 1468/5153 [00:01<00:03, 1050.42it/s]
 31%|███       | 1574/5153 [00:01<00:03, 1050.81it/s]
 33%|███▎      | 1680/5153 [00:01<00:03, 1051.11it/s]
 35%|███▍      | 1786/5153 [00:01<00:03, 1049.42it/s]
 37%|███▋      | 1891/5153 [00:01<00:03, 1049.24it/s]
 39%|███▉      | 1997/5153 [00:01<00:03, 1050.52it/s]
 41%|████      | 2103/5153 [00:02<00:02, 1051.70it/s]
 43%|████▎     | 2209/5153 [00:02<00:02, 1051.53it/s]
 45%|████▍     | 2315/5153 [00:02<00:02, 1047.50it/s]
 47%|████▋     | 2420/5153 [00:02<00:02, 1047.60it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1047.47it/s]
 51%|█████     | 2630/5153 [00:02<00:02, 1047.99it/s]
 53%|█████▎    | 2736/5153 [00:02<00:02, 1049.27it/s]
 55%|█████▌    | 2842/5153 [00:02<00:02, 1050.80it/s]
 57%|█████▋    | 2948/5153 [00:02<00:02, 1049.34it/s]
 59%|█████▉    | 3053/5153 [00:02<00:02, 1049.22it/s]
 61%|██████▏   | 3159/5153 [00:03<00:01, 1050.11it/s]
 63%|██████▎   | 3265/5153 [00:03<00:01, 1050.30it/s]
 65%|██████▌   | 3371/5153 [00:03<00:01, 1050.10it/s]
 67%|██████▋   | 3477/5153 [00:03<00:01, 1047.03it/s]
 70%|██████▉   | 3582/5153 [00:03<00:01, 1047.49it/s]
 72%|███████▏  | 3687/5153 [00:03<00:01, 1047.42it/s]
 74%|███████▎  | 3793/5153 [00:03<00:01, 1049.01it/s]
 76%|███████▌  | 3899/5153 [00:03<00:01, 1049.97it/s]
 78%|███████▊  | 4005/5153 [00:03<00:01, 1050.31it/s]
 80%|███████▉  | 4111/5153 [00:03<00:00, 1050.29it/s]
 82%|████████▏ | 4217/5153 [00:04<00:00, 1049.64it/s]
 84%|████████▍ | 4322/5153 [00:04<00:00, 1048.61it/s]
 86%|████████▌ | 4428/5153 [00:04<00:00, 1049.19it/s]
 88%|████████▊ | 4533/5153 [00:04<00:00, 1048.82it/s]
 90%|█████████ | 4638/5153 [00:04<00:00, 1048.22it/s]
 92%|█████████▏| 4743/5153 [00:04<00:00, 1046.97it/s]
 94%|█████████▍| 4848/5153 [00:04<00:00, 1047.19it/s]
 96%|█████████▌| 4953/5153 [00:04<00:00, 1047.11it/s]
 98%|█████████▊| 5058/5153 [00:04<00:00, 1045.21it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.48it/s]
2024-11-21:14:52:14,158 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.03s/it]
100%|██████████| 10/10 [00:03<00:00,  3.27it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:54:32,561 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:32,561 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:54:32,605 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1022.12it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1030.10it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1032.48it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1035.80it/s]
 10%|█         | 521/5153 [00:00<00:04, 1037.36it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1039.51it/s]
 14%|█▍        | 730/5153 [00:00<00:04, 1038.18it/s]
 16%|█▌        | 835/5153 [00:00<00:04, 1039.80it/s]
 18%|█▊        | 940/5153 [00:00<00:04, 1040.02it/s]
 20%|██        | 1045/5153 [00:01<00:03, 1041.45it/s]
 22%|██▏       | 1150/5153 [00:01<00:03, 1042.27it/s]
 24%|██▍       | 1255/5153 [00:01<00:03, 1044.43it/s]
 26%|██▋       | 1361/5153 [00:01<00:03, 1046.60it/s]
 28%|██▊       | 1467/5153 [00:01<00:03, 1050.27it/s]
 31%|███       | 1573/5153 [00:01<00:03, 1050.12it/s]
 33%|███▎      | 1679/5153 [00:01<00:03, 1048.86it/s]
 35%|███▍      | 1785/5153 [00:01<00:03, 1049.24it/s]
 37%|███▋      | 1890/5153 [00:01<00:03, 1047.19it/s]
 39%|███▊      | 1996/5153 [00:01<00:03, 1049.70it/s]
 41%|████      | 2102/5153 [00:02<00:02, 1049.82it/s]
 43%|████▎     | 2208/5153 [00:02<00:02, 1049.86it/s]
 45%|████▍     | 2313/5153 [00:02<00:02, 1048.48it/s]
 47%|████▋     | 2418/5153 [00:02<00:02, 1047.28it/s]
 49%|████▉     | 2523/5153 [00:02<00:02, 1047.65it/s]
 51%|█████     | 2628/5153 [00:02<00:02, 1047.98it/s]
 53%|█████▎    | 2734/5153 [00:02<00:02, 1049.13it/s]
 55%|█████▌    | 2840/5153 [00:02<00:02, 1050.49it/s]
 57%|█████▋    | 2946/5153 [00:02<00:02, 1050.44it/s]
 59%|█████▉    | 3052/5153 [00:02<00:02, 1048.37it/s]
 61%|██████▏   | 3158/5153 [00:03<00:01, 1048.96it/s]
 63%|██████▎   | 3264/5153 [00:03<00:01, 1049.36it/s]
 65%|██████▌   | 3369/5153 [00:03<00:01, 1048.44it/s]
 67%|██████▋   | 3474/5153 [00:03<00:01, 1047.82it/s]
 69%|██████▉   | 3579/5153 [00:03<00:01, 1047.00it/s]
 71%|███████▏  | 3684/5153 [00:03<00:01, 1047.49it/s]
 74%|███████▎  | 3789/5153 [00:03<00:01, 1048.01it/s]
 76%|███████▌  | 3895/5153 [00:03<00:01, 1048.73it/s]
 78%|███████▊  | 4001/5153 [00:03<00:01, 1049.64it/s]
 80%|███████▉  | 4107/5153 [00:03<00:00, 1052.40it/s]
 82%|████████▏ | 4213/5153 [00:04<00:00, 1051.48it/s]
 84%|████████▍ | 4319/5153 [00:04<00:00, 1051.22it/s]
 86%|████████▌ | 4425/5153 [00:04<00:00, 1051.62it/s]
 88%|████████▊ | 4531/5153 [00:04<00:00, 1050.37it/s]
 90%|████████▉ | 4637/5153 [00:04<00:00, 1049.84it/s]
 92%|█████████▏| 4742/5153 [00:04<00:00, 1048.21it/s]
 94%|█████████▍| 4847/5153 [00:04<00:00, 1048.32it/s]
 96%|█████████▌| 4952/5153 [00:04<00:00, 1048.20it/s]
 98%|█████████▊| 5057/5153 [00:04<00:00, 1047.32it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1046.94it/s]
2024-11-21:14:54:37,568 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:27,  3.08s/it]
100%|██████████| 10/10 [00:03<00:00,  3.23it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:56:56,981 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:56,981 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:56:57,025 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1032.12it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1032.46it/s]
  6%|▌         | 313/5153 [00:00<00:04, 1037.22it/s]
  8%|▊         | 418/5153 [00:00<00:04, 1038.37it/s]
 10%|█         | 522/5153 [00:00<00:04, 1037.44it/s]
 12%|█▏        | 627/5153 [00:00<00:04, 1040.56it/s]
 14%|█▍        | 732/5153 [00:00<00:04, 1043.10it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1043.22it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1043.97it/s]
 20%|██        | 1047/5153 [00:01<00:03, 1045.38it/s]
 22%|██▏       | 1153/5153 [00:01<00:03, 1048.60it/s]
 24%|██▍       | 1259/5153 [00:01<00:03, 1050.78it/s]
 26%|██▋       | 1365/5153 [00:01<00:03, 1049.42it/s]
 29%|██▊       | 1471/5153 [00:01<00:03, 1050.78it/s]
 31%|███       | 1577/5153 [00:01<00:03, 1050.36it/s]
 33%|███▎      | 1683/5153 [00:01<00:03, 1051.72it/s]
 35%|███▍      | 1789/5153 [00:01<00:03, 1049.27it/s]
 37%|███▋      | 1894/5153 [00:01<00:03, 1047.60it/s]
 39%|███▉      | 1999/5153 [00:01<00:03, 1047.64it/s]
 41%|████      | 2104/5153 [00:02<00:02, 1046.38it/s]
 43%|████▎     | 2209/5153 [00:02<00:02, 1047.09it/s]
 45%|████▍     | 2314/5153 [00:02<00:02, 1047.87it/s]
 47%|████▋     | 2420/5153 [00:02<00:02, 1048.79it/s]
 49%|████▉     | 2525/5153 [00:02<00:02, 1049.11it/s]
 51%|█████     | 2631/5153 [00:02<00:02, 1050.20it/s]
 53%|█████▎    | 2737/5153 [00:02<00:02, 1051.67it/s]
 55%|█████▌    | 2843/5153 [00:02<00:02, 1052.23it/s]
 57%|█████▋    | 2949/5153 [00:02<00:02, 1051.07it/s]
 59%|█████▉    | 3055/5153 [00:02<00:01, 1050.06it/s]
 61%|██████▏   | 3161/5153 [00:03<00:01, 1048.41it/s]
 63%|██████▎   | 3266/5153 [00:03<00:01, 1047.78it/s]
 65%|██████▌   | 3371/5153 [00:03<00:01, 1047.48it/s]
 67%|██████▋   | 3476/5153 [00:03<00:01, 1047.24it/s]
 69%|██████▉   | 3581/5153 [00:03<00:01, 1047.01it/s]
 72%|███████▏  | 3686/5153 [00:03<00:01, 1045.65it/s]
 74%|███████▎  | 3792/5153 [00:03<00:01, 1048.63it/s]
 76%|███████▌  | 3898/5153 [00:03<00:01, 1050.46it/s]
 78%|███████▊  | 4004/5153 [00:03<00:01, 1050.40it/s]
 80%|███████▉  | 4110/5153 [00:03<00:00, 1052.15it/s]
 82%|████████▏ | 4216/5153 [00:04<00:00, 1051.70it/s]
 84%|████████▍ | 4322/5153 [00:04<00:00, 1049.27it/s]
 86%|████████▌ | 4427/5153 [00:04<00:00, 1048.48it/s]
 88%|████████▊ | 4532/5153 [00:04<00:00, 1047.53it/s]
 90%|████████▉ | 4637/5153 [00:04<00:00, 1046.44it/s]
 92%|█████████▏| 4742/5153 [00:04<00:00, 1045.28it/s]
 94%|█████████▍| 4847/5153 [00:04<00:00, 1043.94it/s]
 96%|█████████▌| 4952/5153 [00:04<00:00, 1044.81it/s]
 98%|█████████▊| 5057/5153 [00:04<00:00, 1044.14it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1047.06it/s]
2024-11-21:14:57:01,989 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.21s/it]
100%|██████████| 10/10 [00:03<00:00,  3.10it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:14:59:23,219 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:59:23,219 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:14:59:23,263 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1029.68it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1031.12it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1033.98it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1036.40it/s]
 10%|█         | 521/5153 [00:00<00:04, 1037.85it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1041.09it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1042.83it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1045.19it/s]
 18%|█▊        | 943/5153 [00:00<00:04, 1046.84it/s]
 20%|██        | 1049/5153 [00:01<00:03, 1047.88it/s]
 22%|██▏       | 1155/5153 [00:01<00:03, 1051.37it/s]
 24%|██▍       | 1261/5153 [00:01<00:03, 1050.69it/s]
 27%|██▋       | 1367/5153 [00:01<00:03, 1050.18it/s]
 29%|██▊       | 1473/5153 [00:01<00:03, 1051.32it/s]
 31%|███       | 1579/5153 [00:01<00:03, 1049.85it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1048.59it/s]
 35%|███▍      | 1790/5153 [00:01<00:03, 1050.03it/s]
 37%|███▋      | 1896/5153 [00:01<00:03, 1050.47it/s]
 39%|███▉      | 2002/5153 [00:01<00:02, 1051.85it/s]
 41%|████      | 2108/5153 [00:02<00:02, 1052.72it/s]
 43%|████▎     | 2214/5153 [00:02<00:02, 1053.93it/s]
 45%|████▌     | 2320/5153 [00:02<00:02, 1054.52it/s]
 47%|████▋     | 2426/5153 [00:02<00:02, 1053.49it/s]
 49%|████▉     | 2532/5153 [00:02<00:02, 1050.97it/s]
 51%|█████     | 2638/5153 [00:02<00:02, 1051.18it/s]
 53%|█████▎    | 2744/5153 [00:02<00:02, 1051.80it/s]
 55%|█████▌    | 2850/5153 [00:02<00:02, 1052.26it/s]
 57%|█████▋    | 2956/5153 [00:02<00:02, 1052.28it/s]
 59%|█████▉    | 3062/5153 [00:02<00:01, 1051.04it/s]
 61%|██████▏   | 3168/5153 [00:03<00:01, 1050.98it/s]
 64%|██████▎   | 3274/5153 [00:03<00:01, 1050.57it/s]
 66%|██████▌   | 3380/5153 [00:03<00:01, 1051.52it/s]
 68%|██████▊   | 3486/5153 [00:03<00:01, 1053.69it/s]
 70%|██████▉   | 3592/5153 [00:03<00:01, 1053.26it/s]
 72%|███████▏  | 3698/5153 [00:03<00:01, 1052.27it/s]
 74%|███████▍  | 3804/5153 [00:03<00:01, 1052.38it/s]
 76%|███████▌  | 3910/5153 [00:03<00:01, 1050.33it/s]
 78%|███████▊  | 4016/5153 [00:03<00:01, 1048.87it/s]
 80%|███████▉  | 4122/5153 [00:03<00:00, 1049.60it/s]
 82%|████████▏ | 4228/5153 [00:04<00:00, 1050.08it/s]
 84%|████████▍ | 4334/5153 [00:04<00:00, 1049.91it/s]
 86%|████████▌ | 4440/5153 [00:04<00:00, 1052.21it/s]
 88%|████████▊ | 4546/5153 [00:04<00:00, 1053.20it/s]
 90%|█████████ | 4652/5153 [00:04<00:00, 1053.43it/s]
 92%|█████████▏| 4758/5153 [00:04<00:00, 1054.88it/s]
 94%|█████████▍| 4864/5153 [00:04<00:00, 1052.36it/s]
 96%|█████████▋| 4970/5153 [00:04<00:00, 1051.74it/s]
 99%|█████████▊| 5076/5153 [00:04<00:00, 1049.82it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.67it/s]
2024-11-21:14:59:28,213 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.20s/it]
100%|██████████| 10/10 [00:03<00:00,  3.12it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:01:49,337 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:01:49,337 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:01:49,382 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 103/5153 [00:00<00:04, 1024.99it/s]
  4%|▍         | 207/5153 [00:00<00:04, 1029.45it/s]
  6%|▌         | 311/5153 [00:00<00:04, 1032.44it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1035.68it/s]
 10%|█         | 520/5153 [00:00<00:04, 1036.72it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1042.16it/s]
 14%|█▍        | 731/5153 [00:00<00:04, 1043.36it/s]
 16%|█▌        | 836/5153 [00:00<00:04, 1044.78it/s]
 18%|█▊        | 941/5153 [00:00<00:04, 1044.71it/s]
 20%|██        | 1046/5153 [00:01<00:03, 1044.18it/s]
 22%|██▏       | 1151/5153 [00:01<00:03, 1042.25it/s]
 24%|██▍       | 1256/5153 [00:01<00:03, 1044.00it/s]
 26%|██▋       | 1361/5153 [00:01<00:03, 1044.59it/s]
 28%|██▊       | 1466/5153 [00:01<00:03, 1046.04it/s]
 31%|███       | 1572/5153 [00:01<00:03, 1047.54it/s]
 33%|███▎      | 1677/5153 [00:01<00:03, 1045.52it/s]
 35%|███▍      | 1783/5153 [00:01<00:03, 1046.90it/s]
 37%|███▋      | 1888/5153 [00:01<00:03, 1047.07it/s]
 39%|███▊      | 1993/5153 [00:01<00:03, 1047.53it/s]
 41%|████      | 2098/5153 [00:02<00:02, 1047.37it/s]
 43%|████▎     | 2203/5153 [00:02<00:02, 1045.67it/s]
 45%|████▍     | 2308/5153 [00:02<00:02, 1043.71it/s]
 47%|████▋     | 2413/5153 [00:02<00:02, 1044.77it/s]
 49%|████▉     | 2518/5153 [00:02<00:02, 1045.90it/s]
 51%|█████     | 2623/5153 [00:02<00:02, 1046.32it/s]
 53%|█████▎    | 2728/5153 [00:02<00:02, 1046.27it/s]
 55%|█████▍    | 2833/5153 [00:02<00:02, 1046.74it/s]
 57%|█████▋    | 2938/5153 [00:02<00:02, 1046.84it/s]
 59%|█████▉    | 3043/5153 [00:02<00:02, 1046.39it/s]
 61%|██████    | 3148/5153 [00:03<00:01, 1046.68it/s]
 63%|██████▎   | 3253/5153 [00:03<00:01, 1044.76it/s]
 65%|██████▌   | 3358/5153 [00:03<00:01, 1043.82it/s]
 67%|██████▋   | 3463/5153 [00:03<00:01, 1042.38it/s]
 69%|██████▉   | 3568/5153 [00:03<00:01, 1041.90it/s]
 71%|███████▏  | 3673/5153 [00:03<00:01, 1041.15it/s]
 73%|███████▎  | 3778/5153 [00:03<00:01, 1041.78it/s]
 75%|███████▌  | 3883/5153 [00:03<00:01, 1040.33it/s]
 77%|███████▋  | 3988/5153 [00:03<00:01, 1041.34it/s]
 79%|███████▉  | 4093/5153 [00:03<00:01, 1043.50it/s]
 81%|████████▏ | 4198/5153 [00:04<00:00, 1045.10it/s]
 84%|████████▎ | 4303/5153 [00:04<00:00, 1045.05it/s]
 86%|████████▌ | 4408/5153 [00:04<00:00, 1044.04it/s]
 88%|████████▊ | 4513/5153 [00:04<00:00, 1044.01it/s]
 90%|████████▉ | 4618/5153 [00:04<00:00, 1041.75it/s]
 92%|█████████▏| 4723/5153 [00:04<00:00, 1042.05it/s]
 94%|█████████▎| 4828/5153 [00:04<00:00, 1043.79it/s]
 96%|█████████▌| 4933/5153 [00:04<00:00, 1042.62it/s]
 98%|█████████▊| 5038/5153 [00:04<00:00, 1041.83it/s]
100%|█████████▉| 5143/5153 [00:04<00:00, 1041.98it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1043.43it/s]
2024-11-21:15:01:54,362 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:34,  3.85s/it]
100%|██████████| 10/10 [00:03<00:00,  2.55it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:04:18,002 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:04:18,002 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:04:18,045 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 102/5153 [00:00<00:04, 1011.99it/s]
  4%|▍         | 204/5153 [00:00<00:04, 1016.04it/s]
  6%|▌         | 307/5153 [00:00<00:04, 1018.65it/s]
  8%|▊         | 410/5153 [00:00<00:04, 1022.39it/s]
 10%|▉         | 513/5153 [00:00<00:04, 1021.94it/s]
 12%|█▏        | 617/5153 [00:00<00:04, 1026.89it/s]
 14%|█▍        | 721/5153 [00:00<00:04, 1030.54it/s]
 16%|█▌        | 825/5153 [00:00<00:04, 1033.10it/s]
 18%|█▊        | 929/5153 [00:00<00:04, 1032.60it/s]
 20%|██        | 1033/5153 [00:01<00:03, 1034.25it/s]
 22%|██▏       | 1138/5153 [00:01<00:03, 1037.10it/s]
 24%|██▍       | 1243/5153 [00:01<00:03, 1039.43it/s]
 26%|██▌       | 1348/5153 [00:01<00:03, 1041.05it/s]
 28%|██▊       | 1453/5153 [00:01<00:03, 1042.28it/s]
 30%|███       | 1558/5153 [00:01<00:03, 1041.31it/s]
 32%|███▏      | 1663/5153 [00:01<00:03, 1040.89it/s]
 34%|███▍      | 1768/5153 [00:01<00:03, 1041.11it/s]
 36%|███▋      | 1873/5153 [00:01<00:03, 1038.41it/s]
 38%|███▊      | 1978/5153 [00:01<00:03, 1039.37it/s]
 40%|████      | 2082/5153 [00:02<00:02, 1038.26it/s]
 42%|████▏     | 2187/5153 [00:02<00:02, 1041.13it/s]
 44%|████▍     | 2292/5153 [00:02<00:02, 1042.47it/s]
 47%|████▋     | 2397/5153 [00:02<00:02, 1043.52it/s]
 49%|████▊     | 2502/5153 [00:02<00:02, 1044.25it/s]
 51%|█████     | 2607/5153 [00:02<00:02, 1044.26it/s]
 53%|█████▎    | 2712/5153 [00:02<00:02, 1044.29it/s]
 55%|█████▍    | 2817/5153 [00:02<00:02, 1043.59it/s]
 57%|█████▋    | 2922/5153 [00:02<00:02, 1042.52it/s]
 59%|█████▊    | 3027/5153 [00:02<00:02, 1041.49it/s]
 61%|██████    | 3132/5153 [00:03<00:01, 1041.72it/s]
 63%|██████▎   | 3237/5153 [00:03<00:01, 1038.49it/s]
 65%|██████▍   | 3341/5153 [00:03<00:01, 1038.46it/s]
 67%|██████▋   | 3446/5153 [00:03<00:01, 1040.75it/s]
 69%|██████▉   | 3551/5153 [00:03<00:01, 1042.55it/s]
 71%|███████   | 3656/5153 [00:03<00:01, 1043.07it/s]
 73%|███████▎  | 3762/5153 [00:03<00:01, 1045.68it/s]
 75%|███████▌  | 3868/5153 [00:03<00:01, 1047.25it/s]
 77%|███████▋  | 3973/5153 [00:03<00:01, 1047.87it/s]
 79%|███████▉  | 4078/5153 [00:03<00:01, 1047.85it/s]
 81%|████████  | 4183/5153 [00:04<00:00, 1046.13it/s]
 83%|████████▎ | 4288/5153 [00:04<00:00, 1045.26it/s]
 85%|████████▌ | 4393/5153 [00:04<00:00, 1043.00it/s]
 87%|████████▋ | 4498/5153 [00:04<00:00, 1043.16it/s]
 89%|████████▉ | 4603/5153 [00:04<00:00, 1043.23it/s]
 91%|█████████▏| 4708/5153 [00:04<00:00, 1044.34it/s]
 93%|█████████▎| 4813/5153 [00:04<00:00, 1043.93it/s]
 95%|█████████▌| 4918/5153 [00:04<00:00, 1044.63it/s]
 97%|█████████▋| 5023/5153 [00:04<00:00, 1044.23it/s]
100%|█████████▉| 5128/5153 [00:04<00:00, 1045.26it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1040.24it/s]
2024-11-21:15:04:23,040 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.16s/it]
100%|██████████| 10/10 [00:03<00:00,  3.14it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:06:44,880 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:06:44,880 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:06:44,925 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1032.00it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1035.05it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1036.10it/s]
  8%|▊         | 416/5153 [00:00<00:04, 1036.72it/s]
 10%|█         | 520/5153 [00:00<00:04, 1037.75it/s]
 12%|█▏        | 626/5153 [00:00<00:04, 1042.91it/s]
 14%|█▍        | 732/5153 [00:00<00:04, 1045.54it/s]
 16%|█▌        | 837/5153 [00:00<00:04, 1045.17it/s]
 18%|█▊        | 942/5153 [00:00<00:04, 1045.97it/s]
 20%|██        | 1048/5153 [00:01<00:03, 1047.81it/s]
 22%|██▏       | 1154/5153 [00:01<00:03, 1051.26it/s]
 24%|██▍       | 1260/5153 [00:01<00:03, 1053.85it/s]
 27%|██▋       | 1366/5153 [00:01<00:03, 1054.26it/s]
 29%|██▊       | 1472/5153 [00:01<00:03, 1053.63it/s]
 31%|███       | 1578/5153 [00:01<00:03, 1050.27it/s]
 33%|███▎      | 1684/5153 [00:01<00:03, 1047.14it/s]
 35%|███▍      | 1789/5153 [00:01<00:03, 1046.50it/s]
 37%|███▋      | 1894/5153 [00:01<00:03, 1046.72it/s]
 39%|███▉      | 1999/5153 [00:01<00:03, 1046.32it/s]
 41%|████      | 2105/5153 [00:02<00:02, 1047.56it/s]
 43%|████▎     | 2211/5153 [00:02<00:02, 1048.48it/s]
 45%|████▍     | 2317/5153 [00:02<00:02, 1049.35it/s]
 47%|████▋     | 2423/5153 [00:02<00:02, 1051.51it/s]
 49%|████▉     | 2529/5153 [00:02<00:02, 1052.27it/s]
 51%|█████     | 2635/5153 [00:02<00:02, 1051.63it/s]
 53%|█████▎    | 2741/5153 [00:02<00:02, 1051.60it/s]
 55%|█████▌    | 2847/5153 [00:02<00:02, 1050.85it/s]
 57%|█████▋    | 2953/5153 [00:02<00:02, 1049.99it/s]
 59%|█████▉    | 3058/5153 [00:02<00:01, 1049.19it/s]
 61%|██████▏   | 3163/5153 [00:03<00:01, 1048.29it/s]
 63%|██████▎   | 3269/5153 [00:03<00:01, 1049.02it/s]
 65%|██████▌   | 3375/5153 [00:03<00:01, 1050.12it/s]
 68%|██████▊   | 3481/5153 [00:03<00:01, 1052.19it/s]
 70%|██████▉   | 3587/5153 [00:03<00:01, 1052.26it/s]
 72%|███████▏  | 3693/5153 [00:03<00:01, 1052.08it/s]
 74%|███████▎  | 3799/5153 [00:03<00:01, 1052.19it/s]
 76%|███████▌  | 3905/5153 [00:03<00:01, 1050.31it/s]
 78%|███████▊  | 4011/5153 [00:03<00:01, 1049.72it/s]
 80%|███████▉  | 4116/5153 [00:03<00:00, 1049.64it/s]
 82%|████████▏ | 4221/5153 [00:04<00:00, 1046.74it/s]
 84%|████████▍ | 4326/5153 [00:04<00:00, 1043.00it/s]
 86%|████████▌ | 4431/5153 [00:04<00:00, 1042.94it/s]
 88%|████████▊ | 4536/5153 [00:04<00:00, 1044.41it/s]
 90%|█████████ | 4641/5153 [00:04<00:00, 1045.17it/s]
 92%|█████████▏| 4746/5153 [00:04<00:00, 1045.52it/s]
 94%|█████████▍| 4852/5153 [00:04<00:00, 1047.49it/s]
 96%|█████████▌| 4957/5153 [00:04<00:00, 1047.83it/s]
 98%|█████████▊| 5063/5153 [00:04<00:00, 1048.98it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1048.01it/s]
2024-11-21:15:06:49,883 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.20s/it]
100%|██████████| 10/10 [00:03<00:00,  3.06it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:09:14,034 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:09:14,034 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:09:14,077 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1036.45it/s]
  4%|▍         | 209/5153 [00:00<00:04, 1039.21it/s]
  6%|▌         | 314/5153 [00:00<00:04, 1040.60it/s]
  8%|▊         | 419/5153 [00:00<00:04, 1043.91it/s]
 10%|█         | 524/5153 [00:00<00:04, 1045.03it/s]
 12%|█▏        | 630/5153 [00:00<00:04, 1049.46it/s]
 14%|█▍        | 736/5153 [00:00<00:04, 1052.05it/s]
 16%|█▋        | 842/5153 [00:00<00:04, 1051.41it/s]
 18%|█▊        | 948/5153 [00:00<00:03, 1053.34it/s]
 20%|██        | 1055/5153 [00:01<00:03, 1055.76it/s]
 23%|██▎       | 1162/5153 [00:01<00:03, 1058.74it/s]
 25%|██▍       | 1269/5153 [00:01<00:03, 1060.12it/s]
 27%|██▋       | 1376/5153 [00:01<00:03, 1062.10it/s]
 29%|██▉       | 1483/5153 [00:01<00:03, 1062.27it/s]
 31%|███       | 1590/5153 [00:01<00:03, 1061.83it/s]
 33%|███▎      | 1697/5153 [00:01<00:03, 1060.48it/s]
 35%|███▌      | 1804/5153 [00:01<00:03, 1057.75it/s]
 37%|███▋      | 1910/5153 [00:01<00:03, 1054.65it/s]
 39%|███▉      | 2016/5153 [00:01<00:02, 1054.54it/s]
 41%|████      | 2123/5153 [00:02<00:02, 1056.80it/s]
 43%|████▎     | 2230/5153 [00:02<00:02, 1058.01it/s]
 45%|████▌     | 2337/5153 [00:02<00:02, 1058.96it/s]
 47%|████▋     | 2443/5153 [00:02<00:02, 1059.10it/s]
 49%|████▉     | 2550/5153 [00:02<00:02, 1061.57it/s]
 52%|█████▏    | 2657/5153 [00:02<00:02, 1062.19it/s]
 54%|█████▎    | 2764/5153 [00:02<00:02, 1063.16it/s]
 56%|█████▌    | 2871/5153 [00:02<00:02, 1063.56it/s]
 58%|█████▊    | 2978/5153 [00:02<00:02, 1060.86it/s]
 60%|█████▉    | 3085/5153 [00:02<00:01, 1059.18it/s]
 62%|██████▏   | 3191/5153 [00:03<00:01, 1056.29it/s]
 64%|██████▍   | 3297/5153 [00:03<00:01, 1055.20it/s]
 66%|██████▌   | 3403/5153 [00:03<00:01, 1054.50it/s]
 68%|██████▊   | 3509/5153 [00:03<00:01, 1054.52it/s]
 70%|███████   | 3615/5153 [00:03<00:01, 1055.24it/s]
 72%|███████▏  | 3722/5153 [00:03<00:01, 1056.85it/s]
 74%|███████▍  | 3828/5153 [00:03<00:01, 1057.67it/s]
 76%|███████▋  | 3934/5153 [00:03<00:01, 1057.78it/s]
 78%|███████▊  | 4041/5153 [00:03<00:01, 1058.68it/s]
 80%|████████  | 4147/5153 [00:03<00:00, 1058.54it/s]
 83%|████████▎ | 4253/5153 [00:04<00:00, 1057.34it/s]
 85%|████████▍ | 4359/5153 [00:04<00:00, 1053.39it/s]
 87%|████████▋ | 4465/5153 [00:04<00:00, 1053.18it/s]
 89%|████████▊ | 4571/5153 [00:04<00:00, 1052.01it/s]
 91%|█████████ | 4677/5153 [00:04<00:00, 1051.66it/s]
 93%|█████████▎| 4783/5153 [00:04<00:00, 1052.38it/s]
 95%|█████████▍| 4889/5153 [00:04<00:00, 1052.81it/s]
 97%|█████████▋| 4995/5153 [00:04<00:00, 1052.82it/s]
 99%|█████████▉| 5101/5153 [00:04<00:00, 1053.43it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1055.66it/s]
2024-11-21:15:09:19,000 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:29,  3.33s/it]
100%|██████████| 10/10 [00:03<00:00,  2.98it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:11:41,014 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:11:41,014 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:11:41,059 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 105/5153 [00:00<00:04, 1040.31it/s]
  4%|▍         | 210/5153 [00:00<00:04, 1044.24it/s]
  6%|▌         | 315/5153 [00:00<00:04, 1046.41it/s]
  8%|▊         | 421/5153 [00:00<00:04, 1049.55it/s]
 10%|█         | 527/5153 [00:00<00:04, 1050.50it/s]
 12%|█▏        | 634/5153 [00:00<00:04, 1056.36it/s]
 14%|█▍        | 741/5153 [00:00<00:04, 1059.06it/s]
 16%|█▋        | 848/5153 [00:00<00:04, 1061.20it/s]
 19%|█▊        | 955/5153 [00:00<00:03, 1062.58it/s]
 21%|██        | 1062/5153 [00:01<00:03, 1064.05it/s]
 23%|██▎       | 1169/5153 [00:01<00:03, 1063.89it/s]
 25%|██▍       | 1276/5153 [00:01<00:03, 1065.47it/s]
 27%|██▋       | 1383/5153 [00:01<00:03, 1066.37it/s]
 29%|██▉       | 1491/5153 [00:01<00:03, 1068.20it/s]
 31%|███       | 1598/5153 [00:01<00:03, 1068.49it/s]
 33%|███▎      | 1706/5153 [00:01<00:03, 1069.24it/s]
 35%|███▌      | 1813/5153 [00:01<00:03, 1068.64it/s]
 37%|███▋      | 1920/5153 [00:01<00:03, 1067.09it/s]
 39%|███▉      | 2028/5153 [00:01<00:02, 1068.40it/s]
 41%|████▏     | 2135/5153 [00:02<00:02, 1067.72it/s]
 44%|████▎     | 2242/5153 [00:02<00:02, 1068.35it/s]
 46%|████▌     | 2349/5153 [00:02<00:02, 1067.08it/s]
 48%|████▊     | 2456/5153 [00:02<00:02, 1067.86it/s]
 50%|████▉     | 2563/5153 [00:02<00:02, 1067.84it/s]
 52%|█████▏    | 2670/5153 [00:02<00:02, 1068.22it/s]
 54%|█████▍    | 2777/5153 [00:02<00:02, 1068.01it/s]
 56%|█████▌    | 2885/5153 [00:02<00:02, 1069.27it/s]
 58%|█████▊    | 2992/5153 [00:02<00:02, 1068.49it/s]
 60%|██████    | 3100/5153 [00:02<00:01, 1070.08it/s]
 62%|██████▏   | 3208/5153 [00:03<00:01, 1070.01it/s]
 64%|██████▍   | 3316/5153 [00:03<00:01, 1070.16it/s]
 66%|██████▋   | 3424/5153 [00:03<00:01, 1070.85it/s]
 69%|██████▊   | 3532/5153 [00:03<00:01, 1068.52it/s]
 71%|███████   | 3639/5153 [00:03<00:01, 1067.60it/s]
 73%|███████▎  | 3746/5153 [00:03<00:01, 1068.04it/s]
 75%|███████▍  | 3853/5153 [00:03<00:01, 1067.93it/s]
 77%|███████▋  | 3960/5153 [00:03<00:01, 1067.55it/s]
 79%|███████▉  | 4067/5153 [00:03<00:01, 1068.17it/s]
 81%|████████  | 4174/5153 [00:03<00:00, 1068.30it/s]
 83%|████████▎ | 4281/5153 [00:04<00:00, 1068.26it/s]
 85%|████████▌ | 4388/5153 [00:04<00:00, 1068.15it/s]
 87%|████████▋ | 4495/5153 [00:04<00:00, 1068.63it/s]
 89%|████████▉ | 4602/5153 [00:04<00:00, 1067.77it/s]
 91%|█████████▏| 4709/5153 [00:04<00:00, 1066.32it/s]
 93%|█████████▎| 4816/5153 [00:04<00:00, 1064.79it/s]
 96%|█████████▌| 4923/5153 [00:04<00:00, 1065.64it/s]
 98%|█████████▊| 5030/5153 [00:04<00:00, 1065.67it/s]
100%|█████████▉| 5137/5153 [00:04<00:00, 1065.98it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1065.67it/s]
2024-11-21:15:11:45,936 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:03<00:28,  3.15s/it]
100%|██████████| 10/10 [00:03<00:00,  3.13it/s]
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/xl6yq/.conda/envs/rwkv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2024-11-21:15:14:32,657 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:14:32,657 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-11-21:15:14:32,701 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...

  0%|          | 0/5153 [00:00<?, ?it/s]
  2%|▏         | 104/5153 [00:00<00:04, 1034.17it/s]
  4%|▍         | 208/5153 [00:00<00:04, 1037.40it/s]
  6%|▌         | 312/5153 [00:00<00:04, 1036.90it/s]
  8%|▊         | 417/5153 [00:00<00:04, 1039.98it/s]
 10%|█         | 522/5153 [00:00<00:04, 1042.88it/s]
 12%|█▏        | 628/5153 [00:00<00:04, 1045.92it/s]
 14%|█▍        | 734/5153 [00:00<00:04, 1047.87it/s]
 16%|█▋        | 839/5153 [00:00<00:04, 1048.26it/s]
 18%|█▊        | 945/5153 [00:00<00:04, 1049.17it/s]
 20%|██        | 1051/5153 [00:01<00:03, 1050.15it/s]
 22%|██▏       | 1157/5153 [00:01<00:03, 1051.45it/s]
 25%|██▍       | 1263/5153 [00:01<00:03, 1050.09it/s]
 27%|██▋       | 1369/5153 [00:01<00:03, 1051.10it/s]
 29%|██▊       | 1475/5153 [00:01<00:03, 1050.94it/s]
 31%|███       | 1581/5153 [00:01<00:03, 1050.20it/s]
 33%|███▎      | 1687/5153 [00:01<00:03, 1049.17it/s]
 35%|███▍      | 1792/5153 [00:01<00:03, 1046.43it/s]
 37%|███▋      | 1897/5153 [00:01<00:03, 1044.39it/s]
 39%|███▉      | 2002/5153 [00:01<00:03, 1045.81it/s]
 41%|████      | 2107/5153 [00:02<00:02, 1046.37it/s]
 43%|████▎     | 2213/5153 [00:02<00:02, 1048.30it/s]
 45%|████▍     | 2318/5153 [00:02<00:02, 1047.79it/s]
 47%|████▋     | 2424/5153 [00:02<00:02, 1049.21it/s]
 49%|████▉     | 2529/5153 [00:02<00:02, 1049.15it/s]
 51%|█████     | 2634/5153 [00:02<00:02, 1048.71it/s]
 53%|█████▎    | 2740/5153 [00:02<00:02, 1049.17it/s]
 55%|█████▌    | 2845/5153 [00:02<00:02, 1049.26it/s]
 57%|█████▋    | 2951/5153 [00:02<00:02, 1049.90it/s]
 59%|█████▉    | 3056/5153 [00:02<00:01, 1049.52it/s]
 61%|██████▏   | 3161/5153 [00:03<00:01, 1049.24it/s]
 63%|██████▎   | 3266/5153 [00:03<00:01, 1049.39it/s]
 65%|██████▌   | 3372/5153 [00:03<00:01, 1049.96it/s]
 67%|██████▋   | 3477/5153 [00:03<00:01, 1049.07it/s]
 70%|██████▉   | 3583/5153 [00:03<00:01, 1052.01it/s]
 72%|███████▏  | 3689/5153 [00:03<00:01, 1052.51it/s]
 74%|███████▎  | 3795/5153 [00:03<00:01, 1053.72it/s]
 76%|███████▌  | 3901/5153 [00:03<00:01, 1053.66it/s]
 78%|███████▊  | 4007/5153 [00:03<00:01, 1052.37it/s]
 80%|███████▉  | 4113/5153 [00:03<00:00, 1053.11it/s]
 82%|████████▏ | 4219/5153 [00:04<00:00, 1052.26it/s]
 84%|████████▍ | 4325/5153 [00:04<00:00, 1051.35it/s]
 86%|████████▌ | 4431/5153 [00:04<00:00, 1050.77it/s]
 88%|████████▊ | 4537/5153 [00:04<00:00, 1052.11it/s]
 90%|█████████ | 4643/5153 [00:04<00:00, 1051.10it/s]
 92%|█████████▏| 4749/5153 [00:04<00:00, 1051.07it/s]
 94%|█████████▍| 4855/5153 [00:04<00:00, 1052.60it/s]
 96%|█████████▋| 4961/5153 [00:04<00:00, 1053.52it/s]
 98%|█████████▊| 5067/5153 [00:04<00:00, 1051.76it/s]
100%|██████████| 5153/5153 [00:04<00:00, 1049.38it/s]
2024-11-21:15:14:37,655 INFO     [evaluator.py:489] Running loglikelihood requests

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|█         | 1/10 [00:02<00:26,  3.00s/it]
100%|██████████| 10/10 [00:03<00:00,  3.29it/s]

========================================
